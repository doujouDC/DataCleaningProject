@misc{Anguita2013,
author = {Anguita, Davide and Ghio, Alessandro and Oneto, Luca and Parra, Xavier and Reyes-Ortiz, Jorge L.},
title = {{Human Activity Recognition Using Smartphones Data Set}},
url = {http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones{\#}},
urldate = {2019-10-04},
year = {2013}
}
@article{Higman2015,
abstract = {Purpose - The purpose of this paper is to investigate the relationship between research data management (RDM) and data sharing in the formulation of RDM policies and development of practices in Higher Education Institutions (HEIs). Design/methodology/approach - Two strands of work were undertaken sequentially: first, content analysis of 37 RDM policies from UK HEIs; and second, two detailed case studies of institutions with different approaches to RDM based on semi-structured interviews with staff involved in the development of RDM policy and services. The data are interpreted using insights from Actor Network Theory. Findings - RDM policy formation and service development has created a complex set of networks within and beyond institutions involving different professional groups with widely varying priorities shaping activities. Data sharing is considered an important activity in the policies and services of HEIs studied, but its prominence can in most cases be attributed to the positions adopted by large research funders. Research limitations/implications - The case studies, as research based on qualitative data, cannot be assumed to be universally applicable but do illustrate a variety of issues and challenges experienced more generally, particularly in the UK. Practical implications - The research may help to inform development of policy and practice in RDM in HEIs and funder organisations. Originality/value - This paper makes an early contribution to the RDM literature on the specific topic of the relationship between RDM policy and services, and openness - a topic which to date has received limited attention.},
annote = {Sp. Iss. SI
Dc3fx
Times Cited:5
Cited References Count:53},
author = {Higman, R and Pinfield, S},
doi = {10.1108/PROG­01­2015­0005},
isbn = {0033-0337},
journal = {Program-Electronic Library and Information Systems},
keywords = {access,actor network theory,actor-network theory,data sharing,open data,openness,research data management,research data services},
language = {English},
number = {4},
pages = {364--381},
title = {{Research data management and openness: the role of data sharing in developing institutional policies and practices}},
volume = {49},
year = {2015}
}
@article{Joque2013,
author = {Joque, Justin},
journal = {IASSIST Quarterly},
title = {{From Data to the Creation of Meaning Part 1: Unit of Analysis as Epistemological Problem}},
year = {2013}
}
@inproceedings{Kery2017,
abstract = {A diverse range of people, from students to engineers to designers, are interested in using programming to analyze, visualize, and build new intelligent systems from data. However, when working with data, a programmer must typically experiment heavily: writing out and running many different approaches in code to reach a desired result [1][2]. This form of exploratory programming presents extra challenges and pitfalls for programmers. For example, as a person iterates on a problem over a long period of time, it can become difficult to answer questions like: 'Through what steps did I achieve this result?' [3] or 'What different analyses have I tried or not tried so far?'. Currently there is a sparsity of tools for programmers to keep track of all their code experimentation, and intermediary data analysis steps are easily lost. Programmers also struggle with making many small highly exploratory code changes, such as trying 10 different values of a parameter [2]. Current code version tools are not designed for rapid iteration on small sections of code, thus these programmers often resort to informal ad-hoc methods of versioning such as leaving 10 different values of a parameter in comments in their code, or copying the 10 different values to a separate text file. As programmers work to make sense of challenging data questions, managing experiments in code adds an extra degree of overhead and confusion that can make this work all the more difficult. {\textcopyright} 2017 IEEE.},
annote = {Export Date: 20 July 2018
Correspondence Address: Kery, M.B.; Human-Computer Interaction Institute, Carnegie Mellon UniversityUnited States; email: mkery@cs.cmu.edu},
author = {Kery, M B},
doi = {10.1109/VLHCC.2017.8103490},
editor = {Rodgers, P and Henley, A Z and Sarma, A},
isbn = {19436092 (ISSN); 9781538604434 (ISBN)},
keywords = {Ad hoc methods,Code changes,Codes (symbols),Current codes,Diverse range,Intelligent systems,Iterative methods,Keep track of,Text file,Versioning,Visual languages},
language = {English},
pages = {321--322},
publisher = {IEEE Computer Society},
title = {{Tools to support exploratory programming with data}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85041006054{\&}doi=10.1109{\%}2FVLHCC.2017.8103490{\&}partnerID=40{\&}md5=8db6cc7f255a486065a09e45e092f6a3 https://ieeexplore.ieee.org/ielx7/8094484/8103434/08103490.pdf?tp={\&}arnumber=8103490{\&}isnumber=8103434},
volume = {2017-Octob},
year = {2017}
}
@article{WilsonSayres2018,
abstract = {Although bioinformatics is becoming increasingly central to research in the life sciences, bioinformatics skills and knowledge are not well integrated into undergraduate biology education. This curricular gap prevents biology students from harnessing the full potential of their education, limiting their career opportunities and slowing research innovation. To advance the integration of bioinformatics into life sciences education, a framework of core bioinformatics competencies is needed. To that end, we here report the results of a survey of biology faculty in the United States about teaching bioinformatics to undergraduate life scientists. Responses were received from 1,260 faculty representing institutions in all fifty states with a combined capacity to educate hundreds of thousands of students every year. Results indicate strong, widespread agreement that bioinformatics knowledge and skills are critical for undergraduate life scientists as well as considerable agreement about which skills are necessary. Perceptions of the importance of some skills varied with the respondent's degree of training, time since degree earned, and/or the Carnegie Classification of the respondent's institution. To assess which skills are currently being taught, we analyzed syllabi of courses with bioinformatics content submitted by survey respondents. Finally, we used the survey results, the analysis of the syllabi, and our collective research and teaching expertise to develop a set of bioinformatics core competencies for undergraduate biology students. These core competencies are intended to serve as a guide for institutions as they work to integrate bioinformatics into their life sciences curricula.},
author = {{Wilson Sayres}, Melissa A and Hauser, Charles and Sierk, Michael and Robic, Srebrenka and Rosenwald, Anne G and Smith, Todd M and Triplett, Eric W and Williams, Jason J and Dinsdale, Elizabeth and Morgan, William R and {Burnette  III}, James M and Donovan, Samuel S and Drew, Jennifer C and Elgin, Sarah C R and Fowlks, Edison R and Galindo-Gonzalez, Sebastian and Goodman, Anya L and Grandgenett, Nealy F and Goller, Carlos C and Jungck, John R and Newman, Jeffrey D and Pearson, William and Ryder, Elizabeth F and Tosado-Acevedo, Rafael and Tapprich, William and Tobin, Tammy C and Toro-Mart{\'{i}}nez, Arl{\'{i}}n and Welch, Lonnie R and Wright, Robin and Barone, Lindsay and Ebenbach, David and McWilliams, Mindy and Olney, Kimberly C and Pauley, Mark A},
doi = {10.1371/journal.pone.0196878},
journal = {PLoS ONE},
number = {6},
pages = {e0196878},
publisher = {Public Library of Science},
title = {{Bioinformatics core competencies for undergraduate life sciences education}},
url = {https://doi.org/10.1371/journal.pone.0196878 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5988330/pdf/pone.0196878.pdf},
volume = {13},
year = {2018}
}
@incollection{Matthes2016a,
abstract = {Python Crash Courseis a quick, no-nonsense guide to programming in Python.},
address = {San Francisco, CA},
annote = {Accession Number: 1141153; OCLC: 932304495; Language: English},
author = {Matthes, Eric},
booktitle = {Python Crash Course : A Hands-on, Project-based Introduction to Programming},
isbn = {97815932760349781593277390},
keywords = {COMPUTERS / Software Development {\&} Engineering / S,Computer programming,Python (Computer program language)},
language = {English},
publisher = {No Starch Press},
title = {{Chapter 2: Variables and Simple Data Types}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=nlebk{\&}AN=1141153{\&}site=ehost-live},
year = {2016}
}
@article{Brehmer2017,
abstract = {There are many ways to visualize event sequences as timelines. In a storytelling context where the intent is to convey multiple narrative points, a richer set of timeline designs may be more appropriate than the narrow range that has been used for exploratory data analysis by the research community. Informed by a survey of 263 timelines, we present a design space for storytelling with timelines that balances expressiveness and effectiveness, identifying 14 design choices characterized by three dimensions: Representation, scale, and layout. Twenty combinations of these choices are viable timeline designs that can be matched to different narrative points, while smooth animated transitions between narrative points allow for the presentation of a cohesive story, an important aspect of both interactive storytelling and data videos. We further validate this design space by realizing the full set of viable timeline designs and transitions in a proof-of-concept sandbox implementation that we used to produce seven example timeline stories. Ultimately, this work is intended to inform and inspire the design of future tools for storytelling with timelines. {\textcopyright} 2017 IEEE.},
annote = {Cited By :11
Export Date: 2 January 2019},
author = {Brehmer, M and Lee, B and Bach, B and Riche, N H and Munzner, T},
doi = {10.1109/TVCG.2016.2614803},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Timelines,animated transitions,design space,narrative visualization,storytelling},
number = {9},
pages = {2151--2164},
title = {{Timelines Revisited: A Design Space and Considerations for Expressive Storytelling}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85028884571{\&}doi=10.1109{\%}2FTVCG.2016.2614803{\&}partnerID=40{\&}md5=0d74ae0b6f9a1c227c6b4663a8d27f85 https://ieeexplore.ieee.org/ielx7/2945/7995103/07581076.pdf?tp={\&}arnumber=7581076{\&}isnumber=7995103},
volume = {23},
year = {2017}
}
@incollection{Few2012b,
author = {Few, Stephen},
booktitle = {Show me the numbers : designing tables and graphs to enlighten},
edition = {2nd},
isbn = {978-0970601971},
keywords = {Business presentations Charts, diagrams, etc.,Business presentations Graphic methods.,Graphic methods.},
pages = {15--21},
publisher = {Analytics Press},
title = {{Simple Statistics to Get You Started}},
year = {2012}
}
@article{Tory2009,
abstract = {Spatialization displays use a geographic metaphor to arrange non-spatial data. For example, spatializations are commonly applied to document collections so that document themes appear as geographic features such as hills. Many common spatialization interfaces use a 3-D landscape metaphor to present data. However, it is not clear whether 3-D spatializations afford improved speed and accuracy for user tasks compared to similar 2-D spatializations. We describe a user study comparing users' ability to remember dot displays, 2-D landscapes, and 3-D landscapes for two different data densities (500 vs. 1000 points). Participants' visual memory was statistically more accurate when viewing dot displays and 3-D landscapes compared to 2-D landscapes. Furthermore, accuracy remembering a spatialization was significantly better overall for denser spatializations. Theseresults are of benefit to visualization designers who are contemplating the best ways to present data using spatialization techniques.},
author = {Tory, M and Swindells, C and Dreezer, R},
doi = {10.1109/TVCG.2009.127},
isbn = {1077-2626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {2D landscapes,3D landscapes,Automobiles,Data visualization,Design methodology,Information interfaces and presentation,Psychology,Software systems,Surface fitting,Surface topography,Three dimensional displays,Two dimensional displays,Uncertainty,data visualisation,document collections,document handling,dot displays,dot spatializations,evaluation / methodology,geographic metaphor,landscape spatializations,landscape visualization.,nonspatial data,screen design,software psychology,spatialization displays,spatialization interfaces,user / machine systems,visual memory differences},
number = {6},
pages = {1033--1040},
title = {{Comparing Dot and Landscape Spatializations for Visual Memory Differences}},
url = {https://ieeexplore.ieee.org/document/5290709/},
volume = {15},
year = {2009}
}
@article{Byron2008,
abstract = {In February 2008, the New York Times published an unusual chart of box office revenues for 7500 movies over 21 years. The chart was based on a similar visualization, developed by the first author, that displayed trends in music listening. This paper describes the design decisions and algorithms behind these graphics, and discusses the reaction on the Web. We suggest that this type of complex layered graph is effective for displaying large data sets to a mass audience. We provide a mathematical analysis of how this layered graph relates to traditional stacked graphs and to techniques such as ThemeRiver, showing how each method is optimizing a different ldquoenergy functionrdquo. Finally, we discuss techniques for coloring and ordering the layers of such graphs. Throughout the paper, we emphasize the interplay between considerations of aesthetics and legibility.},
author = {Byron, L and Wattenberg, M},
doi = {10.1109/TVCG.2008.166},
isbn = {1077-2626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Algorithm design and analysis,Blogs,Data visualization,Graphics,History,Index Terms—,Mathematical analysis,Motion pictures,Optimization methods,Process design,Streamgraph,ThemeRiver,aesthetics,communication-minded visualization,complex layered graph,data visualisation,geometry,last.fm,layered graph,listening history,stacked graphs,time series},
number = {6},
pages = {1245--1252},
title = {{Stacked Graphs – Geometry {\&} Aesthetics}},
url = {https://ieeexplore.ieee.org/document/4658136/},
volume = {14},
year = {2008}
}
@article{Borner2007,
author = {B{\"{o}}rner, Katy and Sanyal, Soma and Vespignani, Alessandro},
journal = {Annual Review of Information Science {\&} Technology},
title = {{Network Science}},
volume = {41},
year = {2007}
}
@incollection{Garrett2017a,
abstract = {.},
address = {Sebastopol},
author = {Garrett, Grolemund and Hadley, Wickham},
booktitle = {R for Data Science},
isbn = {978-1491910399},
pages = {555},
publisher = {O'Reilly Media},
title = {{Workflow: basics}},
year = {2017}
}
@book{Few2012a,
author = {Few, Stephen},
edition = {2nd},
isbn = {978-0970601971},
keywords = {Business presentations Charts, diagrams, etc.,Business presentations Graphic methods.,Graphic methods.},
pages = {xviii, 351 pages},
publisher = {Analytics Press},
title = {{Show me the numbers : designing tables and graphs to enlighten}},
year = {2012}
}
@article{Talbot2014,
abstract = {Bar charts are one of the most common visualization types. In a classic graphical perception paper, Cleveland McGill studied how different bar chart designs impact the accuracy with which viewers can complete simple perceptual tasks. They found that people perform substantially worse on stacked bar charts than on aligned bar charts, and that comparisons between adjacent bars are more accurate than between widely separated bars. However, the study did not explore why these differences occur. In this paper, we describe a series of follow-up experiments to further explore and explain their results. While our results generally confirm Cleveland McGill's ranking of various bar chart configurations, we provide additional insight into the bar chart reading task and the sources of participants' errors. We use our results to propose new hypotheses on the perception of bar charts. {\textcopyright} 1995-2012 IEEE.},
annote = {Cited By :15
Export Date: 10 July 2018
CODEN: ITVGE
Correspondence Address: Talbot, J.; Tableau ResearchUnited States},
author = {Talbot, J and Setlur, V and Anand, A},
doi = {10.1109/TVCG.2014.2346320},
isbn = {10772626 (ISSN)},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Bar chart,Graphical perception,Graphical perceptions,Humans,Task Performance and Analysis,Visual Perception,adult,bar charts,computer graphics,crowdsourcing,human,middle aged,physiology,task performance,vision,young adult},
language = {English},
number = {12},
pages = {2152--2160},
publisher = {IEEE Computer Society},
title = {{Four experiments on the perception of bar charts}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84910074126{\&}doi=10.1109{\%}2FTVCG.2014.2346320{\&}partnerID=40{\&}md5=c5c9647a2ba6b9df85d72b899ada22e1 https://ieeexplore.ieee.org/ielx7/2945/6935054/06876021.pdf?tp={\&}arnumber=6876021{\&}isnumber=6935054},
volume = {20},
year = {2014}
}
@unpublished{Hadley2017,
author = {Hadley, Martin},
publisher = {Lynda.com},
title = {{Learning the R Tidyverse}},
url = {http://lynda.com},
year = {2017}
}
@article{Fairfield2014,
abstract = {As big data techniques become widespread in journalism, both as the subject of reporting and as newsgathering tools, the ethics of data science must inform and be informed by media ethics. This article explores emerging problems in ethical research using big data techniques. It does so using the duty-based framework advanced by W.D. Ross, who has significantly influenced both research science and media ethics. A successful framework must provide stability and flexibility. Without stability, ethical precommitments will vanish as technology rapidly shifts costs. Without flexibility, traditional approaches will rapidly become obsolete in the face of technological change. The article concludes that Ross's duty-based approach both provides stability in the face of rapid technological change and flexibility to innovate to achieve the original purpose of basic ethical principles. {\textcopyright} 2014 Copyright Taylor and Francis Group, LLC.},
annote = {Cited By :27
Export Date: 9 January 2019},
author = {Fairfield, J and Shtein, H},
doi = {10.1080/08900523.2014.863126},
journal = {Journal of Mass Media Ethics: Exploring Questions of Media Morality},
number = {1},
pages = {38--51},
title = {{Big Data, Big Problems: Emerging Issues in the Ethics of Data Science and Journalism}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892776073{\&}doi=10.1080{\%}2F08900523.2014.863126{\&}partnerID=40{\&}md5=87f4a3f12ef2e5517fa796e3ed32b636},
volume = {29},
year = {2014}
}
@article{Wolkovich2012,
abstract = {Understanding how species and ecosystems respond to climate change requires spatially and temporally rich data for a diverse set of species and habitats, combined with models that test and predict responses. Yet current study is hampered by the long-known problems of inadequate management of data and insufficient description of analytical procedures, especially in the field of ecology. Despite recent institutional incentives to share data and new data archiving infrastructure, many ecologists do not archive and publish their data and code. Given current rapid rates of global change, the consequences of this are extreme: because an ecological dataset collected at a certain place and time represents an irreproducible set of observations, ecologists doing local, independent research possess, in their file cabinets and spreadsheets, a wealth of information about the natural world and how it is changing. Although large-scale initiatives will increasingly enable and reward open science, we believe that change demands action and personal commitment by individuals - from students and PIs. Herein, we outline the major benefits of sharing data and analytical procedures in the context of global change ecology, and provide guidelines for overcoming common obstacles and concerns. If individual scientists and laboratories can embrace a culture of archiving and sharing we can accelerate the pace of the scientific method and redefine how local science can most robustly scale up to globally relevant questions. {\textcopyright} 2012 Blackwell Publishing Ltd.},
annote = {Cited By :56
Export Date: 9 August 2019
Correspondence Address: Wolkovich, E.M.; Department of Biological Sciences, University of California, San Diego 9500, Gilman Drive {\#}0116, La Jolla, CA 92093-0116, United States; email: wolkovich@biodiversity.ubc.ca},
author = {Wolkovich, E M and Regetz, J and O'Connor, M I},
doi = {10.1111/j.1365-2486.2012.02693.x},
isbn = {13541013 (ISSN)},
journal = {Global Change Biology},
keywords = {Code management,Data management,Global change ecology,Open science,Scientific method,ecosystem modeling,ecosystem response,global change},
language = {English},
number = {7},
pages = {2102--2110},
title = {{Advances in global change research require open science by individual researchers}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84861882341{\&}doi=10.1111{\%}2Fj.1365-2486.2012.02693.x{\&}partnerID=40{\&}md5=600e74ad79db2af53c753c07d0a4e93c https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1365-2486.2012.02693.x},
volume = {18},
year = {2012}
}
@incollection{Garrett2017,
abstract = {.},
address = {Sebastopol},
author = {Garrett, Grolemund and Hadley, Wickham},
booktitle = {R for Data Science},
isbn = {978-1-491-91039-9},
pages = {555},
publisher = {O'Reilly Media},
title = {{Data transformation with dplyr}},
year = {2017}
}
@article{Alter2007,
abstract = {Humans appear to reason using two processing styles: System 1 processes that are quick, intuitive, and effortless and System 2 processes that are slow, analytical, and deliberate that occasionally correct the output of System 1. Four experiments suggest that System 2 processes are activated by metacognitive experiences of difficulty or disfluency during the process of reasoning. Incidental experiences of difficulty or disfluency--receiving information in a degraded font (Experiments 1 and 4), in difficult-to-read lettering (Experiment 2), or while furrowing one's brow (Experiment 3)--reduced the impact of heuristics and defaults in judgment (Experiments 1 and 3), reduced reliance on peripheral cues in persuasion (Experiment 2), and improved syllogistic reasoning (Experiment 4). Metacognitive experiences of difficulty or disfluency appear to serve as an alarm that activates analytic forms of reasoning that assess and sometimes correct the output of more intuitive forms of reasoning.},
annote = {Alter, Adam L
Oppenheimer, Daniel M
Epley, Nicholas
Eyre, Rebecca N
eng
Research Support, U.S. Gov't, Non-P.H.S.
J Exp Psychol Gen. 2007 Nov;136(4):569-76. doi: 10.1037/0096-3445.136.4.569.},
author = {Alter, A L and Oppenheimer, D M and Epley, N and Eyre, R N},
doi = {10.1037/0096-3445.136.4.569},
edition = {2007/11/15},
isbn = {0096-3445 (Print)0022-1015 (Linking)},
journal = {J Exp Psychol Gen},
keywords = {*Cognition,*Decision Making,*Intuition,*Judgment,Humans,Pilot Projects},
number = {4},
pages = {569--576},
pmid = {17999571},
title = {{Overcoming intuition: metacognitive difficulty activates analytic reasoning}},
url = {https://www.ncbi.nlm.nih.gov/pubmed/17999571},
volume = {136},
year = {2007}
}
@article{Sharma1997,
abstract = {This paper surveys current technology and research in the area of digital color imaging. In order to establish the background and lay down terminology, fundamental concepts of color perception and measurement are first presented using vector-space notation and terminology. Present-day color recording and reproduction systems are reviewed along with the common mathematical models used for representing these devices. Algorithms for processing color images for display and communication are surveyed, and a forecast of research trends is attempted. An extensive bibliography is provided. {\textcopyright} 1997 IEEE.},
annote = {Cited By :338
Export Date: 17 August 2019
CODEN: IIPRE
Correspondence Address: Sharma, G.; Xerox Corporation, Webster, NY 14580, United States; email: sharma@wrc.xerox.com},
author = {Sharma, G and Trussell, H J},
doi = {10.1109/83.597268},
isbn = {10577149 (ISSN)},
journal = {IEEE Transactions on Image Processing},
keywords = {Adaptive algorithms,Color image processing,Color perception,Digital image storage,Display devices,Imaging techniques,Mathematical models,Technological forecasting,Terminology,Vectors},
language = {English},
number = {7},
pages = {901--932},
title = {{Digital color imaging}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0031185364{\&}doi=10.1109{\%}2F83.597268{\&}partnerID=40{\&}md5=be045a2e9288e07b8dddfd518ed538f1 https://ieeexplore.ieee.org/document/597268/},
volume = {6},
year = {1997}
}
@article{Brainard2015,
abstract = {Summary A widely-viewed image of a dress elicits striking individual variation in colour perception. Experiments with multiple variants of the image suggest that the individual differences may arise through the action of visual mechanisms that normally stabilise object colour.},
author = {Brainard, David H and Hurlbert, Anya C},
doi = {https://doi.org/10.1016/j.cub.2015.05.020},
isbn = {0960-9822},
journal = {Current Biology},
number = {13},
pages = {R551--R554},
title = {{Colour Vision: Understanding {\#}TheDress}},
url = {http://www.sciencedirect.com/science/article/pii/S0960982215005941},
volume = {25},
year = {2015}
}
@misc{Jordan2018a,
address = {Salt Lake City, Utah},
author = {Jordan, Kari L and Corvellec, Marianne},
booktitle = {2018 ASEE Annual Conference {\&} Exposition},
title = {{Short-formatWorkshops Build Skills and Confidence for Researchers toWork with Data}},
year = {2018}
}
@article{Borner2019,
abstract = {In the information age, the ability to read and construct data visualizations becomes as important as the ability to read and write text. However, while standard definitions and theoretical frameworks to teach and assess textual, mathematical, and visual literacy exist, current data visualization literacy (DVL) definitions and frameworks are not comprehensive enough to guide the design of DVL teaching and assessment. This paper introduces a data visualization literacy framework (DVL-FW) that was specifically developed to define, teach, and assess DVL. The holistic DVL-FW promotes both the reading and construction of data visualizations, a pairing analogous to that of both reading and writing in textual literacy and understanding and applying in mathematical literacy. Specifically, the DVL-FW defines a hierarchical typology of core concepts and details the process steps that are required to extract insights from data. Advancing the state of the art, the DVL-FW interlinks theoretical and procedural knowledge and showcases how both can be combined to design curricula and assessment measures for DVL. Earlier versions of the DVL-FW have been used to teach DVL to more than 8,500 residential and online students, and results from this effort have helped revise and validate the DVL-FW presented here.},
author = {B{\"{o}}rner, Katy and Bueckle, Andreas and Ginda, Michael},
doi = {10.1073/pnas.1807180116},
journal = {Proceedings of the National Academy of Sciences},
number = {6},
pages = {1857},
title = {{Data visualization literacy: Definitions, conceptual frameworks, exercises, and assessments}},
url = {http://www.pnas.org/content/116/6/1857.abstract https://www.pnas.org/content/pnas/116/6/1857.full.pdf},
volume = {116},
year = {2019}
}
@article{Bresciani2015,
abstract = {A large body of research has addressed the benefits of visualization, whereas the analysis of the pitfalls has not received systematic attention. We aim to provide an overview of the common pitfalls and potential disadvantages of visual representations based on a multidisciplinary literature review. Subsequently, we develop a theoretically grounded classification of common cognitive, emotional, and social risks of visualization and populate it with a comprehensive list of visualization pitfalls. The aim of this research is not to diminish the potential of visualization, but rather to improve visual literacy by structuring our understanding of the possible limitations of graphic representations.},
author = {Bresciani, Sabrina and Eppler, Martin J},
doi = {10.1177/2158244015611451},
keywords = {visualization risks,visualization mistakes,disadva},
number = {4},
pages = {2158244015611451},
title = {{The Pitfalls of Visual Representations:A Review and Classification of Common Errors Made While Designing and Interpreting Visualizations}},
url = {https://journals.sagepub.com/doi/abs/10.1177/2158244015611451},
volume = {5},
year = {2015}
}
@article{Mills2015,
abstract = {The recent trend for journals to require open access to primary data included in publications has been embraced by many biologists, but has caused apprehension amongst researchers engaged in long-term ecological and evolutionary studies. A worldwide survey of 73 principal investigators (Pls) with long-term studies revealed positive attitudes towards sharing data with the agreement or involvement of the PI, and 93{\%} of PIs have historically shared data. Only 8{\%} were in favor of uncontrolled, open access to primary data while 63{\%} expressed serious concern. We present here their viewpoint on an issue that can have non-trivial scientific consequences. We discuss potential costs of public data archiving and provide possible solutions to meet the needs of journals and researchers.},
author = {Mills, James A and Teplitsky, C{\'{e}}line and Arroyo, Beatriz and Charmantier, Anne and Becker, Peter H and Birkhead, Tim R and Bize, Pierre and Blumstein, Daniel T and Bonenfant, Christophe and Boutin, Stan and Bushuev, Andrey and Cam, Emmanuelle and Cockburn, Andrew and C{\^{o}}t{\'{e}}, Steeve D and Coulson, John C and Daunt, Francis and Dingemanse, Niels J and Doligez, Blandine and Drummond, Hugh and Espie, Richard H M and Festa-Bianchet, Marco and Frentiu, Francesca and Fitzpatrick, John W and Furness, Robert W and Garant, Dany and Gauthier, Gilles and Grant, Peter R and Griesser, Michael and Gustafsson, Lars and Hansson, Bengt and Harris, Michael P and Jiguet, Fr{\'{e}}d{\'{e}}ric and Kjellander, Petter and Korpim{\"{a}}ki, Erkki and Krebs, Charles J and Lens, Luc and Linnell, John D C and Low, Matthew and McAdam, Andrew and Margalida, Antoni and Meril{\"{a}}, Juha and M{\o}ller, Anders P and Nakagawa, Shinichi and Nilsson, Jan-{\AA}ke and Nisbet, Ian C T and van Noordwijk, Arie J and Oro, Daniel and P{\"{a}}rt, Tomas and Pelletier, Fanie and Potti, Jaime and Pujol, Benoit and R{\'{e}}ale, Denis and Rockwell, Robert F and Ropert-Coudert, Yan and Roulin, Alexandre and Sedinger, James S and Swenson, Jon E and Th{\'{e}}baud, Christophe and Visser, Marcel E and Wanless, Sarah and Westneat, David F and Wilson, Alastair J and Zedrosser, Andreas},
doi = {https://doi.org/10.1016/j.tree.2015.07.006},
isbn = {0169-5347},
journal = {Trends in Ecology {\&} Evolution},
number = {10},
pages = {581--589},
title = {{Archiving Primary Data: Solutions for Long-Term Studies}},
url = {http://www.sciencedirect.com/science/article/pii/S0169534715001858 https://pdf.sciencedirectassets.com/271938/1-s2.0-S0169534714X00224/1-s2.0-S0169534715001858/main.pdf?X-Amz-Security-Token=AgoJb3JpZ2luX2VjEAoaCXVzLWVhc3QtMSJIMEYCIQD3JOLQaKmqLiNhfHQxD7bQS},
volume = {30},
year = {2015}
}
@article{White2013,
author = {White, Ethan and Baldridge, Elita and Brym, Zachary and Locey, Kenneth and McGlinn, Daniel and Supp, Sarah},
doi = {10.4033/iee.2013.6b.6.f},
isbn = {19183178},
journal = {Ideas in Ecology and Evolution},
number = {2},
title = {{Nine simple ways to make it easier to (re)use your data}},
volume = {6},
year = {2013}
}
@article{Milne2002,
abstract = {We have conducted a web-based questionnaire on the various concepts and topics of object-oriented programming that students on introductory courses found most difficult to cope with. A statistical analysis of our results shows that those topics that rely on a clear understanding of pointers and memory-related concepts (such as copy constructors and virtual functions) prove to be the most difficult. In other words, we believe these concepts are only hard because of the student's inability to comprehend what is happening to their program in memory, as they are incapable of creating a clear mental model of its execution. These results would suggest that a clearer approach to teaching these topics would be beneficial to students. We are currently working on a visualization-based approach to address these issues. {\textcopyright} 2002 Kluwer Academic Publishers.},
annote = {Cited By :134
Export Date: 20 July 2018
Correspondence Address: Milne, I.; Department of Applied Computing, University of Dundee, Dundee, DD1 4HN, United Kingdom; email: imilne@computing.dundee.ac.uk},
author = {Milne, I and Rowe, G},
doi = {10.1023/A:1015362608943},
isbn = {13602357 (ISSN)},
journal = {Education and Information Technologies},
keywords = {Novices,Object-orientation,Programming,Programming difficulties,Software visualization},
language = {English},
number = {1},
pages = {55--66},
publisher = {Kluwer Academic Publishers},
title = {{Difficulties in learning and teaching programming - Views of students and tutors}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-11144283135{\&}doi=10.1023{\%}2FA{\%}3A1015362608943{\&}partnerID=40{\&}md5=05f54e2573a8597ab75b2ed103dbd6b9 https://link.springer.com/content/pdf/10.1023{\%}2FA{\%}3A1015362608943.pdf},
volume = {7},
year = {2002}
}
@book{Munzner2015b,
address = {Boca Raton},
annote = {2014020715
Tamara Munzner, Department of Computer Science, University of British Columbia.
25 cm
"An A K Peters Book."
Includes bibliographical references (pages 373-395) and indexes.},
author = {Munzner, Tamara},
booktitle = {A K Peters visualization series},
isbn = {9781466508910 (Pack - Book and Ebook acid-free paper)},
keywords = {Information visualization.},
pages = {xxiii, 404 pages},
pmid = {18165423},
publisher = {CRC Press, Taylor {\&} Francis Group},
title = {{Visualization analysis and design}},
year = {2015}
}
@article{Barone2017,
abstract = {In a 2016 survey of 704 National Science Foundation (NSF) Biological Sciences Directorate principal investigators (BIO PIs), nearly 90{\%} indicated they are currently or will soon be analyzing large data sets. BIO PIs considered a range of computational needs important to their work, including high performance computing (HPC), bioinformatics support, multistep workflows, updated analysis software, and the ability to store, share, and publish data. Previous studies in the United States and Canada emphasized infrastructure needs. However, BIO PIs said the most pressing unmet needs are training in data integration, data management, and scaling analyses for HPC—acknowledging that data science skills will be required to build a deeper understanding of life. This portends a growing data knowledge gap in biology and challenges institutions and funding agencies to redouble their support for computational training in biology. {\textcopyright} 2017 Barone et al.},
annote = {Cited By :19
Export Date: 15 July 2019
Correspondence Address: Barone, L.; DNA Learning Center, Cold Spring Harbor LaboratoryUnited States; email: lbarone@cshl.edu},
author = {Barone, L and Williams, J and Micklos, D},
doi = {10.1371/journal.pcbi.1005755},
isbn = {1553734X (ISSN)},
journal = {PLOS Computational Biology},
keywords = {Article,Canada,Computational Biology,Databases, Genetic,Humans,Research Personnel,United States,bioinformatics,biology,data analysis software,data processing,genetic database,high performance computing,human,human needs,information processing,knowledge,mathematical computing,miscellaneous named groups,non profit organization,personnel,principal investigator,short survey,statistics and numerical data,work,workflow},
language = {English},
number = {10},
publisher = {Public Library of Science},
title = {{Unmet needs for analyzing biological big data: A survey of 704 NSF principal investigators}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032435239{\&}doi=10.1371{\%}2Fjournal.pcbi.1005755{\&}partnerID=40{\&}md5=91fd69796261a23e3e0f0598018f7938 https://journals.plos.org/ploscompbiol/article/file?id=10.1371/journal.pcbi.1005755{\&}type=printable},
volume = {13},
year = {2017}
}
@article{Greeno1994,
abstract = {J. J. Gibson (see PA, Vol 29:5103; see also PA, Vol 81:28168) developed an interactionist view of perception and action that focused on information that is available in the environment. He thereby rejected the still-prevalent framing assumption of factoring external-physical and internal-mental processes. The interactionist alternative, which focuses on processes of agent–situation interactions, is taken in ecological psychology as well as in recent research on conversational communication, research on complex, socially organized activity, and philosophical situation theory. The concepts of affordance and ability are key ideas in an interactionist account. In situation theory, abilities in activity depend on attunements to constraints, and affordances for an agent can be understood as conditions in the environment for constraints to which the agent is attuned. This broad view of affordances includes affordances that are recognized as well as affordances that are perceived directly. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
address = {US},
author = {Greeno, James G},
doi = {10.1037/0033-295X.101.2.336},
isbn = {1939-1471(Electronic),0033-295X(Print)},
journal = {Psychological Review},
keywords = {*Apparent Movement,*Motion Perception,Visual Perception},
number = {2},
pages = {336--342},
publisher = {American Psychological Association},
title = {{Gibson's affordances}},
volume = {101},
year = {1994}
}
@inproceedings{Ankerst1998,
abstract = {The order and arrangement of dimensions (variates) in crucial for the effectiveness of a large number of visualization techniques such as parallel coordinates, scatterplots, recursive pattern, and many others. In this paper, we describe a systematic approach to arrange the dimensions according to their similarity. The basic idea is to rearrange the data dimensions such that dimensions showing a similar behavior are positioned next to each other. For the similarity clustering of dimensions we need to define similarity measures which determine the partial or global similarity of dimensions. We then consider the problem of finding an optimal one- or two-dimensional arrangement of the dimensions based on their similarity. Theoretical considerations show that both, the one- and the two-dimensional arrangement problem are surprisingly hard problems, i.e. they are NP-complete. Our solution of the problem is therefore based on heuristic algorithms. An empirical evaluation using a number of different visualization techniques shows the high impact of our similarity clustering of dimensions on the visualization results.},
address = {Piscataway, NJ, United States},
annote = {Cited By :163
Export Date: 22 August 2019
CODEN: 00221
Correspondence Address: Ankerst, Mihael; Univ of Munich, Munich, Germany},
author = {Ankerst, Mihael and Berchtold, Stefan and Keim, Daniel A},
keywords = {Algorithms,Computational complexity,Data dimensions,Data structures,Heuristic methods,Problem solving,Recursive functions,Similarity clustering,Sorting,Two dimensional,Visualization},
language = {English},
pages = {52--60},
publisher = {IEEE},
title = {{Similarity clustering of dimensions for an enhanced visualization of multidimensional data}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0032304703{\&}partnerID=40{\&}md5=5a87bfbf50a374da9fe004bd74dc93d3},
year = {1998}
}
@article{MacLeod1979,
abstract = {In a space where Cartesian coordinates represent the excitations of the three cone types involved in color vision, a plane of constant luminance provides a chromaticity diagram in which excitation of each cone type (at constant luminance) is represented by a linear scale (horizontal or vertical), and in which the center-of-gravity rule applies with weights proportional to luminance.},
annote = {Cited By :648
Export Date: 14 January 2019},
author = {MacLeod, D I and Boynton, R M},
doi = {10.1364/JOSA.69.001183},
journal = {Journal of the Optical Society of America},
number = {8},
pages = {1183--1186},
title = {{Chromaticity diagram showing cone excitation by stimuli of equal luminance}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0018508110{\&}doi=10.1364{\%}2FJOSA.69.001183{\&}partnerID=40{\&}md5=8998edca61498f4c30708aa09fc1e3e6},
volume = {69},
year = {1979}
}
@article{Kolb2013,
abstract = {ABSTRACT Proper data management (applying coordinated standards and structures to data collection, maintenance, retrieval, and documentation) is essential for complex projects to ensure data accuracy and accessibility. In this article, we used a recent project evaluating changes in Lake Whitefish (Coregonus clupeaformis) growth, condition, and recruitment in the Great Lakes as a case study to illustrate how thoughtful data management approaches can enhance and improve research. Data management best practices described include dedicating personnel to data curation, setting data standards, building a relational database, managing data updates, checking for and trapping errors, extracting data, documenting data sets, and coordinating with project collaborators. The data management actions taken ultimately resulted in a rich body of scientific publication and a robust database available for future studies. Investing in data management allowed this project to serve as a model for taking the first steps toward a common goal of sharing, documenting, and preserving data that are collected and reported during the scientific research process.},
author = {Kolb, Tracy L and Blukacz-Richards, E Agnes and Muir, Andrew M and Claramunt, Randall M and Koops, Marten A and Taylor, William W and Sutton, Trent M and Arts, Michael T and Bissel, Ed},
doi = {10.1080/03632415.2013.757975},
isbn = {0363-2415},
journal = {Fisheries},
number = {2},
pages = {52--64},
publisher = {Taylor {\&} Francis},
title = {{How to Manage Data to Enhance Their Potential for Synthesis, Preservation, Sharing, and Reuse—A Great Lakes Case Study}},
url = {https://doi.org/10.1080/03632415.2013.757975 https://afspubs.onlinelibrary.wiley.com/doi/pdf/10.1080/03632415.2013.757975},
volume = {38},
year = {2013}
}
@inproceedings{Lahtinen2005,
abstract = {Programming is related to several fields of technology, and many university students are studying the basics of it. Unfortunately, they often face difficulties already on the basic courses. This work studies the difficulties in learning programming in order to support developing learning materials for basic programming courses. The difficulties have to be recognized to be able to aid learning and teaching in an effective way. An international survey of opinions was organized for more than 500 students and teachers. This paper analyses the results of the survey. The survey provides information of the difficulties experienced and perceived when learning and teaching programming. The survey results also provide basis for recommendations for developing learning materials and approaches. Copyright 2005 ACM.},
annote = {Cited By :300
Export Date: 20 July 2018
Correspondence Address: Lahtinen, E.; Tampere University of Technology, Institute of Software Systems, P.O. Box 553, FIN-33101 Tampere, Finland; email: essi.lahtinen@tut.fi},
author = {Lahtinen, E and Ala-Mutka, K and J{\"{a}}rvinen, H M},
doi = {10.1145/1067445.1067453},
isbn = {1595930248 (ISBN); 9781595930248 (ISBN)},
keywords = {Computer programming,Curricula,Learning,Learning systems,Novices,Programming,Students,Teaching,Teaching, difficulties},
language = {English},
pages = {14--18},
title = {{A study of the difficulties of novice programmers}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-29844444452{\&}doi=10.1145{\%}2F1067445.1067453{\&}partnerID=40{\&}md5=deeb1fc9de05a222cba20e24db630602 https://dl.acm.org/citation.cfm?doid=1067445.1067453},
year = {2005}
}
@article{DunnJr2016,
abstract = {Objective A memory clinic at an academic medical center has relied on several ad hoc data capture systems including Microsoft Access and Excel for cognitive assessments over the last several years. However these solutions are challenging to maintain and limit the potential of hypothesis-driven or longitudinal research. REDCap, a secure web application based on PHP and MySQL, is a practical solution for improving data capture and organization. Here, we present a workflow and toolset to facilitate legacy data migration and real-time clinical research data collection into REDCap as well as challenges encountered. Materials and methods Legacy data consisted of neuropsychological tests stored in over 4000 Excel workbooks. Functions for data extraction, norm scoring, converting to REDCap-compatible formats, accessing the REDCap API, and clinical report generation were developed and executed in Python. Results Over 400 unique data points for each workbook were migrated and integrated into our REDCap database. Moving forward, our REDCap-based system replaces the Excel-based data collection method as well as eases the integration into the standard clinical research workflow and Electronic Health Record. Conclusion In the age of growing data, efficient organization and storage of clinical and research data is critical for advancing research and providing efficient patient care. We believe that the workflow and tools described in this work to promote legacy data integration as well as real time data collection into REDCap ultimately facilitate these goals. {\textcopyright} 2016},
address = {Department of Neurology, Emory University, Atlanta, GA, United States Department of Biomedical Informatics, Emory University, Atlanta, GA, United States College of Computing, Georgia Institute of Technology, Atlanta, GA, United States},
annote = {Export Date: 17 November 2017 CODEN: IJMIF Correspondence Address: Gutman, D.A.; Department of Neurology, Emory UniversityUnited States; email: dgutman@emory.edu},
author = {{Dunn Jr}, W D and Cobb, J and Levey, A I and Gutman, D A},
doi = {10.1016/j.ijmedinf.2016.06.015},
edition = {2016/07/12},
isbn = {1872-8243 (Electronic)1386-5056 (Linking)},
journal = {International Journal of Medical Informatics},
keywords = {Biomedical informatics Clinical informatics Clinic},
language = {English},
pages = {103--110},
pmid = {27396629},
title = {{REDLetr: Workflow and tools to support the migration of legacy clinical data capture systems to REDCap}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84990985993{\&}doi=10.1016{\%}2Fj.ijmedinf.2016.06.015{\&}partnerID=40{\&}md5=d53f5de54f68d6740c751a65a58aa834 https://www.sciencedirect.com/science/article/pii/S1386505616301447?via{\%}3Dihub},
volume = {93},
year = {2016}
}
@techreport{Burton2018,
author = {Burton, Matt and Lyon, Liz and Erdmann, Chris and Tijerina, Bonnie},
pages = {25},
title = {{Shifting to Data Savvy: The Future of Data Science in Libraries}},
year = {2018}
}
@incollection{Grolemund2017a,
author = {Grolemund, Garrett and Wickham, Hadley},
booktitle = {R for Data Science},
title = {{Tibbles with tibble}},
year = {2017}
}
@incollection{Ware2013,
abstract = {"This is a book about what the science of perception can tell us about visualization. There is a gold mine of information about how we see to be found in more than a century of work by vision researchers. The purpose of this book is to extract from that large body of research literature those design principles that apply to displaying information effectively"--},
address = {Waltham, MA},
annote = {2012009489
Colin Ware.
illustrations (some color) ; 25 cm.
Includes bibliographical references (pages [459]-496) and index.
Machine generated contents note: Chapter 1. Foundations for an Applied Science of Data Visualization Chapter 2. The Environment, Optics, Resolution, and the Display Chapter 3. Lightness, Brightness, Contrast and Constancy Chapter 4. Color Chapter 5. Visual Salience and Finding Information Chapter 6. Static and Moving Patterns Chapter 7. Space Perception Chapter 8. Visual Objects and Data Objects Chapter 9. Images, Narrative, and Gestures for Explanation Chapter 10. Interacting with Visualizations Chapter 11. Visual Thinking Processes.},
author = {Ware, Colin},
booktitle = {Information visualization: perception for design},
edition = {Third edit},
isbn = {9780123814647 (hardback)},
keywords = {Information visualization.,Visual perception.,Visualization.},
pages = {95--138},
pmid = {17195003},
publisher = {Morgan Kaufmann},
title = {{Color}},
year = {2013}
}
@article{Brinker2018,
abstract = {Study Design. A bibliometric analysis. Objective. The aim of this article was to study bibliometric changes over the last 30 years of Spine. These trends are important regarding academic publication productivity. Summary of Background Data. Inflation in authorship number and other bibliometric variables has been described in the scientific literature. The issue of author gender is taking on increasing importance, as efforts are being made to close the gender gap. Methods. From 1985 to 2015, 10-year incremental data for several bibliometric variables were collected, including author gender. Standard bivariate statistical analyses were performed. Trends over time were assessed by the Cochran linear trend. A P{\textless}0.05 was considered statistically significant. Results. Inclusion criteria were met for 1566 manuscripts. The majority of the manuscripts were from North America (51.2{\%}), Europe (25.2{\%}), and Asia (20.8{\%}). The number of manuscripts, authors, countries, pages, and references all increased from 1985 to 2015. There was a slight increase in female first authors over time (17.5{\%} to 18.4{\%}, P=0.048). There was no gender change over time for corresponding authors (14.3{\%} to 14.0{\%}, P=0.29). There was an 88{\%} increase in the percentage of female first authors having male corresponding authors (P=0.00004), and a 123{\%} increase in male first authors having female corresponding authors (P=0.0002). The 14{\%} to 18{\%} of female authors in Spine is higher than the ∼5{\%} female membership of the Scoliosis Research Society and North American Spine Society. Conclusion. Manuscripts in Spine over the past 30 years have shown a significant increase in the number of authors, collaborating institutions and countries, printed pages, references, and number of times each manuscript was cited. There has been a mild increase in female first authorship, but none in corresponding authorship. Increases in female authorship will likely require recruitment of more females into the discipline rather than providing females in the discipline with authorship opportunities. Level of Evidence: N/A . Copyright {\textcopyright} 2018 Wolters Kluwer Health, Inc. All rights reserved.},
annote = {Export Date: 1 November 2018
CODEN: SPIND
Correspondence Address: Loder, R.T.; Department of Orthopaedic Surgery, Indiana University School of Medicine, James Whitcomb Riley Children's Hospital, 705 Riley Hospital Drive, ROC 4250, United States; email: rloder@iupui.edu},
author = {Brinker, A R and Liao, J L and Kraus, K R and Young, J and Sandelski, M and Mikesell, C and Robinson, D and Adjei, M and Lunsford, S D and Fischer, J and Kacena, M A and Whipple, E C and Loder, R T},
doi = {10.1097/BRS.0000000000002562},
isbn = {03622436 (ISSN)},
journal = {Spine},
keywords = {Review,Spine,authorship,bibliometric,bibliometrics,change,female,gender,geographic region,human,male,mentorship,priority journal,publication,sex difference,time,trends,writing},
language = {English},
number = {14},
pages = {E849--E854},
publisher = {Lippincott Williams and Wilkins},
title = {{Bibliometric analysis of gender authorship trends and collaboration dynamics over 30 years of spine 1985 to 2015}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85050243594{\&}doi=10.1097{\%}2FBRS.0000000000002562{\&}partnerID=40{\&}md5=e4d7ec668f4afb571472fa1f17e6cb4b},
volume = {43},
year = {2018}
}
@article{Scarr2012,
abstract = {Spatial memory is an important facet of human cognition - it allows users to learn the locations of items over time and retrieve them with little effort. In human-computer interfaces, knowledge of the spatial location of controls can enable a user to interact fluidly and efficiently, without needing to perform slow visual search. Computer interfaces should therefore be designed to provide support for developing the user's spatial memory, and they should allow the user to exploit it for rapid interaction whenever possible. However, existing systems offer varying support for spatial memory. Many break the user's ability to remember spatial locations, by moving or re-arranging items; others leave spatial memory underutilised, requiring slow sequences of mechanical actions to select items rather than exploiting users' strong ability to index items and controls by their on-screen locations. The aim of this paper is to highlight the importance of designing for spatial memory in HCI. To do this, we examine the literature using an abstract-to-concrete approach. First, we identify important psychological models that underpin our understanding of spatial memory, and differentiate between navigation and object-location memory (with this review focusing on the latter). We then summarise empirical results on spatial memory from both the psychology and HCI domains, identifying a set of observable properties of spatial memory that can be used to inform design. Finally, we analyse existing interfaces in the HCI literature that support or disrupt spatial memory, including space-multiplexed displays for command and navigation interfaces, different techniques for dealing with large spatial data sets, and the effects of spatial distortion. We intend for this paper to be useful to user interface designers, as well as other HCI researchers interested in spatial memory. Throughout the text, we therefore emphasise important design guidelines derived from the work reviewed, as well as methodological issues and topics for future research.},
annote = {Cited By :27
Export Date: 6 July 2019
Correspondence Address: Scarr, J.; University of CanterburyNew Zealand; email: joey@cosc.canterbury.ac.nz},
author = {Scarr, J and Cockburn, A and Gutwin, C},
doi = {10.1561/1100000046},
isbn = {15513955 (ISSN)},
journal = {Foundations and Trends in Human-Computer Interaction},
keywords = {Abstracting,Existing systems,Human computer interfaces,Interface designers,Mechanical action,Navigation interface,Psychological model,Spatial datasets,Spatial distortion,User interfaces},
language = {English},
number = {1},
pages = {1--84},
title = {{Supporting and exploiting spatial memory in user interfaces}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84890699350{\&}doi=10.1561{\%}2F1100000046{\&}partnerID=40{\&}md5=e5d347eca815c502365a403d0097f7bb},
volume = {6},
year = {2012}
}
@misc{Yau2013b,
address = {Indianapolis, IN},
author = {Yau, Nathan},
isbn = {9781118462195 (pbk.)111846219X (pbk.)},
keywords = {Electronic books.,Graphic methods.,Information visualization.},
pages = {xiii, 300 pages},
publisher = {John Wiley {\&} Sons, Inc.},
title = {{Data points visualization that means something}},
year = {2013}
}
@article{Kaplan2018,
abstract = {ABSTRACT?Data science? is a useful catchword for methods and concepts original to the field of statistics, but typically being applied to large, multivariate, observational records. Such datasets call for techniques not often part of an introduction to statistics: modeling, consideration of covariates, sophisticated visualization, and causal reasoning. This article re-imagines introductory statistics as an introduction to data science and proposes a sequence of 10 blocks that together compose a suitable course for extracting information from contemporary data. Recent extensions to the mosaic packages for R together with tools from the ?tidyverse? provide a concise and readable notation for wrangling, visualization, model-building, and model interpretation: the fundamental computational tasks of data science.},
author = {Kaplan, Daniel},
doi = {10.1080/00031305.2017.1398107},
isbn = {0003-1305},
journal = {The American Statistician},
number = {1},
pages = {89--96},
publisher = {Taylor {\&} Francis},
title = {{Teaching Stats for Data Science}},
url = {https://doi.org/10.1080/00031305.2017.1398107 https://www.tandfonline.com/doi/pdf/10.1080/00031305.2017.1398107?needAccess=true},
volume = {72},
year = {2018}
}
@incollection{Few2012c,
author = {Few, Stephen},
booktitle = {Show me the numbers : designing tables and graphs to enlighten},
edition = {2nd},
isbn = {978-0970601971},
keywords = {Business presentations Charts, diagrams, etc.,Business presentations Graphic methods.,Graphic methods.},
pages = {pages 61 -- 85},
publisher = {Analytics Press},
title = {{Visual Perception and Graphical Communication}},
year = {2012}
}
@article{Foster2011,
abstract = {A quarter of a century ago, the first systematic behavioral experiments were performed to clarify the nature of color constancy—the effect whereby the perceived color of a surface remains constant despite changes in the spectrum of the illumination. At about the same time, new models of color constancy appeared, along with physiological data on cortical mechanisms and photographic colorimetric measurements of natural scenes. Since then, as this review shows, there have been many advances. The theoretical requirements for constancy have been better delineated and the range of experimental techniques has been greatly expanded; novel invariant properties of images and a variety of neural mechanisms have been identified; and increasing recognition has been given to the relevance of natural surfaces and scenes as laboratory stimuli. Even so, there remain many theoretical and experimental challenges, not least to develop an account of color constancy that goes beyond deterministic and relatively simple laboratory stimuli and instead deals with the intrinsically variable nature of surfaces and illuminations present in the natural world.},
author = {Foster, David H},
doi = {https://doi.org/10.1016/j.visres.2010.09.006},
isbn = {0042-6989},
journal = {Vision Research},
keywords = {Achromatic adjustment,Asymmetric color matching,Chromatic adaptation,Color appearance,Color constancy,Color naming,Color-constancy indices,Illuminant estimation,Natural scene statistics,Relational color constancy,Spatial ratios of cone excitations,Spectral basis functions,Surface color,Von Kries coefficient},
number = {7},
pages = {674--700},
title = {{Color constancy}},
url = {http://www.sciencedirect.com/science/article/pii/S0042698910004402},
volume = {51},
year = {2011}
}
@techreport{Holdren2013,
author = {Holdren, John P},
pages = {6},
title = {{Increasing Access to the Results of Federally Funded Scientific Research}},
url = {https://obamawhitehouse.archives.gov/sites/default/files/microsites/ostp/ostp{\_}public{\_}access{\_}memo{\_}2013.pdf},
year = {2013}
}
@inproceedings{Lee2006,
address = {Venezia, Italy},
author = {Lee, Bongshin and Plaisant, Catherine and Sims, Cyhthia and Fekete, Jean-Daniel and Henry, Nathalie},
booktitle = {BELIV '06: AVI workshop on BEyond time and errors},
title = {{Task taxonomy for graph visualization}},
year = {2006}
}
@article{Wolfe1994,
abstract = {An important component of routine visual behavior is the ability to find one item in a visual world filled with other, distracting items. This ability to perform visual search has been the subject of a large body of research in the past 15 years. This paper reviews the visual search literature and presents a model of human search behavior. Built upon the work of Neisser, Treisman, Julesz, and others, the model distinguishes between a preattentive, massively parallel stage that processes information about basic visual features (color, motion, various depth cues, etc.) across large portions of the visual field and a subsequent limited-capacity stage that performs other, more complex operations (e.g., face recognition, reading, object identification) over a limited portion of the visual field. The spatial deployment of the limited-capacity process is under attentional control. The heart of the guided search model is the idea that attentional deployment of limited resources is guided by the output of the earlier parallel processes. Guided Search 2.0 (GS2) is a revision of the model in which virtually all aspects of the model have been made more explicit and/or revised in light of new data. The paper is organized into four parts: Part 1 presents the model and the details of its computer simulation. Part 2 reviews the visual search literature on preattentive processing of basic features and shows how the GS2 simulation reproduces those results. Part 3 reviews the literature on the attentional deployment of limited-capacity processes in conjunction and serial searches and shows how the simulation handles those conditions. Finally, Part 4 deals with shortcomings of the model and unresolved issues. {\textcopyright} 1994 Psychonomic Society, Inc.},
annote = {Cited By :2275
Export Date: 9 February 2019},
author = {Wolfe, J M},
doi = {10.3758/BF03200774},
journal = {Psychonomic Bulletin {\&} Review},
number = {2},
pages = {202--238},
title = {{Guided Search 2.0 A revised model of visual search}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84864888849{\&}doi=10.3758{\%}2FBF03200774{\&}partnerID=40{\&}md5=67951ee6d78f8792c91cba2608d79fdb},
volume = {1},
year = {1994}
}
@article{McGuffin2012,
author = {McGuffin, Michael J},
chapter = {383},
doi = {10.1109/tst.2012.6297585},
isbn = {1007-0214},
journal = {Tsinghua Science and Technology},
number = {4},
pages = {383--398},
title = {{Simple algorithms for network visualization: A tutorial}},
volume = {17},
year = {2012}
}
@inproceedings{Lister2004,
abstract = {A study by a ITiCSE 2001 working group ("the McCracken Group") established that many students do not know how to program at the conclusion of their introductory courses. A popular explanation for this incapacity is that the students lack the ability to problem-solve. That is, they lack the ability to take a problem description, decompose it into sub-problems and implement them, then assemble the pieces into a complete solution. An alternative explanation is that many students have a fragile grasp of both basic programming principles and the ability to systematically carry out routine programming tasks, such as tracing (or "desk checking") through code. This ITiCSE 2004 working group studied the alternative explanation, by testing students from seven countries, in two ways. First, students were tested on their ability to predict the outcome of executing a short piece of code. Second, students were tested on their ability, when given the desired function of short piece of near-complete code, to select the correct completion of the code from a small set of possibilities. Many students were weak at these tasks, especially the latter task, suggesting that such students have a fragile grasp of skills that are a prerequisite for problem-solving.},
annote = {Cited By :89
Export Date: 20 July 2018
Correspondence Address: Lister, R.; Faculty of Information Technology, University of Technology, Sydney Broadway, NSW 2007, Australia; email: raymond@it.uts.edu.au},
author = {Lister, R and Adams, E S and Fitzgerald, S and Fone, W and Hamer, J and Lindholm, M and McCartney, R and Mostr{\"{o}}m, J E and Sanders, K and Sepp{\"{a}}l{\"{a}}, O and Simon, B and Thomas, L},
doi = {10.1145/1044550.1041673},
keywords = {Complete solutions,Computer science,Desk checking,Education computing,Engineering education,Engineering research,Innovation,Introductory course,Know-how,Novice programmer,Problem description,Problem solving,Programming principles,Programming tasks,Students,Sub-problems,Teaching,Working groups},
language = {English},
pages = {119--150},
title = {{A multi-national study of reading and tracing skills in novice programmers}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77953844520{\&}doi=10.1145{\%}2F1044550.1041673{\&}partnerID=40{\&}md5=654a116b2e483fb01258419fd521d38a https://dl.acm.org/citation.cfm?doid=1044550.1041673},
year = {2004}
}
@incollection{Benevento2015,
address = {Lexington, MA},
author = {Benevento, Daniel and Rowell, Katherine S},
booktitle = {The Best Boring Book Ever of Tableau for Healthcare},
publisher = {Breviloquent},
title = {{Bar Charts}},
year = {2015}
}
@inproceedings{Lee2017,
abstract = {As a summer camp for middle school and high school students, a new method of learning/teaching computer science was explored: Teaching high schoolers MIT's App Inventor for 2 weeks and then during the following two weeks, having the high schoolers teach middle schoolers ranging from upcoming 6th to 9th graders. The program, App Inventor, simplifies the process of coding, making it an ideal method of teaching beginners the basics of computer programming and computational thinking practice. The simplicity of the program is evident through the rapid learning process of the high schoolers, who were mostly beginners at coding. Additionally, during the process of teaching and helping the middle schooler's debugging session, the high school students were able to properly digest the principles and fundamentals of computer programming by revisiting and teaching what they learned. The students, both the high schoolers and middle schoolers, collaborated in exploring and experimenting with multiple variations of apps that could be made with the given teaching materials. The level of comprehension amongst the middle schoolers was evident through their ability to produce the final products, which ultimately varied depending upon the method of teaching that the high schooler chose to teach with. This paper presents the organization of the summer programming camp, contents and learning outcome. {\textcopyright} 2016 IEEE.},
annote = {Export Date: 20 July 2018},
author = {Lee, J and Jun, S and Kim, K and Yoon, I},
doi = {10.1109/CSCI.2016.0062},
editor = {Yang, M and Arabnia, H R and Deligiannidis, L and Deligiannidis, L},
isbn = {9781509055104 (ISBN)},
keywords = {App Inventor,Application programs,Artificial intelligence,Computational thinkings,Computer debugging,Computer programming,Computing Education,E-learning,Education,High school students,High school students teach middle school students,Method of learning,Middle school students,Students,Teaching materials,learning by teaching,summer camp},
language = {English},
pages = {287--292},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Summer programming boot camp, teach high schoolers first and let them teach middle schoolers}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85017322043{\&}doi=10.1109{\%}2FCSCI.2016.0062{\&}partnerID=40{\&}md5=c71ed5b02b4059b6f00c8ecc0f4243ec https://ieeexplore.ieee.org/ielx7/7879541/7881293/07881355.pdf?tp={\&}arnumber=7881355{\&}isnumber=7881293},
year = {2017}
}
@article{Wilkinson2016,
abstract = {There is an urgent need to improve the infrastructure supporting the reuse of scholarly data. A diverse set of stakeholders-representing academia, industry, funding agencies, and scholarly publishers-have come together to design and jointly endorse a concise and measureable set of principles that we refer to as the FAIR Data Principles. The intent is that these may act as a guideline for those wishing to enhance the reusability of their data holdings. Distinct from peer initiatives that focus on the human scholar, the FAIR Principles put specific emphasis on enhancing the ability of machines to automatically find and use the data, in addition to supporting its reuse by individuals. This Comment is the first formal publication of the FAIR Principles, and includes the rationale behind them, and some exemplar implementations in the community.},
annote = {Wilkinson, Mark D
Dumontier, Michel
Aalbersberg, I Jsbrand Jan
Appleton, Gabrielle
Axton, Myles
Baak, Arie
Blomberg, Niklas
Boiten, Jan-Willem
da Silva Santos, Luiz Bonino
Bourne, Philip E
Bouwman, Jildau
Brookes, Anthony J
Clark, Tim
Crosas, Merce
Dillo, Ingrid
Dumon, Olivier
Edmunds, Scott
Evelo, Chris T
Finkers, Richard
Gonzalez-Beltran, Alejandra
Gray, Alasdair J G
Groth, Paul
Goble, Carole
Grethe, Jeffrey S
Heringa, Jaap
't Hoen, Peter A C
Hooft, Rob
Kuhn, Tobias
Kok, Ruben
Kok, Joost
Lusher, Scott J
Martone, Maryann E
Mons, Albert
Packer, Abel L
Persson, Bengt
Rocca-Serra, Philippe
Roos, Marco
van Schaik, Rene
Sansone, Susanna-Assunta
Schultes, Erik
Sengstag, Thierry
Slater, Ted
Strawn, George
Swertz, Morris A
Thompson, Mark
van der Lei, Johan
van Mulligen, Erik
Velterop, Jan
Waagmeester, Andra
Wittenburg, Peter
Wolstencroft, Katherine
Zhao, Jun
Mons, Barend
eng
BB/E025080/1/Biotechnology and Biological Sciences Research Council/United Kingdom
BB/I000771/1/Biotechnology and Biological Sciences Research Council/United Kingdom
U24 DA039832/DA/NIDA NIH HHS/
England
Sci Data. 2016 Mar 15;3:160018. doi: 10.1038/sdata.2016.18.
https://www.force11.org/fairprinciples for current versions},
author = {Wilkinson, M D and Dumontier, M and Aalbersberg, I J and Appleton, G and Axton, M and Baak, A and Blomberg, N and Boiten, J W and {da Silva Santos}, L B and Bourne, P E and Bouwman, J and Brookes, A J and Clark, T and Crosas, M and Dillo, I and Dumon, O and Edmunds, S and Evelo, C T and Finkers, R and Gonzalez-Beltran, A and Gray, A J and Groth, P and Goble, C and Grethe, J S and Heringa, J and t Hoen, P A and Hooft, R and Kuhn, T and Kok, R and Kok, J and Lusher, S J and Martone, M E and Mons, A and Packer, A L and Persson, B and Rocca-Serra, P and Roos, M and van Schaik, R and Sansone, S A and Schultes, E and Sengstag, T and Slater, T and Strawn, G and Swertz, M A and Thompson, M and van der Lei, J and van Mulligen, E and Velterop, J and Waagmeester, A and Wittenburg, P and Wolstencroft, K and Zhao, J and Mons, B},
doi = {10.1038/sdata.2016.18},
edition = {2016/03/16},
isbn = {2052-4463 (Electronic)2052-4463 (Linking)},
journal = {Sci Data},
keywords = {*Data Collection,*Data Curation,*Research Design,Database Management Systems,Guidelines as Topic,Reproducibility of Results},
pages = {160018},
pmid = {26978244},
title = {{The FAIR Guiding Principles for scientific data management and stewardship}},
url = {https://www.ncbi.nlm.nih.gov/pubmed/26978244},
volume = {3},
year = {2016}
}
@article{Rodriguez-Iglesias2016,
abstract = {Pathogen-Host interaction data is core to our understanding of disease processes and their molecular/genetic bases. Facile access to such core data is particularly important for the plant sciences, where individual genetic and phenotypic observations have the added complexity of being dispersed over a wide diversity of plant species versus the relatively fewer host species of interest to biomedical researchers. Recently, an international initiative interested in scholarly data publishing proposed that all scientific data should be “FAIR” - Findable, Accessible, Interoperable, and Reusable. In this work, we describe the process of migrating a database of notable relevance to the plant sciences - the Pathogen-Host Interaction Database (PHI-base) - to a form that conforms to each of the FAIR Principles. We discuss the technical and architectural decisions, and the migration pathway, including observations of the difficulty and/or fidelity of each step. We examine how multiple FAIR principles can be addressed simultaneously through careful design decisions, including making data FAIR for both humans and machines with minimal duplication of effort. We note how FAIR data publishing involves more than data reformatting, requiring features beyond those exhibited by most life science Semantic Web or Linked Data resources. We explore the value-added by completing this FAIR data transformation, and then test the result through integrative questions that could not easily be asked over traditional Web-based data resources. Finally, we demonstrate the utility of providing explicit and reliable access to provenance information, which we argue enhances citation rates by encouraging and facilitating transparent scholarly reuse of these valuable data holdings.},
author = {Rodr{\'{i}}guez-Iglesias, Alejandro and Rodr{\'{i}}guez-Gonz{\'{a}}lez, Alejandro and Irvine, Alistair G and Sesma, Ane and Urban, Martin and Hammond-Kosack, Kim E and Wilkinson, Mark D},
isbn = {1664-462X},
journal = {Frontiers in Plant Science},
pages = {641},
title = {{Publishing FAIR Data: An Exemplar Methodology Utilizing PHI-Base}},
url = {https://www.frontiersin.org/article/10.3389/fpls.2016.00641 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4922217/pdf/fpls-07-00641.pdf},
volume = {7},
year = {2016}
}
@inproceedings{Ahmadzadeh2005,
abstract = {The process by which students learn to program is a major issue in computer science educational research. Programming is a fundamental part of the computer science curriculum, but one which is often problematic. It seems to be difficult to find an effective method of teaching that is suitable for all students. In this research we tried to gain insights into ways of improving our teaching by a careful examination of students' mistakes. The compiler errors that were generated by their programs together with the pattern that was observed in their debugging activities formed the basis of this research. We discovered that many students with a good understanding of programming do not acquire the skills to debug programs effectively, and this is a major impediment to their producing working code of any complexity. Skill at debugging seems to increase a programmer's confidence and we suggest that more emphasis be placed on debugging skills in the teaching of programming. Copyright 2005 ACM.},
annote = {Cited By :62
Export Date: 20 July 2018
Correspondence Address: Ahmadzadeh, M.; School of CS and IT, University of Nottingham, Nottingham NG8 1BB, United Kingdom; email: mqa@cs.nott.ac.uk},
author = {Ahmadzadeh, M and Elliman, D and Higgins, C},
doi = {10.1145/1067445.1067472},
isbn = {1595930248 (ISBN); 9781595930248 (ISBN)},
keywords = {Computational complexity,Computer programming,Computer science,Computer science educational reserach,Debugging,Problem solving,Program debugging,Programming,Science curriculum,Students,Working codes},
language = {English},
pages = {84--88},
title = {{An analysis of patterns of debugging among novice computer science students}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-29844452135{\&}doi=10.1145{\%}2F1067445.1067472{\&}partnerID=40{\&}md5=380478fa5965afd28694313f8c70901e https://dl.acm.org/citation.cfm?doid=1067445.1067472},
year = {2005}
}
@inproceedings{Staubitz2016,
abstract = {In recent years, Massive Open Online Courses (MOOCs) have become a phenomenon presenting the prospect of free high class education to everybody. They bear a tremendous potential for teaching programming to a large and diverse audience. The typical MOOC components, such as video lectures, reading material, and easily assessable quizzes, however, are not sufficient for proper programming education. To learn programming, participants need an option to work on practical programming exercises and to solve actual programming tasks. It is crucial that the participants receive proper feedback on their work in a timely manner. Without a tool for automated assessment of programming assignments, the teaching teams would be restricted to offer optional ungraded exercises only. The paper at hand sketches scenarios how practical programming exercises could be provided and examines the landscape of potentially helpful tools in this context. Automated assessment has a long record in the history of computer science education. We give an overview of existing tools in this field and also explore the question what can and/or should be assessed. {\textcopyright} 2015 IEEE.},
annote = {Cited By :25
Export Date: 20 July 2018},
author = {Staubitz, T and Klement, H and Renz, J and Teusner, R and Meinel, C},
doi = {10.1109/TALE.2015.7386010},
isbn = {9781467392266 (ISBN)},
keywords = {Assessment,Automated Assessment,Automation,Computer Science Education,E-learning,Education,Education computing,Engineering education,MOOC,Massive Open Online Courses,Massive open online course,Mathematical programming,Programming,Programming assignments,Programming education,Teaching,Teaching programming},
language = {English},
pages = {23--30},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Towards practical programming exercises and automated assessment in Massive Open Online Courses}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84963591589{\&}doi=10.1109{\%}2FTALE.2015.7386010{\&}partnerID=40{\&}md5=21067447c8e7c5619bd5003114a587c7 https://ieeexplore.ieee.org/ielx7/7377406/7385995/07386010.pdf?tp={\&}arnumber=7386010{\&}isnumber=7385995},
year = {2016}
}
@article{VonLandesberger2011,
abstract = {Abstract The analysis of large graphs plays a prominent role in various fields of research and is relevant in many important application areas. Effective visual analysis of graphs requires appropriate visual presentations in combination with respective user interaction facilities and algorithmic graph analysis methods. How to design appropriate graph analysis systems depends on many factors, including the type of graph describing the data, the analytical task at hand and the applicability of graph analysis methods. The most recent surveys of graph visualization and navigation techniques cover techniques that had been introduced until 2000 or concentrate only on graph layouts published until 2002. Recently, new techniques have been developed covering a broader range of graph types, such as time-varying graphs. Also, in accordance with ever growing amounts of graph-structured data becoming available, the inclusion of algorithmic graph analysis and interaction techniques becomes increasingly important. In this State-of-the-Art Report, we survey available techniques for the visual analysis of large graphs. Our review first considers graph visualization techniques according to the type of graphs supported. The visualization techniques form the basis for the presentation of interaction approaches suitable for visual graph exploration. As an important component of visual graph analysis, we discuss various graph algorithmic aspects useful for the different stages of the visual graph analysis process. We also present main open research challenges in this field.},
author = {von Landesberger, T and Kuijper, A and Schreck, T and Kohlhammer, J and van Wijk, J J and Fekete, J D and Fellner, D W},
doi = {10.1111/j.1467-8659.2011.01898.x},
isbn = {0167-7055},
journal = {Computer Graphics Forum},
keywords = {Data Structures [E.1]: Graphs and Networks,Graph Theory [H.4]: Information Systems: Applicati,Information Systems [H.5.2]: Interfaces and Presen,Mathematics of Computing [G.2.2]: Discrete Mathema,Trees,User Interfaces,graph interaction,graph visualization,visual analytics,visual graph analysis},
number = {6},
pages = {1719--1749},
publisher = {John Wiley {\&} Sons, Ltd (10.1111)},
title = {{Visual Analysis of Large Graphs: State-of-the-Art and Future Research Challenges}},
url = {https://doi.org/10.1111/j.1467-8659.2011.01898.x https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1467-8659.2011.01898.x},
volume = {30},
year = {2011}
}
@inproceedings{Garner2005,
abstract = {In this paper we describe an ongoing study of novice programmers. The aim is to record (as close as possible to) all of the problems encountered by students during the laboratory sessions of our introductory Java programming class. We discuss the tools and methods employed, in particular presenting the list of problem definitions which is used to classify students' problems. Data collected during 2003 are presented and discussed. The results are consistent with trends noted in the literature, and highlight the significance of both fundamental design issues and the procedural aspects of programming. Different problem distributions are observed for high and low performing students. An analysis of individual lab sessions can be useful for refining course materials and teaching practice. {\textcopyright} 2005, Australian Computer Society, Inc.},
annote = {Cited By :39
Export Date: 20 July 2018
Correspondence Address: Garner, S.; Computer Science Department, The University of Otago, Dunedin, New Zealand; email: sandy@cs.otago.ac.nz},
author = {Garner, S and Haden, P and Robins, A},
isbn = {14451336 (ISSN); 1920682244 (ISBN); 9781920682248 (ISBN)},
keywords = {Computer programming,Course material,Fundamental design,Java programming,Laboratory sessions,Novice programmer,Novice programming,Novice programming errors CS1,Problem definition,Procedural aspects,Students,Teaching practices,Tools and methods},
language = {English},
pages = {173--180},
title = {{My program is correct but it doesn't run: A preliminary investigation of novice programmers' problems}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-34548059906{\&}partnerID=40{\&}md5=5b76d325b552e550b792c15fafa3ef91},
volume = {42},
year = {2005}
}
@techreport{CrowdFlower2016,
author = {CrowdFlower and CrowdFlower},
title = {{2016 Data Science Report}},
url = {http://visit.crowdflower.com/rs/416-ZBE-142/images/CrowdFlower{\_}DataScienceReport{\_}2016.pdf},
year = {2016}
}
@article{Barbrow2017,
author = {Barbrow, Sarah and Brush, Denise and Goldman, Julie},
doi = {10.5860/crln.78.5.274},
isbn = {2150-6698},
journal = {College {\&} Research Libraries News},
number = {5},
pages = {274},
publisher = {American Library Association},
title = {{Research data management and services: Resources for novice data librarians}},
url = {https://dx.doi.org/10.5860/crln.78.5.274},
volume = {78},
year = {2017}
}
@inproceedings{Khan2018,
abstract = {With the exponential growth in digital research data, libraries are beginning to find opportunities to assist researchers with planning, maintaining, sharing, and accessing data through research data services. Using a content analysis with the lens of information architecture, this study sought to better understand how these services are organized in North American academic library websites and to what extent the research data lifecycle is supported within research data services. 50 academic library websites were studied and results yielded three provisions that make up research data services: Information Access, Technical Support, and Personalized Consultation. The data lifecycle was found to be strongly supported in research data services for planning, data curation, and data access stages. {\textcopyright} 2018 Authors.},
annote = {Export Date: 20 July 2018},
author = {Khan, H R and Chang, H C and Kim, J},
doi = {10.1145/3197026.3203887},
isbn = {15525996 (ISSN); 9781450351782 (ISBN)},
keywords = {data lifecycle,research data management (rdm),research data services (rds)},
language = {English},
pages = {353--354},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{Unfolding Research Data Services: An Information Architecture Perspective}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85048873526{\&}doi=10.1145{\%}2F3197026.3203887{\&}partnerID=40{\&}md5=8335f90ba8ef351682c8972a57535e11 https://dl.acm.org/citation.cfm?doid=3197026.3203887},
year = {2018}
}
@article{Wickham2010,
abstract = {A grammar of graphics is a tool that enables us to concisely describe the components of a graphic. Such a grammar allows us to move beyond named graphics (e.g., the "scatterplot") and gain insight into the deep structure that underlies statistical graphics. This article builds on Wilkinson, Anand, and Grossman (2005), describing extensions and refinements developed while building an open source implementation of the grammar of graphics for R, ggplot2. The topics in this article include an introduction to the grammar by working through the process of creating a plot, and discussing the components that we need. The grammar is then presented formally and compared toWilkinson's grammar, highlighting the hierarchy of defaults, and the implications of embedding a graphical grammar into a programming language. The power of the grammar is illustrated with a selection of examples that explore different components and their interactions, in more detail. The article concludes by discussing some perceptual issues, and thinking about how we can build on the grammar to learn how to create graphical "poems." Supplemental materials are available online. Copyright {\textcopyright} 2010 American Statistical Association, Institute of Mathematical Statistics, and Interface Foundation of North America.},
annote = {Cited By :70
Export Date: 20 June 2019},
author = {Wickham, Hadley},
doi = {10.1198/jcgs.2009.07098},
journal = {Journal of Computational and Graphical Statistics},
keywords = {Grammar of graphics,Statistical graphics},
number = {1},
pages = {3--28},
title = {{A Layered grammar of graphics}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77749327678{\&}doi=10.1198{\%}2Fjcgs.2009.07098{\&}partnerID=40{\&}md5=49d1add2cdc65647e1d6371e4a2f81f7 https://www.tandfonline.com/doi/abs/10.1198/jcgs.2009.07098},
volume = {19},
year = {2010}
}
@article{Read2018,
abstract = {Background: REDCap, an electronic data capture tool, supports good research data management, but many researchers lack familiarity with the tool. While a REDCap administrator provided technical support and a clinical data management support unit provided study design support, a service gap existed. Case Presentation: Librarians with REDCap expertise sought to increase and improve usage through outreach, workshops, and consultations. In collaboration with a REDCap administrator and the director of the clinical data management support unit, the role of the library was established in providing REDCap training and consultations. REDCap trainings were offered to the medical center during the library's quarterly data series, which served as a springboard for offering tailored REDCap support to researchers and research groups. Conclusions: Providing REDCap support has proved to be an effective way to associate the library with data-related activities in an academic medical center and identify new opportunities for offering data services in the library. By offering REDCap services, the library established strong partnerships with the Information Technology Department, Clinical Data Support Department, and Compliance Office by filling in training gaps, while simultaneously referring users back to these departments when additional expertise was required. These new partnerships continue to grow and serve to position the library as a central data hub in the institution. {\textcopyright} 2018, Medical Library Association. All rights reserved.},
annote = {Export Date: 20 July 2018
CODEN: JMLAC},
author = {Read, K and LaPolla, F W Z},
doi = {10.5195/jmla.2018.327},
isbn = {15365050 (ISSN)},
journal = {Journal of the Medical Library Association},
keywords = {Clinical data management,Consultations,Data collection,Data governance,Education,REDCap,Training,Workshops,administrative personnel,article,consultation,human,information processing,information technology,librarian,scientist,university hospital},
language = {English},
number = {1},
pages = {120--126},
publisher = {Medical Library Association},
title = {{A new hat for librarians: Providing REDCap support to establish the library as a central data hub}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040942008{\&}doi=10.5195{\%}2Fjmla.2018.327{\&}partnerID=40{\&}md5=02471cf3210e28a3e84305275b277c36 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5764577/pdf/jmla-106-120.pdf},
volume = {106},
year = {2018}
}
@book{Stueben2018,
abstract = {Improve your coding skills and learn how to write readable code. Rather than teach basic programming, this book presumes that readers understand the fundamentals, and offers time-honed best practices for style, design, documenting, testing, refactoring, and more. Taking an informal, conversational tone, author Michael Stueben offers programming stories, anecdotes, observations, advice, tricks, examples, and challenges based on his 38 years experience writing code and teaching programming classes. Trying to teach style to beginners is notoriously difficult and can easily appear pedantic. Instead, this book offers solutions and many examples to back up his ideas. Good Habits for Great Coding distills Stueben's three decades of analyzing his own mistakes, analyzing student mistakes, searching for problems that teach lessons, and searching for simple examples to illustrate complex ideas. Having found that most learn by trying out challenging problems, and reflecting on them, each chapter includes quizzes and problems in each chapter. The final chapter introduces dynamic programming to reduce complex problems to subcases, and illustrates many concepts discussed in the book. Code samples are provided in Python and designed to be understandable by readers familiar with any modern programming language. At the end of this book, you will have acquired a lifetime of good coding advice; the lessons the author wishes he had learned when he was a novice. {\textcopyright} 2018 by Michael Stueben.},
annote = {Export Date: 20 July 2018
Correspondence Address: Stueben, M.; Fairfax High SchoolUnited States},
author = {Stueben, M},
booktitle = {Good Habits for Great Coding: Improving Programming Skills with Examples in Python},
doi = {10.1007/978-1-4842-3459-4},
isbn = {9781484234594 (ISBN); 9781484234587 (ISBN)},
keywords = {Algorithms,Code comments,Coding advice,Coding style,Coding tricks,Dynamic programming,Programming philosophy,Python,Refactoring,Self-documenting code,Step-wise refinement,Teaching programming,Testing},
language = {English},
pages = {1--314},
publisher = {Apress Media LLC},
title = {{Good habits for great coding: Improving programming skills with examples in python}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046412082{\&}doi=10.1007{\%}2F978-1-4842-3459-4{\&}partnerID=40{\&}md5=59ae94a5d18083469111c342da669b8f},
year = {2018}
}
@article{Castle2019,
abstract = {RDS are usually cross-disciplinary, centralised services, which are increasingly provided at a university by the academic library and in collaboration with other RDM stakeholders, such as the Research Office. At research-intensive universities, research data is generated in a wide range of disciplines and sub-disciplines. This paper will discuss how providing discipline-specific RDM support is approached by such universities and academic libraries, and the advantages and disadvantages of these central and discipline-specific approaches. A descriptive case study on the author's experiences of collaborating with a central RDS at the University of Cambridge, as a subject librarian embedded in an academic department, is a major component of this paper. The case study describes how centralised RDM services offered by the Office of Scholarly Communication (OSC) have been adapted to meet discipline-specific needs in the Department of Chemistry. It will introduce the department and the OSC, and describe the author's role in delivering RDM training, as well as the Data Champions programme, and their membership of the RDM Project Group. It will describe the outcomes of this collaboration for the Department of Chemistry, and for the centralised service. Centralised and discipline-specific approaches to RDS provision have their own advantages and disadvantages. Supporting the discipline-specific RDM needs of researchers is proving particularly challenging for universities to address sustainably: it requires adequate financial resources and staff skilled (or re-skilled) in RDM. A mixed approach is the most desirable, cost-effective way of providing RDS, but this still has constraints. [ABSTRACT FROM AUTHOR] Copyright of Libri: International Journal of Libraries {\&} Information Services is the property of De Gruyter and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
annote = {Castle, Clair 1; Email Address: cmc32@cam.ac.uk; Affiliation: 1: Department of Chemistry Library, University of Cambridge Department of Chemistry, Cambridge, UK; Source Info: Jun2019, Vol. 69 Issue 2, p105; Subject Term: ACADEMIC libraries; Subject Term: COMPUTER assisted research; Subject Term: RESEARCH; Subject Term: LIBRARY public services; Author-Supplied Keyword: chemistry data; Author-Supplied Keyword: discipline-specific research data services; Author-Supplied Keyword: research data management; Author-Supplied Keyword: research data services; Author-Supplied Keyword: subject librarians; Company/Entity: UNIVERSITY of Cambridge; NAICS/Industry Codes: 519120 Libraries and Archives; Number of Pages: 12p; Document Type: Article; Full Text Word Count: 7944},
author = {Castle, Clair},
doi = {10.1515/libri-2018-0064},
isbn = {00242667},
journal = {Libri: International Journal of Libraries {\&} Information Services},
keywords = {ACADEMIC libraries,COMPUTER assisted research,LIBRARY public services,RESEARCH,UNIVERSITY of Cambridge,chemistry data,discipline-specific research data services,research data management,research data services,subject librarians},
number = {2},
pages = {105--116},
pmid = {136769714},
title = {{Getting the Central RDM Message Across: A Case Study of Central versus Discipline-Specific Research Data Services (RDS) at the University of Cambridge}},
url = {http://proxycu.wrlc.org/login?url=http://search.ebscohost.com/login.aspx?direct=true{\&}db=a9h{\&}AN=136769714{\&}site=ehost-live https://www.degruyter.com/view/j/libr.2019.69.issue-2/libri-2018-0064/libri-2018-0064.xml},
volume = {69},
year = {2019}
}
@article{Broman2018,
abstract = {ABSTRACTSpreadsheets are widely used software tools for data entry, storage, analysis, and visualization. Focusing on the data entry and storage aspects, this article offers practical recommendations for organizing spreadsheet data to reduce errors and ease later analyses. The basic principles are: be consistent, write dates like YYYY-MM-DD, do not leave any cells empty, put just one thing in a cell, organize the data as a single rectangle (with subjects as rows and variables as columns, and with a single header row), create a data dictionary, do not include calculations in the raw data files, do not use font color or highlighting as data, choose good names for things, make backups, use data validation to avoid data entry errors, and save the data in plain text files.},
author = {Broman, Karl W and Woo, Kara H},
doi = {10.1080/00031305.2017.1375989},
isbn = {0003-1305},
journal = {The American Statistician},
number = {1},
pages = {2--10},
publisher = {Taylor {\&} Francis},
title = {{Data Organization in Spreadsheets}},
url = {https://doi.org/10.1080/00031305.2017.1375989 https://www.tandfonline.com/doi/pdf/10.1080/00031305.2017.1375989?needAccess=true},
volume = {72},
year = {2018}
}
@misc{Barabasi2014,
address = {Cambridge, Mass.},
author = {Barab{\'{a}}si, Albert-L{\'{a}}szl{\'{o}}},
isbn = {0738206679},
keywords = {Computer networks Miscellanea.,Economics Miscellanea.,Electronic books.,Science Philosophy.,Social networks Miscellanea.,System theory.,World Wide Web Miscellanea.},
pages = {280 p.},
publisher = {Perseus Pub.},
title = {{Linked: The New Science Of Networks Science Of Networks}},
year = {2014}
}
@article{Chang2000,
abstract = {The purpose of this research is to develop a programming learning system for beginners using the completion strategy. The completion strategy uses well-designed programs to let students engage in completing, modifying, and extending their programs. The completion strategy is a paradigm of learning by examples with learning enforcement. In this paper, learning theories of the completion strategy are investigated. A template technique is employed to realize the strategy. An educational experiment was made to show the learning impact of the proposed system. The experimental result shows that the completion strategy is benefit to the programming learning for beginners. {\textcopyright} 2000 IEEE.},
annote = {Cited By :21
Export Date: 20 July 2018
CODEN: IEEDA
Correspondence Address: Chang, K.-E.; Department of Information and Computer Education, National Taiwan Normal University, Taipei, Taiwan; email: kchang@ice.ntnu.edu.tw},
author = {Chang, K E and Chiao, B C and Chen, S W and Hsiao, R S},
doi = {10.1109/13.848075},
isbn = {00189359 (ISSN)},
journal = {IEEE Transactions on Education},
keywords = {Completion strategy,Computer aided instruction,Computer programming,Engineering education,Learning systems,Programming learning,Students,Teaching,Template technique},
language = {English},
number = {2},
pages = {211--220},
title = {{A programming learning system for beginners - A completion strategy approach}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0034187838{\&}doi=10.1109{\%}2F13.848075{\&}partnerID=40{\&}md5=0d26fb162fccd1de79a230295e78b089 https://ieeexplore.ieee.org/ielx5/13/18450/00848075.pdf?tp={\&}arnumber=848075{\&}isnumber=18450},
volume = {43},
year = {2000}
}
@article{Floridi2016,
abstract = {This theme issue has the founding ambition of landscaping data ethics as a new branch of ethics that studies and evaluates moral problems related to data (including generation, recording, curation, processing, dissemination, sharing and use), algorithms (including artificial intelligence, artificial agents, machine learning and robots) and corresponding practices (including responsible innovation, programming, hacking and professional codes), in order to formulate and support morally good solutions (e.g. right conducts or right values). Data ethics builds on the foundation provided by computer and information ethics but, at the same time, it refines the approach endorsed so far in this research field, by shifting the level of abstraction of ethical enquiries, from being information-centric to being data-centric. This shift brings into focus the different moral dimensions of all kinds of data, even data that never translate directly into information but can be used to support actions or generate behaviours, for example. It highlights the need for ethical analyses to concentrate on the content and nature of computational operations-the interactions among hardware, software and data-rather than on the variety of digital technologies that enable them. And it emphasizes the complexity of the ethical challenges posed by data science. Because of such complexity, data ethics should be developed from the start as a macroethics, that is, as an overall framework that avoids narrow, ad hoc approaches and addresses the ethical impact and implications of data science and its applications within a consistent, holistic and inclusive framework. Only as a macroethics will data ethics provide solutions that can maximize the value of data science for our societies, for all of us and for our environments.This article is part of the themed issue 'The ethical impact of data science'.},
annote = {Floridi, Luciano
Taddeo, Mariarosaria
eng
England
Philos Trans A Math Phys Eng Sci. 2016 Dec 28;374(2083). pii: rsta.2016.0360. doi: 10.1098/rsta.2016.0360.},
author = {Floridi, Luciano and Taddeo, Mariarosaria},
doi = {doi:10.1098/rsta.2016.0360},
edition = {2016/01/01},
isbn = {1364-503X (Print)1364-503X (Linking)},
journal = {Philos Trans A Math Phys Eng Sci},
keywords = {*data ethics,*data science,*ethics of algorithms,*ethics of data,*ethics of practices,*levels of abstraction,Information Science/*ethics},
number = {2083},
pages = {20160360},
pmid = {28336805},
title = {{What is data ethics?}},
volume = {374},
year = {2016}
}
@article{Sedlmair2012,
abstract = {Design studies are an increasingly popular form of problem-driven visualization research, yet there is little guidance available about how to do them effectively. In this paper we reflect on our combined experience of conducting twenty-one design studies, as well as reading and reviewing many more, and on an extensive literature review of other field work methods and methodologies. Based on this foundation we provide definitions, propose a methodological framework, and provide practical guidance for conducting design studies. We define a design study as a project in which visualization researchers analyze a specific real-world problem faced by domain experts, design a visualization system that supports solving this problem, validate the design, and reflect about lessons learned in order to refine visualization design guidelines. We characterize two axes - a task clarity axis from fuzzy to crisp and an information location axis from the domain expert's head to the computer - and use these axes to reason about design study contributions, their suitability, and uniqueness from other approaches. The proposed methodological framework consists of 9 stages: learn, winnow, cast, discover, design, implement, deploy, reflect, and write. For each stage we provide practical guidance and outline potential pitfalls. We also conducted an extensive literature survey of related methodological approaches that involve a significant amount of qualitative field work, and compare design study methodology to that of ethnography, grounded theory, and action research.},
author = {Sedlmair, M and Meyer, M and Munzner, T},
doi = {10.1109/TVCG.2012.213},
isbn = {1077-2626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Algorithm design and analysis,Collaboration,Data visualization,Design methodology,Design study,Logic gates,Visualization,data visualisation,design study methodology,framework,information location axis,methodology,problem-driven visualization,task clarity axis,visualization design guideline},
number = {12},
pages = {2431--2440},
title = {{Design Study Methodology: Reflections from the Trenches and the Stacks}},
volume = {18},
year = {2012}
}
@article{Duncan1984,
abstract = {Conducted 4 experiments with 108 volunteers (aged 18-42 yrs) to test object-, discrimination-, and space-based theories of visual attention. In each experiment, Ss were presented with small ({\textless} 1|), brief, foveal displays, each consisting of 2 overlapping objects (a box with a line struck through it). Overall results indicate that 2 judgments that concern the same object were made simultaneously without loss of accuracy, whereas 2 judgments that concern different objects were not. Neither the similarity nor the difficulty of required discriminations, nor the spatial distribution of information, could account for the results. Findings support a view in which parallel, preattentive processes serve to segment the field into separate objects, followed by a process of focal attention that deals with only 1 object at a time. This view is also able to account for results taken to support both discrimination-based and space-based theories. (33 ref) (PsycINFO Database Record (c) 2006 APA, all rights reserved). {\textcopyright} 1984 American Psychological Association.},
annote = {Cited By :1349
Export Date: 9 February 2019},
author = {Duncan, J},
doi = {10.1037/0096-3445.113.4.501},
journal = {Journal of Experimental Psychology: General},
keywords = {discrimination- {\&},object- {\&},space-based theories of selective attention, accur},
number = {4},
pages = {501--517},
title = {{Selective attention and the organization of visual information}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0021696833{\&}doi=10.1037{\%}2F0096-3445.113.4.501{\&}partnerID=40{\&}md5=dbbad4ed186ee70e32a01f549562e1b2},
volume = {113},
year = {1984}
}
@inproceedings{Zuk2006,
abstract = {Heuristic evaluation is a well known discount evaluation technique in human-computer interaction (HCI) but has not been utilized in information visualization (InfoVis) to the same extent. While several sets of heuristics have been used or proposed for InfoVis, it is not yet known what kind of heuristics are useful for finding general InfoVis problems. We performed a meta-analysis with the goal of exploring the issues of heuristic evaluation for InfoVis. This meta-analysis concentrates on issues pertaining to the selection and organization of heuristics, and the process itself. For this purpose, we used three sets of previously published heuristics to assess a visual decision support system that is used to examine simulation data. The meta-analysis shows that the evaluation process and results have a high dependency on the heuristics and the types of evaluators chosen. We describe issues related to interpretation, redundancy, and conflict in heuristics. We also provide a discussion of generalizability and categorization of these heuristics. Copyright 2006 ACM.},
annote = {Cited By :60
Export Date: 26 June 2019
Correspondence Address: Zuk, T.; University of Calgary, 2500 University Dr. NW, Calgary, T2N 1N4, Canada; email: zuk@cpsc.ucalgary.ca},
author = {Zuk, T and Schlesier, L and Neumann, P and Hancock, M S and Carpendale, S},
doi = {10.1145/1168149.1168162},
isbn = {1595935622 (ISBN); 9781595935625 (ISBN)},
keywords = {Computer simulation,Data acquisition,Decision support systems,Heuristic evaluation,Heuristic methods,Human computer interaction,Information systems,Information visualization evaluation,Meta-analysis,Visualization},
language = {English},
title = {{Heuristics for information visualization evaluation}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-34547152721{\&}doi=10.1145{\%}2F1168149.1168162{\&}partnerID=40{\&}md5=48821fde1d65866cfbaed4d604f0c90a https://dl.acm.org/citation.cfm?doid=1168149.1168162},
year = {2006}
}
@article{Fernandez2017,
author = {Fernandez, Nicolas F and Gundersen, Gregory W and Rahman, Adeeb and Grimes, Mark L and Rikova, Klarisa and Hornbeck, Peter and Ma'ayan, Avi},
doi = {10.1038/sdata.2017.151https://www.nature.com/articles/sdata2017151#supplementary-information},
journal = {Scientific Data},
pages = {170151},
publisher = {The Author(s)},
title = {{Clustergrammer, a web-based heatmap visualization and analysis tool for high-dimensional biological data}},
url = {http://dx.doi.org/10.1038/sdata.2017.151 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5634325/pdf/sdata2017151.pdf},
volume = {4},
year = {2017}
}
@article{Gibson1987,
abstract = {In four studies we investigated the perception of the affordance for traversal of a supporting surface. The surface presented was either rigid or deformable, and this property was specified either optically, haptically, or both. In Experiment 1A, crawling and walking infants were presented with two surfaces in succession: a standard surface that both looked and felt rigid and a deforming surface that both looked and felt nonrigid. Latency to initiate locomotion, duration of visual and haptic exploration, and displacement activity were coded from videotapes. Compared with the standard, the deforming surface elicited longer latency, more exploratory behavior, and more displacement in walkers, but not in crawlers, suggesting that typical mode of locomotion influences perceived traversability. These findings were replicated in Experiment 1B, in which the infant was presented with a dual walkway, forcing a choice between the two surfaces. Experiments 2, 3A and B, and 4A and B investigated the use of optical and haptic information in detecting traversability of rigid and nonrigid surfaces. Patterns of exploration varied with the information presented and differed for crawlers and walkers in the case of a deformable surface, as an affordance theory would predict.},
annote = {Gibson, E J
Riccio, G
Schmuckler, M A
Stoffregen, T A
Rosenberg, D
Taormina, J
eng
1RO1HD 17207-02/HD/NICHD NIH HHS/
Research Support, U.S. Gov't, Non-P.H.S.
Research Support, U.S. Gov't, P.H.S.
J Exp Psychol Hum Percept Perform. 1987 Nov;13(4):533-44.},
author = {Gibson, E J and Riccio, G and Schmuckler, M A and Stoffregen, T A and Rosenberg, D and Taormina, J},
edition = {1987/11/01},
isbn = {0096-1523 (Print)0096-1523 (Linking)},
journal = {J Exp Psychol Hum Percept Perform},
keywords = {*Form Perception,*Locomotion,*Psychology, Child,*Social Environment,Attention,Discrimination Learning,Exploratory Behavior,Female,Humans,Infant,Male,Reaction Time,Touch},
number = {4},
pages = {533--544},
pmid = {2965745},
title = {{Detection of the traversability of surfaces by crawling and walking infants}},
url = {https://www.ncbi.nlm.nih.gov/pubmed/2965745},
volume = {13},
year = {1987}
}
@article{Langley2017,
abstract = {The article discusses several aspects of how research and academic libraries support the research process. It mentions that researchers depend on the libraries to purchase, subscribe to the books, journals, databases, and other materials that make up the universe of scholarly communication. It also mentions about new roles at the Penn State Libraries at the Pennsylvania State University have titles such as scholarly communications librarian, copyright librarian and data librarian.},
annote = {Langley, Anne 1; Email Address: Anne.langley@gmail.com; Affiliations: 1 : Associate Dean for Research, Collections and Scholarly Communications, Penn State University Libraries; Source Info: Nov2017, Vol. 29 Issue 5, p12; Thesaurus Term: Research libraries; Thesaurus Term: Academic libraries; Thesaurus Term: Librarians; Subject Term: Communication in learning {\&} scholarship; Number of Pages: 2p; Document Type: Article},
author = {Langley, Anne},
issn = {10432094},
journal = {Against the Grain},
keywords = {Research libraries Academic libraries Librarians C},
number = {5},
pages = {12--14},
title = {{How Research Libraries Support the Research Process: From Idea To Publishing}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=lxh{\&}AN=126153004{\&}site=ehost-live},
volume = {29},
year = {2017}
}
@article{Wilson2017,
abstract = {Author summary Computers are now essential in all branches of science, but most researchers are never taught the equivalent of basic lab skills for research computing. As a result, data can get lost, analyses can take much longer than necessary, and researchers are limited in how effectively they can work with software and data. Computing workflows need to follow the same practices as lab projects and notebooks, with organized data, documented steps, and the project structured for reproducibility, but researchers new to computing often don't know where to start. This paper presents a set of good computing practices that every researcher can adopt, regardless of their current level of computational skill. These practices, which encompass data management, programming, collaborating with colleagues, organizing projects, tracking work, and writing manuscripts, are drawn from a wide variety of published sources from our daily lives and from our work with volunteer organizations that have delivered workshops to over 11,000 people since 2010.},
author = {Wilson, Greg and Bryan, Jennifer and Cranston, Karen and Kitzes, Justin and Nederbragt, Lex and Teal, Tracy K},
doi = {10.1371/journal.pcbi.1005510},
journal = {PLOS Computational Biology},
number = {6},
pages = {e1005510},
title = {{Good enough practices in scientific computing}},
url = {https://doi.org/10.1371/journal.pcbi.1005510},
volume = {13},
year = {2017}
}
@incollection{Lander2017,
abstract = {Using the open source R language, you can build powerful statistical models to answer many of your most challenging questions. R has traditionally been difficult for non-statisticians to learn, and most R books assume far too much knowledge to be of help. R for Everyone, Second Edition, is the solution. Drawing on his unsurpassed experience teaching new users, professional data scientist Jared P. Lander has written the perfect tutorial for anyone new to statistical programming and modeling. Organized to make learning easy and intuitive, this guide focuses on the 20 percent of R functionality you'll need to accomplish 80 percent of modern data tasks. Lander's self-contained chapters start with the absolute basics, offering extensive hands-on practice and sample code. You'll download and install R; navigate and use the R environment; master basic program control, data import, manipulation, and visualization; and walk through several essential tests. Then, building on this foundation, you'll construct several complete models, both linear and nonlinear, and use some data mining techniques. After all this you'll make your code reproducible with LaTeX, RMarkdown, and Shiny. By the time you're done, you won't just know how to write R programs, you'll be ready to tackle the statistical problems you care about most. -- Provided by publisher.},
annote = {2017934582
Jared P. Lander.
illustrations (some color) ; 23 cm.
Includes indexes.
Getting R -- The R environment -- R packages -- Basics of R -- Advanced data structures -- Reading data into R -- Statistical graphics -- Writing R functions -- Control statements -- Loops, the Un-R way to iterate -- Group manipulation -- Faster group manipulation with dplyr -- Iterating with purrr -- Data reshaping -- Reshaping data in the Tidyverse -- Manipualting strings -- Probability distributions -- Basic statistics -- Linear models -- Generalized linear models -- Model diagnostics -- Regularization and shrinkage -- Nonlinear models -- Time series and autocorrelation -- Clustering -- Model fitting with Caret -- Reproducibility and reports with knitr -- Rich documents with RMarkdown -- Interactive dashboards with shiny -- Building R packages -- Real-life resources.
Addison-Wesley data and analytics series.},
author = {Lander, Jared P C N - HARRISBURG INTRANSIT QA76.73.R3L36 2017 BOOKFLOAT UP-ENGIN STACKS-EG QA76.73.R3L36 2017 BOOK},
booktitle = {R for everyone : advanced analytics and graphics},
edition = {Second edi},
isbn = {013454692X 9780134546926},
keywords = {R (Computer program language) Scripting languages},
pages = {xxiv, 528 pages},
title = {{Chapter 3: Installing Packages}},
year = {2017}
}
@article{Akers2012,
abstract = {Academic libraries are increasingly engaging in data curation by providing infrastructure and services to support the management of research data on their campus. Efforts to develop these resources can benefit from a greater understanding of the social factors that affect how researchers manage their data during and after their research projects. In particular, the age or amount of experience of researchers is often thought to be an important factor influencing their viewpoints on research data sharing and preservation. In this study, we categorized faculty members who responded to our campus-wide survey on research data management into four ranks-professor, associate professor, assistant professor, and non-tenure track- and analyzed differences in their patterns of survey responses. We found statistically significant differences among faculty ranks in familiarity with funding agency requirements for data management plans, reasons that might prevent data sharing, and interest in potential research data services. These findings reveal key distinctions among different ranks of faculty members in their outlook toward research data management, which can help guide academic librarians and data curation professionals to develop research data services that are tailored to the unique needs of specific populations of researchers. [ABSTRACT FROM AUTHOR] Copyright of IASSIST Quarterly is the property of IASSIST Quarterly and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
annote = {Akers, Katherine G. 1; Email Address: kgakers@umich.edu; Doty, Jennifer 2; Email Address: jennifer.doty@emory.edu; Affiliations: 1 : eScience Librarian and CLIR Postdoctoral Fellow, University of Michigan Libraries; 2 : Data Management Specialist, Emory University Libraries; Source Info: Summer2012, Vol. 36 Issue 2, p16; Thesaurus Term: Research; Subject Term: Academic titles (Higher education); Subject Term: Job titles; Subject Term: Social factors; Subject Term: Differences; Author-Supplied Keyword: Data curation; Author-Supplied Keyword: data sharing; Author-Supplied Keyword: faculty rank; Author-Supplied Keyword: library; Author-Supplied Keyword: research data management; Author-Supplied Keyword: researchers; Number of Pages: 5p; Document Type: Article},
author = {Akers, Katherine G and Doty, Jennifer},
issn = {07391137},
journal = {IASSIST Quarterly},
keywords = {Research Academic titles (Higher education) Job ti},
number = {2},
pages = {16--20},
title = {{Differences among Faculty Ranks in Views on Research Data Management}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=lxh{\&}AN=94876868{\&}site=ehost-live},
volume = {36},
year = {2012}
}
@article{Wirz2015,
annote = {Cited By :1 Export Date: 17 November 2017},
author = {Wirz, J},
journal = {MLA'15, 115Th Annual Meeting of the Medical Library Association},
title = {{More than a pretty picture: Data visualization and research communication skills}},
year = {2015}
}
@article{Scaramozzino2014,
abstract = {Programs for geospatial support at academic libraries have evolved over the past decade in response to changing campus needs and developing technologies. Geospatial applications have matured tremendously in this time, emerging from specialty tools to become broadly used across numerous disciplines. At many universities, the library has served as a central resource allowing students and faculty across academic departments access to GIS resources. Today, as many academic libraries evaluate their spaces and services, GIS and data services are central in discussions on how to further engage with patrons and meet increasingly diverse researcher needs. As library programs evolve to support increasingly technical data and GIS needs, many universities are faced with similar challenges and opportunities. To explore these themes, data and GIS services librarians and GIS specialists from five universities—the University of North Carolina at Chapel Hill, Texas A{\&}M, New York University, North Carolina State University, and California Polytechnic State University—with different models of library geospatial and data support, describe their programs to help identify common services, as well as unique challenges, opportunities, and future plans. [ABSTRACT FROM AUTHOR] Copyright of Journal of Map {\&} Geography Libraries is the property of Taylor {\&} Francis Ltd and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
annote = {Scaramozzino, Jeanine 1; White, Russell 1; Essic, Jeff 2; Fullington, Lee Ann 3; Mistry, Himanshu 3; Henley, Amanda 4; Olivares, Miriam 5; Affiliations: 1 : California Polytechnic State University, San Luis Obispo, California, USA; 2 : North Carolina State University, Raleigh, North Carolina, USA; 3 : New York University, New York, New York, USA; 4 : University of North Carolina at Chapel Hill, Chapel Hill, North Carolina, USA; 5 : Texas A{\&}M University, College Station, Texas, USA; Source Info: Jan-Apr2014, Vol. 10 Issue 1, p6; Thesaurus Term: Geographic information systems; Thesaurus Term: Academic libraries; Thesaurus Term: Data mining; Thesaurus Term: Technical education; Subject Term: Geospatial data; Subject Term: Academic departments (Universities {\&} colleges); Author-Supplied Keyword: collections; Author-Supplied Keyword: data services; Author-Supplied Keyword: Geographic Information Services; Author-Supplied Keyword: GIS; Author-Supplied Keyword: GIS services; Author-Supplied Keyword: infrastructure; Author-Supplied Keyword: instruction; Author-Supplied Keyword: outreach; Author-Supplied Keyword: reference; Author-Supplied Keyword: spatial literacy; Number of Pages: 42p; Document Type: Article},
author = {Scaramozzino, Jeanine and White, Russell and Essic, Jeff and Fullington, Lee Ann and Mistry, Himanshu and Henley, Amanda and Olivares, Miriam},
doi = {10.1080/15420353.2014.893943},
issn = {15420353},
journal = {Journal of Map {\&} Geography Libraries},
keywords = {Geographic information systems Academic libraries},
number = {1},
pages = {6--47},
title = {{Map Room to Data and GIS Services: Five University Libraries Evolving to Meet Campus Needs and Changing Technologies}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=lxh{\&}AN=95678376{\&}site=ehost-live},
volume = {10},
year = {2014}
}
@article{Elmore2014,
abstract = {The article explores the roles of data management in libraries. Topics discussed include the addition of data services in the job descriptions of business librarians, assessment of the need and implementation of data services in libraries, several areas where libraries could provide data-related services, Milne Library's encouragement of data sharing and progress of libraries in the development of data services.},
annote = {Elmore, Justina M. 1; Email Address: elmore@geneseo.edu; Jefferson, Charissa O. 2; Affiliations: 1 : Milne Library, SUNY Geneseo, Geneseo, New York, USA; 2 : Oviatt Library, California State University, Northridge, California, USA; Source Info: Jul-Sep2014, Vol. 10 Issue 3, p252; Thesaurus Term: Information resources management; Thesaurus Term: Library science; Thesaurus Term: Information sharing; Thesaurus Term: Information science; Thesaurus Term: Business libraries -- Administration; Thesaurus Term: Libraries -- Data processing; Number of Pages: 11p; Document Type: Article},
author = {Elmore, Justina M and Jefferson, Charissa O},
doi = {10.1080/15228959.2014.931206},
issn = {15228959},
journal = {Public Services Quarterly},
keywords = {Information resources management Library science I},
number = {3},
pages = {252--262},
title = {{Business Librarians Donning the Data Hat: Perspectives on This New Challenge}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=lxh{\&}AN=97239884{\&}site=ehost-live},
volume = {10},
year = {2014}
}
@incollection{Lander2017a,
abstract = {Using the open source R language, you can build powerful statistical models to answer many of your most challenging questions. R has traditionally been difficult for non-statisticians to learn, and most R books assume far too much knowledge to be of help. R for Everyone, Second Edition, is the solution. Drawing on his unsurpassed experience teaching new users, professional data scientist Jared P. Lander has written the perfect tutorial for anyone new to statistical programming and modeling. Organized to make learning easy and intuitive, this guide focuses on the 20 percent of R functionality you'll need to accomplish 80 percent of modern data tasks. Lander's self-contained chapters start with the absolute basics, offering extensive hands-on practice and sample code. You'll download and install R; navigate and use the R environment; master basic program control, data import, manipulation, and visualization; and walk through several essential tests. Then, building on this foundation, you'll construct several complete models, both linear and nonlinear, and use some data mining techniques. After all this you'll make your code reproducible with LaTeX, RMarkdown, and Shiny. By the time you're done, you won't just know how to write R programs, you'll be ready to tackle the statistical problems you care about most. -- Provided by publisher.},
author = {Lander, Jared P},
booktitle = {R for everyone : advanced analytics and graphics},
edition = {Second edi},
isbn = {013454692X 9780134546926},
keywords = {R (Computer program language) Scripting languages},
pages = {xxiv, 528 pages},
title = {{Chapter 5: Advanced Data Structures}},
year = {2017}
}
@article{Steeves2017,
abstract = {Over the past few years, research reproducibility has been increasingly highlighted as a multifaceted challenge across many disciplines. There are socio-cultural obstacles as well as a constantly changing technical landscape that make replicating and reproducing research extremely difficult. For example, the prioritization of citation counts and journal prestige has undermined incentives to make research reproducible. Technically, researchers face challenges in reproducing research across different operating systems and different versions of software. While libraries have been building support around research data management and digital scholarship, reproducibility is an emerging area that has yet to be systematically addressed. In response, New York University created the position of Librarian for Research Data Management and Reproducibility (RDM {\&} R), a dual appointment between the Center for Data Science (CDS) and the Division of Libraries. This report will outline the role of the RDM {\&} R librarian, with special focus on the collaboration between the CDS and Libraries to bring reproducible research practices into the norm. [ABSTRACT FROM AUTHOR] Copyright of Collaborative Librarianship is the property of Colorado Library Consortium (CLiC) and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
annote = {Steeves, Vicky 1; Email Address: vicky.steeves@nyu.edu; Affiliations: 1 : Librarian for Research Data Management {\&} Reproducibility, New York University; Source Info: 2017, Vol. 9 Issue 2, p80; Thesaurus Term: Library research; Thesaurus Term: Data science (Information science); Thesaurus Term: Library science; Subject Term: Reproducible research; Subject Term: Data -- Management; Subject Term: Computer operating system software; Author-Supplied Keyword: data librarianship; Author-Supplied Keyword: data management; Author-Supplied Keyword: reproducibility; Number of Pages: 10p; Illustrations: 2 Diagrams, 1 Chart, 1 Graph; Document Type: Article},
author = {Steeves, Vicky},
issn = {19437528},
journal = {Collaborative Librarianship},
keywords = {Library research Data science (Information science},
number = {2},
pages = {80--89},
title = {{Reproducibility Librarianship}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=lxh{\&}AN=124163812{\&}site=ehost-live},
volume = {9},
year = {2017}
}
@article{Larson2016,
abstract = {Agile methodologies were introduced in 2001. Since this time, practitioners have applied Agile methodologies to many delivery disciplines. This article explores the application of Agile methodologies and principles to business intelligence delivery and how Agile has changed with the evolution of business intelligence. Business intelligence has evolved because the amount of data generated through the internet and smart devices has grown exponentially altering how organizations and individuals use information. The practice of business intelligence delivery with an Agile methodology has matured; however, business intelligence has evolved altering the use of Agile principles and practices. The Big Data phenomenon, the volume, variety, and velocity of data, has impacted business intelligence and the use of information. New trends such as fast analytics and data science have emerged as part of business intelligence. This paper addresses how Agile principles and practices have evolved with business intelligence, as well as its challenges and future directions. [ABSTRACT FROM AUTHOR] Copyright of International Journal of Information Management is the property of Elsevier B.V. and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
annote = {Larson, Deanne 1; Email Address: larsonelink@aol.com; Chang, Victor 2; Email Address: ic.victor.chang@gmail.com; Affiliations: 1 : Larson {\&} Associates, LLC, USA; 2 : Xi'an Jiaotong Liverpool University, Suzhou, China; Source Info: Oct2016, Vol. 36 Issue 5, p700; Thesaurus Term: Business intelligence; Thesaurus Term: Data science (Information science); Thesaurus Term: Big data; Thesaurus Term: Web analytics; Subject Term: Agile software development; Author-Supplied Keyword: Agile methodologies; Author-Supplied Keyword: Analytics and big data; Author-Supplied Keyword: Business intelligence (BI); Author-Supplied Keyword: Lifecycle for BI and Big Data; Number of Pages: 11p; Document Type: Article},
author = {Larson, Deanne and Chang, Victor},
doi = {10.1016/j.ijinfomgt.2016.04.013},
issn = {02684012},
journal = {International Journal of Information Management},
keywords = {Business intelligence Data science (Information sc},
number = {5},
pages = {700--710},
title = {{A review and future direction of agile, business intelligence, analytics and data science}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=lxh{\&}AN=117797515{\&}site=ehost-live},
volume = {36},
year = {2016}
}
@incollection{Lander2017b,
abstract = {Using the open source R language, you can build powerful statistical models to answer many of your most challenging questions. R has traditionally been difficult for non-statisticians to learn, and most R books assume far too much knowledge to be of help. R for Everyone, Second Edition, is the solution. Drawing on his unsurpassed experience teaching new users, professional data scientist Jared P. Lander has written the perfect tutorial for anyone new to statistical programming and modeling. Organized to make learning easy and intuitive, this guide focuses on the 20 percent of R functionality you'll need to accomplish 80 percent of modern data tasks. Lander's self-contained chapters start with the absolute basics, offering extensive hands-on practice and sample code. You'll download and install R; navigate and use the R environment; master basic program control, data import, manipulation, and visualization; and walk through several essential tests. Then, building on this foundation, you'll construct several complete models, both linear and nonlinear, and use some data mining techniques. After all this you'll make your code reproducible with LaTeX, RMarkdown, and Shiny. By the time you're done, you won't just know how to write R programs, you'll be ready to tackle the statistical problems you care about most. -- Provided by publisher.},
annote = {2017934582 Jared P. Lander. illustrations (some color) ; 23 cm. Includes indexes. Getting R -- The R environment -- R packages -- Basics of R -- Advanced data structures -- Reading data into R -- Statistical graphics -- Writing R functions -- Control statements -- Loops, the Un-R way to iterate -- Group manipulation -- Faster group manipulation with dplyr -- Iterating with purrr -- Data reshaping -- Reshaping data in the Tidyverse -- Manipualting strings -- Probability distributions -- Basic statistics -- Linear models -- Generalized linear models -- Model diagnostics -- Regularization and shrinkage -- Nonlinear models -- Time series and autocorrelation -- Clustering -- Model fitting with Caret -- Reproducibility and reports with knitr -- Rich documents with RMarkdown -- Interactive dashboards with shiny -- Building R packages -- Real-life resources. Addison-Wesley data and analytics series.},
author = {Lander, Jared P C N - HARRISBURG INTRANSIT QA76.73.R3L36 2017 BOOKFLOAT},
booktitle = {R for everyone : advanced analytics and graphics},
edition = {Second edi},
isbn = {013454692X 9780134546926},
keywords = {R (Computer program language) Scripting languages},
pages = {xxiv, 528 pages},
title = {{Chapter 4: R Basics}},
year = {2017}
}
@article{Teal2015,
annote = {Cited By :15 Export Date: 17 November 2017},
author = {Teal, T K and Cranston, K A and Lapp, H and White, E and Wilson, G and Ram, K and Pawlik, A},
journal = {International Journal of Digital Curation},
number = {1},
pages = {135--143},
title = {{Data carpentry: workshops to increase data literacy for researchers}},
volume = {10},
year = {2015}
}
@misc{Zozus2017,
abstract = {While several standards for metadata describing clinical studies exist, comprehensive metadata to support traceability of data from clinical studies has not been articulated. We examine uses of metadata in clinical studies. We examine and enumerate seven sources of data value-level metadata in clinical studies inclusive of research designs across the spectrum of the National Institutes of Health definition of clinical research. The sources of metadata inform categorization in terms of metadata describing the origin of a data value, the definition of a data value, and operations to which the data value was subjected. The latter is further categorized into information about changes to a data value, movement of a data value, retrieval of a data value, and data quality checks, constraints or assessments to which the data value was subjected. The implications of tracking and managing data value-level metadata are explored. {\textcopyright} 2017 The authors and IOS Press.},
address = {Department of Biomedical Informatics, University of Arkansas for Medical Sciences, 4301 W. Markham St. {\#}782AR, United States Ascension Health, National Data Governance Office, St. Louis, MO, United States},
annote = {Export Date: 17 November 2017 Correspondence Address: Zozus, M.N.; Department of Biomedical Informatics, University of Arkansas for Medical Sciences, 4301 W. Markham St. {\#}782, United States},
author = {Zozus, M N and Bonner, J},
booktitle = {Studies in Health Technology and Informatics},
doi = {10.3233/978-1-61499-742-9-418},
editor = {Kuo, A and Borycki, E and Lau, F and Bliss, G and Courtney, K and Bartle-Clar, J B C},
isbn = {09269630 (ISSN); 9781614997412 (ISBN)},
keywords = {Clinical Research Informatics data quality metadat},
language = {English},
pages = {418--423},
publisher = {IOS Press},
title = {{Towards data value-level metadata for clinical studies}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85012255183{\&}doi=10.3233{\%}2F978-1-61499-742-9-418{\&}partnerID=40{\&}md5=f5d614c820e86530cd40ab7297260755},
volume = {234},
year = {2017}
}
@article{Mattern2015,
abstract = {Purpose – The purpose of this paper is to report on an information gathering study on users' research data-related challenges and proposals for library research data services (RDS). This study probes how early career researchers visually conceptualize the research process in their disciplines, their self-reported research data challenges, and their recommendations for library RDS. Design/methodology/approach – Two focus group sessions were undertaken with a total of eight early career researchers. Adopting the visual narrative inquiry method, the participants were asked to sketch the general research process in their domain. The individuals' illustrations of the research process were then used as the basis for reflecting on their data-related needs and potential RDS that would assist them during the research process. Findings – Participants presented a research process that was more personal and, in most cases, more imperfect than the research lifecycle models that academic libraries are increasingly using for RDS development and communication. The authors present their data-related challenges, which included data access barriers, low knowledge of best practices for research data management, the need for a deeper understanding of post-publication impact, and inconsistent awareness of existing library and institution RDS. The authors outline RDS recommendations that participants proposed, which included a web-based tools, customized training sessions, and “distilled” guides to research data best practices. Practical implications – The study flagged users' gaps in understandings of existing library and institutional RDS, suggesting that there may be an opportunity to engage users in the design of communications plans for services. The findings from this user study will inform the development of RDS at the institution. Originality/value – This paper puts forth a methodological approach that academic libraries can adapt for understanding users' needs and user-generated design solutions. [ABSTRACT FROM AUTHOR] Copyright of Program is the property of Emerald Publishing and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
annote = {Mattern, Eleanor 1; Jeng, Wei 2; He, Daqing 2; Lyon, Liz 2; Brenner, Aaron 3; Affiliations: 1 : School of Information Sciences and University Library System, University of Pittsburgh, Pittsburgh, PA, USA; 2 : School of Information Sciences, University of Pittsburgh, Pittsburgh, PA, USA; 3 : University Library System, University of Pittsburgh, Pittsburgh, PA, USA; Source Info: 2015, Vol. 49 Issue 4, p408; Thesaurus Term: Information resources management; Thesaurus Term: Academic libraries; Thesaurus Term: Library research; Thesaurus Term: Web-based instruction; Subject Term: Participatory design; Author-Supplied Keyword: Library service development; Author-Supplied Keyword: Research data services; Author-Supplied Keyword: Visual narrative inquiry; Number of Pages: 16p; Document Type: Article; Full Text Word Count: 6653},
author = {Mattern, Eleanor and Jeng, Wei and He, Daqing and Lyon, Liz and Brenner, Aaron},
doi = {10.1108/PROG-01-2015-0012},
issn = {00330337},
journal = {Program},
keywords = {Information resources management Academic librarie},
number = {4},
pages = {408--423},
title = {{Using participatory design and visual narrative inquiry to investigate researchers' data challenges and recommendations for library research data services}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=lxh{\&}AN=109379165{\&}site=ehost-live},
volume = {49},
year = {2015}
}
@article{Conrad2017,
abstract = {Research data management represents a significant professional development area for academic librarians – significant for its growing importance to the profession, since researchers are increasingly expected to comply with research data management requirements, and for the extent of competence needed by librarians to support researchers in research data management practices and plans. This article recounts how the Association of College and Research Libraries is fostering professional development opportunities in research data management. The authors describe two key endeavors: (1) the development and deployment of a needs assessment survey, which allowed insight into the types of librarians expressing the most need; and (2) planning and implementation of a pre-conference workshop for ACRL 2015, intended to prototype a future professional development offering. The article concludes by discussing additional assessment that was done following the workshop and how the pre-conference laid the foundation for proposing a “roadshow” for research data management, similar to what the Association of College and Research Libraries sponsors for scholarly communication. [ABSTRACT FROM AUTHOR] Copyright of IFLA Journal is the property of Sage Publications, Ltd. and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
annote = {Conrad, Suzanna 1; Shorish, Yasmeen 2; Email Address: shorisyl@jmu.edu; Whitmire, Amanda L. 3; Hswe, Patricia 4; Affiliations: 1 : California State University, USA; 2 : James Madison University, USA; 3 : Stanford University, USA; 4 : Andrew W. Mellon Foundation, USA; Source Info: Mar2017, Vol. 43 Issue 1, p65; Thesaurus Term: Data transmission systems; Thesaurus Term: Academic librarians; Thesaurus Term: Digital libraries; Subject Term: Professional education; Subject Term: Communication in learning {\&} scholarship; Author-Supplied Keyword: Academic libraries; Author-Supplied Keyword: data management; Author-Supplied Keyword: data services; Author-Supplied Keyword: professional development; Author-Supplied Keyword: professional organizations; Number of Pages: 16p; Document Type: Article; Full Text Word Count: 9319},
author = {Conrad, Suzanna and Shorish, Yasmeen and Whitmire, Amanda L and Hswe, Patricia},
doi = {10.1177/0340035216678237},
issn = {03400352},
journal = {IFLA Journal},
keywords = {Data transmission systems Academic librarians Digi},
number = {1},
pages = {65--80},
title = {{Building professional development opportunities in data services for academic librarians}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=lxh{\&}AN=121559483{\&}site=ehost-live},
volume = {43},
year = {2017}
}
@article{Whitmire2015,
abstract = {Purpose – The purpose of this paper is to demonstrate how knowledge of local research data management (RDM) practices critically informs the progressive development of research data services (RDS) after basic services have already been established. Design/methodology/approach – An online survey was distributed via e-mail to all university faculty in the fall of 2013, and was left open for just over one month. The authors sent two reminder e-mails before closing the survey. Survey data were downloaded from Qualtrics survey software and analyzed in R. Findings – In this paper, the authors reviewed a subset of survey findings that included data types, volume, and storage locations, RDM roles and responsibilities, and metadata practices. The authors found that Oregon State University (OSU) researchers are generating a wide variety of data types, and that practices vary between colleges. The authors discovered that faculty are not utilizing campus-wide storage infrastructure, and are maintaining their own storage servers in surprising numbers. Faculty-level research assistants perform the majority of data-related tasks at OSU, with the exception of data sharing, which is primarily handled by the professorial ranks. The authors found that many faculty on campus are creating metadata, but that there is a need to provide support in how to discover and create standardized metadata. Originality/value – This paper presents a novel example of how to efficiently move from establishing basic RDM services to providing more focussed services that meet specific local needs. It provides an approach for others to follow when tackling the difficult question of, “What next?” with regard to providing academic RDS. [ABSTRACT FROM AUTHOR] Copyright of Program is the property of Emerald Publishing and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
annote = {Whitmire, Amanda L. 1; Boock, Michael 1; Sutton, Shan C. 2; Affiliations: 1 : Oregon State University, Corvallis, Oregon, USA; 2 : University of Arizona, Tuscon, Arizona, USA; Source Info: 2015, Vol. 49 Issue 4, p382; Thesaurus Term: RESEARCH; Thesaurus Term: Information sharing; Thesaurus Term: Information resources management; Thesaurus Term: Research; Thesaurus Term: UNIVERSITIES {\&} colleges; Thesaurus Term: Metadata; Subject Term: Education; Author-Supplied Keyword: Academic libraries; Author-Supplied Keyword: Data management; Author-Supplied Keyword: Data sharing; Author-Supplied Keyword: Research data services; Author-Supplied Keyword: Survey; Number of Pages: 26p; Document Type: Article; Full Text Word Count: 7549},
author = {Whitmire, Amanda L and Boock, Michael and Sutton, Shan C},
doi = {10.1108/PROG-02-2015-0017},
issn = {00330337},
journal = {Program},
keywords = {RESEARCH Information sharing Information resources},
number = {4},
pages = {382--407},
title = {{Variability in academic research data management practices}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=lxh{\&}AN=109379168{\&}site=ehost-live},
volume = {49},
year = {2015}
}
@article{,
annote = {Source Info: 2017, Issue 3, p476; Number of Pages: 2p; Document Type: Article; Language: Hungarian},
issn = {00233773},
journal = {Library Review / Konyvtari Figyelo},
number = {3},
pages = {476--477},
title = {{Data literacy for researchers and data librarians}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=lxh{\&}AN=125597113{\&}site=ehost-live},
year = {2017}
}
@article{Wang2015,
abstract = {This case study details how a data services librarian and a science librarian collaborate to provide embedded data management support for the research-oriented Department of Earth {\&} Environmental Sciences at Rutgers University–Newark. Combining their familiarity with emerging professional practices and resources, their efforts to gain a deeper understanding of the specific data management needs of researchers in the department, and their research into the evolving research data infrastructure in that particular discipline, the two are able to successfully connect researchers with the best practices in data management, suitable data repositories, and experts in the campus' Computing Services unit. [ABSTRACT FROM AUTHOR] Copyright of Science {\&} Technology Libraries is the property of Taylor {\&} Francis Ltd and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
annote = {Wang, Minglu 1; Fong, Bonnie L. 1; Affiliations: 1 : John Cotton Dana Library, Rutgers University–Newark, New Jersey; Source Info: Jul-Sep2015, Vol. 34 Issue 3, p228; Thesaurus Term: Data libraries; Thesaurus Term: Library science; Thesaurus Term: Database management; Subject Term: Best practices; Author-Supplied Keyword: academic libraries; Author-Supplied Keyword: data management support; Author-Supplied Keyword: data services; Author-Supplied Keyword: embedded librarianship; Author-Supplied Keyword: science librarians; Number of Pages: 13p; Document Type: Article},
author = {Wang, Minglu and Fong, Bonnie L},
doi = {10.1080/0194262X.2015.1085348},
issn = {0194262X},
journal = {Science {\&} Technology Libraries},
keywords = {Data libraries Library science Database management},
number = {3},
pages = {228--240},
title = {{Embedded Data Librarianship: A Case Study of Providing Data Management Support for a Science Department}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=lxh{\&}AN=110811307{\&}site=ehost-live},
volume = {34},
year = {2015}
}
@article{Williams2013,
abstract = {Making connections with faculty can be challenging for librarians developing new data services programs. In order to identify faculty with a variety of data experiences, the author conducted a review of selected recent publications by sixty-two agricultural faculty members at the University of Illinois at Urbana–Champaign. As a follow-up, faculty who had publicly shared data beyond that published in an article were contacted directly to request interviews to discuss data sharing. These active, targeted messages have generated more faculty response than the general data services announcements previously broadcast. Bibliographic studies are a known method for librarians, but using this method to identify faculty candidates for data services represents a new application. The advantages and disadvantages of this approach are discussed. [ABSTRACT FROM AUTHOR] Copyright of Science {\&} Technology Libraries is the property of Taylor {\&} Francis Ltd and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
annote = {Williams, Sarah C. 1; Email Address: scwillms@illinois.edu; Affiliations: 1 : University of Illinois at Urbana–Champaign , Urbana , Illinois; Source Info: 2013, Vol. 32 Issue 2, p202; Thesaurus Term: Librarians; Thesaurus Term: Collection development in libraries; Subject Term: Universities {\&} colleges -- Faculty; Subject Term: Science projects; Subject Term: Libraries -- Illinois; Author-Supplied Keyword: connections; Author-Supplied Keyword: data services; Author-Supplied Keyword: faculty; Author-Supplied Keyword: publications; Number of Pages: 8p; Document Type: Article},
author = {Williams, Sarah C},
doi = {10.1080/0194262X.2013.774622},
issn = {0194262X},
journal = {Science {\&} Technology Libraries},
keywords = {Librarians Collection development in libraries Uni},
number = {2},
pages = {202--209},
title = {{Using a Bibliographic Study to Identify Faculty Candidates for Data Services}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=lxh{\&}AN=88212311{\&}site=ehost-live},
volume = {32},
year = {2013}
}
@article{Jingfeng2014,
abstract = {This study examines job announcements for social science data librarians and professionals to identify trends in the profession. A collection of 167 job postings in 2005-2012 from the International Association for Social Science Information Services {\&}Technology website was analyzed on the frequencies of term occurrence and co-occurrence in job qualifications and responsibilities. The study verifies that employers valued non-technical skills as heavily as technical skills, and detects dissimilar emphases of data activities for data librarians and non-librarian professionals: the former on data discovery and collection, and the latter on data analysis and preservation. An increasing requirement of data management planning was also found for data librarians. [ABSTRACT FROM AUTHOR] Copyright of College {\&} Research Libraries is the property of American Library Association and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
annote = {Jingfeng Xia 1; Email Address: xiaji@iupui.edu; Minglu Wang 2; Email Address: minglu@rutgers.edu; Affiliations: 1 : Associate Professor, Department of Library and Information Science, Indiana University; 2 : Data Services Librarian, John Cotton Data Library, Rutgers, the State University of New Jersey; Source Info: May2014, Vol. 75 Issue 3, p362; Thesaurus Term: Employment of librarians; Thesaurus Term: Data libraries; Subject Term: Job postings; Subject Term: Job qualifications; Subject Term: Job descriptions; Subject Term: Job skills; Number of Pages: 27p; Document Type: Article; Full Text Word Count: 11170},
author = {Jingfeng, Xia and Minglu, Wang},
issn = {00100870},
journal = {College {\&} Research Libraries},
keywords = {Employment of librarians Data libraries Job postin},
number = {3},
pages = {362--388},
title = {{Competencies and Responsibilities of Social Science Data Librarians: An Analysis of Job Descriptions}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=lxh{\&}AN=95901478{\&}site=ehost-live},
volume = {75},
year = {2014}
}
@article{Henderson2015,
abstract = {As the need for research data management grows, many libraries are considering adding data services to help with the research mission of their institution. The Virginia Commonwealth University (VCU) Libraries created a position and hired a director of research data management in September 2013. The position was new to the libraries and the university. With the backing of the library administration, a plan for building relationships with VCU faculty, researchers, students, service and resource providers, including grant administrators, was developed to educate and engage the community in data management plan writing and research data management training. [ABSTRACT FROM AUTHOR] Copyright of Medical Reference Services Quarterly is the property of Taylor {\&} Francis Ltd and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
annote = {Henderson, Margaret E. 1; Knott, Teresa L. 1; Affiliations: 1 : VCU Libraries, Virginia Commonwealth University, Richmond, Virginia, USA; Source Info: Jan-Mar2015, Vol. 34 Issue 1, p47; Thesaurus Term: Database management; Thesaurus Term: Information retrieval; Thesaurus Term: Research; Subject Term: Academic libraries -- Virginia; Subject Term: Endowments; Subject Term: Human services programs; Subject: Virginia; Author-Supplied Keyword: Data management plans; Author-Supplied Keyword: data services; Author-Supplied Keyword: research data management; Number of Pages: 13p; Document Type: Article},
author = {Henderson, Margaret E and Knott, Teresa L},
doi = {10.1080/02763869.2015.986783},
issn = {02763869},
journal = {Medical Reference Services Quarterly},
keywords = {Database management Information retrieval Research},
number = {1},
pages = {47--59},
title = {{Starting a Research Data Management Program Based in a University Library}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=lxh{\&}AN=100577461{\&}site=ehost-live},
volume = {34},
year = {2015}
}
@article{Joque2014,
abstract = {Aligning data and research infrastructure is, as our daily work often reminds us, a difficult process. While data professionals often focus on research lifecycles, incentives, storage and transmission technologies, metadata and data sharing we tend to overlook the epistemological incongruences of diverse research and data practices. All data creation processes, even if unknowingly, make assumptions about the world and what exists as a unique unit that can be analyzed. In attempting to make data meaningful to different audiences, especially across disciplines, we must pay attention to these epistemological assumptions. Failure to do so will inevitably frustrate our attempts to develop meaningful infrastructure for research data and even potentially undermine effective research through misunderstandings of data. Looking at census and zip code data as examples, this paper explores the issue of unit of analysis as an example of such disciplinary epistemological assumptions. The complexities that arise even in these simple examples suggest the importance of addressing the theoretical complexities of dealing with data collections, management and interpretation. [ABSTRACT FROM AUTHOR] Copyright of IASSIST Quarterly is the property of IASSIST Quarterly and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
annote = {Joque, Justin 1; Affiliations: 1 : Librarian, University of Michigan in Ann Arbor, Michigan, USA; Source Info: 2014, Vol. 38 Issue 2, p7; Thesaurus Term: Data libraries; Thesaurus Term: Data warehousing; Thesaurus Term: Information storage {\&} retrieval systems; Author-Supplied Keyword: Categorization; Author-Supplied Keyword: Critique; Author-Supplied Keyword: Data Profession; Author-Supplied Keyword: Data Theory; Author-Supplied Keyword: Epistemology; Author-Supplied Keyword: Harmonization; Number of Pages: 5p; Document Type: Article},
author = {Joque, Justin},
issn = {07391137},
journal = {IASSIST Quarterly},
keywords = {Data libraries Data warehousing Information storag},
number = {2},
pages = {7--11},
title = {{From Data to the Creation of Meaning Part 1: Unit of Analysis as Epistemological Problem}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=lxh{\&}AN=102065483{\&}site=ehost-live},
volume = {38},
year = {2014}
}
@article{Wright2016,
abstract = {REDCap is an electronic data capture software that allows the easy building of research instruments while providing collaboration capabilities, meta-data workflow, security, auditing, and export to common statistical packages. Medical librarians have used REDCap for both research data capture as well as operational databases. {\textcopyright} 2016, Published with license by Taylor {\&} Francis {\textcopyright} Andrea Wright.},
address = {Biomedical Library, University of South Alabama, Mobile, AL, United States},
annote = {Export Date: 17 November 2017 Correspondence Address: Wright, A.; Biomedical Library, University of South Alabama, 5791 USA Drive N, United States; email: awright@southalabama.edu},
author = {Wright, A},
doi = {10.1080/15424065.2016.1259026},
issn = {15424065 (ISSN)},
journal = {Journal of Electronic Resources in Medical Libraries},
keywords = {Data management REDCap research data data base hum},
language = {English},
number = {4},
pages = {197--201},
title = {{REDCap: A Tool for the Electronic Capture of Research Data}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85006124111{\&}doi=10.1080{\%}2F15424065.2016.1259026{\&}partnerID=40{\&}md5=8e41573d47bc1651f5ca070a75be2247},
volume = {13},
year = {2016}
}
@article{Cox2017,
abstract = {This article reports an international study of research data management (RDM) activities, services, and capabilities in higher education libraries. It presents the results of a survey covering higher education libraries in Australia, Canada, Germany, Ireland, the Netherlands, New Zealand, and the UK. The results indicate that libraries have provided leadership in RDM, particularly in advocacy and policy development. Service development is still limited, focused especially on advisory and consultancy services (such as data management planning support and data-related training), rather than technical services (such as provision of a data catalog, and curation of active data). Data curation skills development is underway in libraries, but skills and capabilities are not consistently in place and remain a concern. Other major challenges include resourcing, working with other support services, and achieving "buy in" from researchers and senior managers. Results are compared with previous studies in order to assess trends and relative maturity levels. The range of RDM activities explored in this study are positioned on a "landscape maturity model," which reflects current and planned research data services and practice in academic libraries, representing a "snapshot" of current developments and a baseline for future research. [ABSTRACT FROM AUTHOR] Copyright of Journal of the Association for Information Science {\&} Technology is the property of John Wiley {\&} Sons, Inc. and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
annote = {Cox, Andrew M. 1; Email Address: a.m.cox@sheffield.ac.uk; Kennan, Mary Anne 2; Email Address: mkennan@csu.edu.au; Lyon, Liz 3; Email Address: elyon@pitt.edu; Pinfield, Stephen 1; Email Address: s.pinfield@sheffield.ac.uk; Affiliations: 1 : Information School, University of Sheffield, Regent Court, 211 Portobello, Sheffield, S1 4DP, UK; 2 : School of Information Studies, Charles Sturt University - Sydney, Locked Bag 450, Silverwater, NSW 2128, Australia; 3 : School of Information Sciences, University of Pittsburgh, Information Sciences Building, 135 North Bellefield Avenue, Pittsburgh, PA 15260; Source Info: Sep2017, Vol. 68 Issue 9, p2182; Thesaurus Term: Library education; Thesaurus Term: Database management; Thesaurus Term: Questionnaires; Thesaurus Term: Research; Thesaurus Term: Surveys; Thesaurus Term: Technical services (Libraries); Subject Term: Academic libraries -- United States; Subject Term: Academic libraries -- Great Britain; Subject Term: Academic libraries -- Australia; Subject Term: Academic libraries -- Europe; Subject Term: Academic libraries -- New Zealand; Subject: Australia; Subject: Europe; Subject: Great Britain; Subject: New Zealand; Subject: United States; Number of Pages: 18p; Document Type: Article},
author = {Cox, Andrew M and Kennan, Mary Anne and Lyon, Liz and Pinfield, Stephen},
issn = {23301635},
journal = {Journal of the Association for Information Science {\&} Technology},
keywords = {Library education Database management Questionnair},
number = {9},
pages = {2182--2199},
title = {{Developments in Research Data Management in Academic Libraries: Towards an Understanding of Research Data Service Maturity}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=lxh{\&}AN=124675497{\&}site=ehost-live},
volume = {68},
year = {2017}
}
@article{Witt2016,
abstract = {An introduction is presented in which the editor discusses various reports within the issue on topics including innovative data management services offered by the libraries, and libraries research data services.},
annote = {Witt, Michael 1; Horstmann, Wolfram 2; Affiliations: 1 : Purdue University, West Lafayette, Indiana, USA; 2 : G{\"{o}}ttingen State and University Library, University of G{\"{o}}ttingen, Germany; Source Info: Dec2016, Vol. 42 Issue 4, p251; Thesaurus Term: Data; Thesaurus Term: Libraries; Subject Term: Data -- Management; Number of Pages: 2p; Document Type: Article; Full Text Word Count: 883},
author = {Witt, Michael and Horstmann, Wolfram},
doi = {10.1177/0340035216678726},
issn = {03400352},
journal = {IFLA Journal},
keywords = {Data Libraries Data -- Management},
number = {4},
pages = {251--252},
title = {{International approaches to research data services in libraries}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=lxh{\&}AN=119926522{\&}site=ehost-live},
volume = {42},
year = {2016}
}
@article{Rong2016,
abstract = {In this study, an exploratory content analysis of 30 randomly selected Data Science (DS) programs from eight disciplines revealed significant gaps in current DS education in the United States. The analysis centers on linguistic patterns of program descriptions, curriculum requirements, and DS course focus as pertaining to key skills and domain knowledge. The results show that a range of unique terms was used in individual program descriptions, with common terms being shared across disciplines. DS programs required varying numbers of credit hours, including practicum and capstone. Most DS courses covered the basic level of analytical skills, but upper-level skills were inadequately addressed. Programs in eight disciplines delivered information skills through their core courses, and four addressed communication skills. Six disciplines covered visualization skills through their core courses, yet just three in elective courses. The course offering on mathematics/statistics was rather weak in iSchools. While core courses in iSchools provided communication and visualization skills, their electives courses did not address such skills. These findings have implications for improving DS education in iSchools and across other disciplines. [ABSTRACT FROM AUTHOR] Copyright of Education for Information is the property of IOS Press and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
annote = {Rong Tang 1; Email Address: rong.tang@simmons.edu; Watinee Sae-Lim 1; Affiliations: 1 : School of Library and Information Science, Simmons College, Boston, MA, USA; Source Info: 2016, Vol. 32 Issue 3, p269; Thesaurus Term: Data science (Information science); Subject Term: Computer science education (Higher); Subject Term: Curricula (Courses of study) -- United States; Subject Term: Communicative competence; Subject Term: Information skills; Subject Term: Higher education; Author-Supplied Keyword: course focus; Author-Supplied Keyword: curriculum structure; Author-Supplied Keyword: Data science (DS) programs; Author-Supplied Keyword: ischools; Author-Supplied Keyword: program description; Number of Pages: 22p; Illustrations: 7 Charts, 4 Graphs; Document Type: Article},
author = {Rong, Tang and Watinee, Sae-Lim},
doi = {10.3233/EFI-160977},
issn = {01678329},
journal = {Education for Information},
keywords = {Data science (Information science) Computer scienc},
number = {3},
pages = {269--290},
title = {{Data science programs in U.S. higher education: An exploratory content analysis of program description, curriculum structure, and course focus}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=lxh{\&}AN=117173791{\&}site=ehost-live},
volume = {32},
year = {2016}
}
@article{Tenopir2017,
abstract = {Research data is an essential part of the scholarly record, and management of research data is increasingly seen as an important role for academic libraries. This article presents the results of a survey of directors of the Association of European Research Libraries (LIBER) academic member libraries to discover what types of research data services (RDS) are being offered by European academic research libraries and what services are planned for the future. Overall, the survey found that library directors strongly agree on the importance of RDS. As was found in earlier studies of academic libraries in North America, more European libraries are currently offering or are planning to offer consultative or reference RDS than technical or hands-on RDS. The majority of libraries provide support for training in skills related to RDS for their staff members. Almost all libraries collaborate with other organizations inside their institutions or with outside institutions in order to offer or develop policy related to RDS. We discuss the implications of the current state of RDS in European academic research libraries, and offer directions for future research. [ABSTRACT FROM AUTHOR] Copyright of Liber Quarterly: The Journal of European Research Libraries is the property of Universiteit Utrecht and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
annote = {Tenopir, Carol 1; Email Address: ctenopir@utk.edu; Talja, Sanna 2; Email Address: Sanna.K.Talja@uta.i; Horstmann, Wolfram 3; Email Address: horstmann@sub.uni-goettingen.de; Late, Elina 2; Email Address: elina.late@uta.i; Hughes, Dane 1; Email Address: tmc752@utk.edu; Pollock, Danielle 1; Email Address: dpolloc2@vols.utk.edu; Schmidt, Birgit 3; Email Address: bschmidt@sub.uni-goettingen.de; Baird, Lynn 4; Email Address: lbaird@uidaho.edu; Sandusky, Robert J. 5; Email Address: sandusky@uic.edu; Allard, Suzie 1; Email Address: sallard@utk.edu; Affiliations: 1 : University of Tennessee; 2 : University of Tampere; 3 : University of Gottingen; 4 : University of Idaho; 5 : University of Illinois at Chicago; Source Info: 2017, Vol. 27 Issue 1, p23; Thesaurus Term: Academic libraries; Thesaurus Term: UNIVERSITIES {\&} colleges; Thesaurus Term: Data analysis; Subject Term: Data -- Management; Subject Term: Research; Subject Term: Management research; Author-Supplied Keyword: academic libraries; Author-Supplied Keyword: data management; Author-Supplied Keyword: research data services; Number of Pages: 22p; Document Type: Article},
author = {Tenopir, Carol and Talja, Sanna and Horstmann, Wolfram and Late, Elina and Hughes, Dane and Pollock, Danielle and Schmidt, Birgit and Baird, Lynn and Sandusky, Robert J and Allard, Suzie},
doi = {10.18352/lq.10180},
issn = {14355205},
journal = {Liber Quarterly: The Journal of European Research Libraries},
keywords = {Academic libraries UNIVERSITIES {\&} colleges Data an},
number = {1},
pages = {23--44},
title = {{Research Data Services in European Academic Research Libraries}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=lxh{\&}AN=121616550{\&}site=ehost-live},
volume = {27},
year = {2017}
}
@article{Margolis2014,
abstract = {Biomedical research has and will continue to generate large amounts of data (termed 'big data') in many formats and at all levels. Consequently, there is an increasing need to better understand and mine the data to further knowledge and foster new discovery. The National Institutes of Health (NIH) has initiated a Big Data to Knowledge (BD2K) initiative to maximize the use of biomedical big data. BD2K seeks to better define how to extract value from the data, both for the individual investigator and the overall research community, create the analytic tools needed to enhance utility of the data, provide the next generation of trained personnel, and develop data science concepts and tools that can be made available to all stakeholders. [ABSTRACT FROM AUTHOR] Copyright of Journal of the American Medical Informatics Association is the property of Oxford University Press / USA and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
annote = {Margolis, Ronald 1; Email Address: margolisr@mail.nih.gov; Derr, Leslie 2; Dunn, Michelle 3; Huerta, Michael 4; Larkin, Jennie 5; Sheehan, Jerry 4; Guyer, Mark 6; Green, Eric D. 6; Affiliations: 1 : National Institute of Diabetes and Digestive and Kidney Diseases, NIH, Bethesda, Maryland, USA; 2 : Office of the Director, NIH, Bethesda, Maryland, USA; 3 : National Cancer Institute, NIH, Bethesda, Maryland, USA; 4 : National Library of Medicine, NIH, Bethesda, Maryland, USA; 5 : National Heart, Lung and Blood Institute, NIH, Bethesda, Maryland, USA; 6 : National Human Genome Research Institute, NIH, Bethesda, Maryland, USA; Source Info: Nov2014, Vol. 21 Issue 6, p957; Thesaurus Term: Big data; Thesaurus Term: Data science (Information science); Thesaurus Term: Databases; Thesaurus Term: Electronic data processing; Thesaurus Term: Medical informatics; Subject Term: Biological research; Subject Term: Medical research; Number of Pages: 2p; Document Type: Article},
author = {Margolis, Ronald and Derr, Leslie and Dunn, Michelle and Huerta, Michael and Larkin, Jennie and Sheehan, Jerry and Guyer, Mark and Green, Eric D},
doi = {10.1136/amiajnl-2014-002974},
issn = {10675027},
journal = {Journal of the American Medical Informatics Association},
keywords = {Big data Data science (Information science) Databa},
number = {6},
pages = {957--958},
title = {{The National Institutes of Health's Big Data to Knowledge (BD2K) initiative: capitalizing on biomedical big data}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=lxh{\&}AN=98991112{\&}site=ehost-live},
volume = {21},
year = {2014}
}
@unpublished{MarcialPortilla2017,
author = {{Marcial Portilla}, Jose},
publisher = {Udemy},
title = {{Python for Data Science and Machine Learning Bootcamp}},
url = {https://www.pieriandata.com/p/python-for-data-science-and-machine-learning-bootcamp},
year = {2017}
}
@misc{WolskiSamantha2015,
abstract = {Purpose – The purpose of this paper is to describe the evolution to date and future directions in research data policy, infrastructure, skills development and advisory services in an Australian university, with a focus on the role of librarians. Design/methodology/approach – The authors have been involved in the development of research data services at Griffith, and the case study presents observations and reflections arising from their first-hand experiences. Findings – Griffith University's organisational structure and “whole-of-enterprise” approach has facilitated service development to support research data. Fostering strong national partnerships has also accelerated development of institutional capability. Policies and strategies are supported by pragmatic best practice guidelines aimed directly at researchers. Iterative software development and a commitment to well-supported enterprise infrastructure enable the provision of a range of data management solutions. Training programs, repository support and data planning services are still relatively immature. Griffith recognises that information services staff (including librarians) will need more opportunities to develop knowledge and skills to support these services as they evolve. Originality/value – This case study provides examples of library-led and library-supported activities that could be used for comparative purposes by other libraries. At the same time, it provides a critical perspective by contrasting areas of good practice within the University with those of less satisfactory progress. While other institutions may have different constraints or opportunities, some of the major concepts within this paper may prove useful to advance the development of research data capability and capacity across the library profession. [ABSTRACT FROM AUTHOR] Copyright of Program is the property of Emerald Publishing and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
annote = {Accession Number: 109379166; Searle, Samantha 1; Wolski, Malcolm 1; Simons, Natasha 1; Richardson, Joanna 1; Affiliations: 1 : Information Services, Griffith University, Brisbane, Australia; Source Info: 2015, Vol. 49 Issue 4, p440; Thesaurus Term: Information resources management; Thesaurus Term: Data libraries; Thesaurus Term: Information services; Thesaurus Term: Academic librarians; Author-Supplied Keyword: Data; Author-Supplied Keyword: Infrastructure; Author-Supplied Keyword: Libraries; Author-Supplied Keyword: Policy; Author-Supplied Keyword: Services; Author-Supplied Keyword: Skills; Number of Pages: 21p; Document Type: Case Study; Full Text Word Count: 10172},
doi = {10.1108/PROG-02-2015-0013},
editor = {{Wolski  Samantha}, Malcolm A4 - Searle},
keywords = {Information resources management Data libraries In},
pages = {440--460},
title = {{Librarians as partners in research data service development at Griffith University}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=lxh{\&}AN=109379166{\&}site=ehost-live},
volume = {49},
year = {2015}
}
@article{Reinhalter2014,
abstract = {Since 2012, nearly every sector has developed a fascination with the seemingly new discovery of Big Data and its unprecedented capabilities to fuel analytic breakthroughs. It is clear that the use of Big Data as an information resource will continue to become more prevalent as it is employed in academic research and data-driven decision making, and even emerges as a vehicle for government transparency. This article reviews the emergence and potentials of Big Data, describes the policies fueling the current data surge, and discusses the impact on libraries. As libraries evolve to provide more data services, there is an opportunity for librarians to become experts and authorities in the data age. [ABSTRACT FROM AUTHOR] Copyright of Serials Librarian is the property of Taylor {\&} Francis Ltd and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
annote = {Reinhalter, Lauren 1; Wittmann, Rachel J. 1; Affiliations: 1 : Pratt Institute, New York, New York, USA; Source Info: Nov/Dec2014, Vol. 67 Issue 4, p363; Thesaurus Term: Database management; Thesaurus Term: Librarians; Thesaurus Term: Libraries; Subject Term: Occupational roles; Author-Supplied Keyword: Big Data; Author-Supplied Keyword: data curation; Author-Supplied Keyword: data librarianship; Author-Supplied Keyword: library education; Author-Supplied Keyword: Open Government; Author-Supplied Keyword: skills and training; Number of Pages: 10p; Document Type: Article},
author = {Reinhalter, Lauren and Wittmann, Rachel J},
doi = {10.1080/0361526X.2014.915605},
issn = {0361526X},
journal = {Serials Librarian},
keywords = {Database management Librarians Libraries Occupatio},
number = {4},
pages = {363--372},
title = {{The Library: Big Data's Boomtown}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=lxh{\&}AN=100355964{\&}site=ehost-live},
volume = {67},
year = {2014}
}
@article{Brown2015,
abstract = {In recent years, there has been considerable discussion about the key role which university libraries can play by engaging with their research community. As a result libraries are scoping, developing and implementing new roles and service models, especially in the relatively new area of research data. This article explores the specific challenges experienced by a traditional academic librarian at Griffith University as she moved into a new role as a data librarian. It was found that this transition needed to be underpinned by a skills development programme, a mentor/coach and a support network of specialists. The authors then outline some strategies to facilitate this type of role transition, which include investing in a range of training and staff development activities, leveraging existing core librarian capabilities and understanding the researcher perspective. The article concludes with a suggestion that several national organisations will continue to have an important role in supporting librarians as they develop new skills. [ABSTRACT FROM PUBLISHER] Copyright of Australian Library Journal is the property of Routledge and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
annote = {Brown, Rebecca A. 1; Wolski, Malcolm 1; Richardson, Joanna 1; Affiliations: 1 : Division of Information Services, Griffith University, Brisbane, Australia; Source Info: Aug2015, Vol. 64 Issue 3, p224; Thesaurus Term: Data libraries; Thesaurus Term: Academic libraries; Thesaurus Term: Libraries; Thesaurus Term: Data protection; Subject Term: Scientific community; Author-Supplied Keyword: data librarian; Author-Supplied Keyword: library roles; Author-Supplied Keyword: research data management; Author-Supplied Keyword: research data services; Author-Supplied Keyword: research libraries; Number of Pages: 11p; Document Type: Article},
author = {Brown, Rebecca A and Wolski, Malcolm and Richardson, Joanna},
doi = {10.1080/00049670.2015.1041215},
issn = {00049670},
journal = {Australian Library Journal},
keywords = {Data libraries Academic libraries Libraries Data p},
number = {3},
pages = {224--234},
title = {{Developing new skills for research support librarians}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=lxh{\&}AN=108394497{\&}site=ehost-live},
volume = {64},
year = {2015}
}
@article{VanLoon2017,
abstract = {With the emergence of the National Science Foundation requirement for data management plans, academic librarians have increasingly aided researchers in developing these plans and disseminating research data. To determine the overall quality of data management plans at Wayne State University, the Library System's Research Data Services team evaluated the content of 119 plans from National Science Foundation grant proposals submitted between 2012 and 2014. The results of our content analysis indicate that, while most researchers understand the need to share data, many data management plans fail to adequately describe the data generated by the project, how data will be managed during the project, or how data will be preserved and shared after the completion of the project. Our results also show that data management plan deficiencies vary across academic units, suggesting the need for differentiated outreach services to improve the strength of data management plans in future National Science Foundation grant proposals. [ABSTRACT FROM AUTHOR] Copyright of IFLA Journal is the property of Sage Publications, Ltd. and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
annote = {Van Loon, James E. 1; Email Address: jevanloon@wayne.edu; Akers, Katherine G. 1; Hudson, Cole 1; Sarkozy, Alexandra 1; Affiliations: 1 : Wayne State University, USA; Source Info: Mar2017, Vol. 43 Issue 1, p98; Thesaurus Term: Information resources management; Thesaurus Term: Data quality; Subject Term: Research universities {\&} colleges; Author-Supplied Keyword: Data management; Author-Supplied Keyword: data sharing; Author-Supplied Keyword: evaluation; Author-Supplied Keyword: National Science Foundation; Author-Supplied Keyword: quality; Author-Supplied Keyword: research data; Number of Pages: 7p; Document Type: Article; Full Text Word Count: 3956},
author = {{Van Loon}, James E and Akers, Katherine G and Hudson, Cole and Sarkozy, Alexandra},
doi = {10.1177/0340035216682041},
issn = {03400352},
journal = {IFLA Journal},
keywords = {Information resources management Data quality Rese},
number = {1},
pages = {98--104},
title = {{Quality evaluation of data management plans at a research university}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=lxh{\&}AN=121559486{\&}site=ehost-live},
volume = {43},
year = {2017}
}
@article{Ogier2014,
abstract = {Rapidly growing within academic libraries, library data services have often been focused on assessing research trends and building partnerships outside the library. There are distinct benefits, however, to using data audit methodologies created for these external assessments of researcher practices inside the library as well. In this article, we share our experiences using the Data Asset Framework (DAF) methodology as an interview protocol to audit and assess electronic resources data management and associated reports. This article provides background information on data management as a library service, outlines the methodology and interview protocols followed by the assessment team, considers the strengths and weaknesses of the DAF when used to assess library data assets, provides brief analysis of the audit results, and discusses benefits of using data audit protocols as a tool for assessing library data. [ABSTRACT FROM AUTHOR] Copyright of Journal of Electronic Resources Librarianship is the property of Taylor {\&} Francis Ltd and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
annote = {Ogier, Andi; Hall, Monena; Bailey, Annette; Stovall, Connie; Source Info: Apr-Jun2014, Vol. 26 Issue 2, p101; Thesaurus Term: Academic librarians; Thesaurus Term: Electronic information resources; Thesaurus Term: Research; Thesaurus Term: Library administration; Subject Term: Methodology; Author-Supplied Keyword: academic libraries; Author-Supplied Keyword: assessment; Author-Supplied Keyword: data audit; Author-Supplied Keyword: Data Audit Framework; Author-Supplied Keyword: Data management; Author-Supplied Keyword: e-resources; Author-Supplied Keyword: usage statistics; Number of Pages: 13p; Document Type: Article},
author = {Ogier, Andi and Hall, Monena and Bailey, Annette and Stovall, Connie},
doi = {10.1080/1941126X.2014.910406},
issn = {1941126X},
journal = {Journal of Electronic Resources Librarianship},
keywords = {Academic librarians Electronic information resourc},
number = {2},
pages = {101--113},
title = {{Data Management Inside the Library: Assessing Electronic Resources Data Using the Data Asset Framework Methodology}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=lxh{\&}AN=96583415{\&}site=ehost-live},
volume = {26},
year = {2014}
}
@article{Snyder2012,
abstract = {Collecting and managing data for clinical and translational research presents significant challenges for clinical and translational researchers, many of whom lack needed access to data management expertise, methods, and tools. At many institutions, funding constraints result in differential levels of research informatics support among investigators. In addition, the lack of widely shared models and ontologies for clinical research informatics and health information technology hampers the accurate assessment of investigators' needs and complicates the efficient allocation of crucial resources for research projects, ultimately affecting the quality and reliability of research. In this paper, we present a model for providing flexible, cost-efficient institutional support for clinical and translational research data management and informatics, the research management team, and describe our initial experiences with deploying this model at our institution. {\textcopyright} 2012 Wiley Periodicals, Inc.},
address = {Duke University, School of Nursing, Durham, NC, United States Duke University, School of Medicine, Durham, NC, United States Duke Clinical Research Institute, Durham, NC, United States Division of Cardiology, Department of Medicine, Duke University Medica},
annote = {Cited By :3 Export Date: 17 November 2017 Correspondence Address: Snyder, D.C.; Duke University, School of Nursing, Durham, NC, United States; email: denise.snyder@duke.edu},
author = {Snyder, D C and Epps, S and Beresford, H F and Ennis, C and Levens, J S and Woody, S K and Tcheng, J E and Stacy, M A and Nahm, M},
doi = {10.1111/cts.12010},
issn = {17528054 (ISSN)},
journal = {Clinical and Translational Science},
keywords = {Biostatistics Clinical trials Computers Translatio},
language = {English},
number = {6},
pages = {464--469},
title = {{Research Management Team (RMT): A Model for Research Support -Services at Duke University}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84871394912{\&}doi=10.1111{\%}2Fcts.12010{\&}partnerID=40{\&}md5=688ad4c819e0ad4aac455eb21b3b4e82},
volume = {5},
year = {2012}
}
@article{Lorbeer2010,
abstract = {In this article the authors discuss the role of librarians in making open supplemental data services available at academic libraries. They highlight the benefits of the Open Data movement including transparency, increased academic debate, and freedom of access to research. They argue that librarians are the ideal employees to manage open supplemental data because they are familiar with academic-sponsored repositories.},
annote = {Lorbeer, Elizabeth R. 1; Email Address: lorbeer@uab.edu; Klusendorf, Heather 2; Email Address: Hklusendorf@ebsco.com; Affiliations: 1 : Associate Director for Content Management, Lister Hill Library of the Health Sciences, University of Alabama at Birmingham.; 2 : Media Relations Coordinator, EBSCO Information Services.; Source Info: Dec2010/Jan2011, Vol. 22 Issue 6, p42; Thesaurus Term: Open access publishing; Thesaurus Term: Librarians; Thesaurus Term: Academic librarians; Thesaurus Term: Academic libraries; Thesaurus Term: Institutional repositories; Number of Pages: 2p; Document Type: Opinion},
author = {Lorbeer, Elizabeth R and Klusendorf, Heather},
issn = {10432094},
journal = {Against the Grain},
keywords = {Open access publishing Librarians Academic librari},
number = {6},
pages = {42--43},
title = {{Op Ed -- Open and Accessible Supplemental Data: How Librarians Can Solve the Supplemental Data Arms Race}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=lxh{\&}AN=57934094{\&}site=ehost-live},
volume = {22},
year = {2010}
}
@article{Tenopir2014,
abstract = {The emergence of data intensive science and the establishment of data management mandates have motivated academic libraries to develop research data services (RDS) for their faculty and students. Here the results of two studies are reported: librarians' RDS practices in U.S. and Canadian academic research libraries, and the RDS-related library policies in those or similar libraries. Results show that RDS are currently not frequently employed in libraries, but many services are in the planning stages. Technical RDS are less common than informational RDS, RDS are performed more often for faculty than for students, and more library directors believe they offer opportunities for staff to develop RDS-related skills than the percentage of librarians who perceive such opportunities to be available. Librarians need opportunities to learn more about these services either on campus or through attendance at workshops and professional conferences. [ABSTRACT FROM AUTHOR] Copyright of Library {\&} Information Science Research (07408188) is the property of Elsevier Science and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
annote = {Tenopir, Carol 1; Sandusky, Robert J. 2; Allard, Suzie 1; Birch, Ben 1; Email Address: wbirch@utk.edu; Affiliations: 1 : School of Information Sciences, University of Tennessee, 451 Communications Bldg., 1345 Circle Park Drive, Knoxville, TN 37996-0341, USA; 2 : Richard J. Daley Library, MC-234, 801 S. Morgan St., Chicago, IL 60607, USA; Source Info: Apr2014, Vol. 36 Issue 2, p84; Thesaurus Term: RESEARCH; Thesaurus Term: Library publications; Thesaurus Term: Acquisition of data; Thesaurus Term: Academic libraries; Thesaurus Term: Library rules {\&} regulations; Thesaurus Term: Information theory; Subject Term: Education; Number of Pages: 7p; Document Type: Article},
author = {Tenopir, Carol and Sandusky, Robert J and Allard, Suzie and Birch, Ben},
doi = {10.1016/j.lisr.2013.11.003},
issn = {07408188},
journal = {Library {\&} Information Science Research (07408188)},
keywords = {RESEARCH Library publications Acquisition of data},
number = {2},
pages = {84--90},
title = {{Research data management services in academic research libraries and perceptions of librarians}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=lxh{\&}AN=96976377{\&}site=ehost-live},
volume = {36},
year = {2014}
}
@incollection{Brewer1994,
author = {Brewer, Cynthia A},
booktitle = {Modern Cartography Series},
doi = {https://doi.org/10.1016/B978-0-08-042415-6.50014-4},
editor = {Maceachren, Alan M and Taylor, D R Fraser},
isbn = {1363-0814},
pages = {123--147},
publisher = {Academic Press},
title = {{Chapter 7 - Color Use Guidelines for Mapping and Visualization}},
url = {http://www.sciencedirect.com/science/article/pii/B9780080424156500144},
volume = {2},
year = {1994}
}
@incollection{Kirk2012,
address = {Birmingham, UK},
author = {Kirk, Andy},
booktitle = {Data visualization a successful design process.},
keywords = {Electronic books.,Information visualization.,Software visualization.},
pages = {iv, 189 p.},
pmid = {12581277},
publisher = {Packt Pub.},
title = {{Chapter 1: The context of data visualization}},
year = {2012}
}
@article{Wang2013,
abstract = {Purpose – The purpose of this paper is to describe how the authors gained a better understanding of the variety of library users' data needs, and how gradually some new data services were established based on current capabilities. Design/methodology/approach – This paper uses a case study of the new data services at the John Cotton Dana Library, at Rutgers, The State University of New Jersey, Newark campus, to demonstrate the possible ways to extend data reference services and provide data computing services. A content analysis of services records shows how each user group falls into the multiple data services levels and subcategories. Findings – Library users can be classified into many different categories, and each of these may have different needs. Research centers might have big projects involving data gathering and applications where a librarian can mainly provide consultation; while an individual faculty member or student might need the librarians as research partners, with help for their specific problems. Computing data services can involve group training and statistical analysis assistance, where researchers need emergent help. Data librarians can take various opportunities for data management education, thereby gradually raising awareness and cultivating better research habits among researchers. Originality/value – Library data computing services can make unique contributions to faculty and students' research and study. Institution, library and users' interaction determines the levels and extent of data services and is generalized from the description and analysis of typical data service examples. Classic concept of data services levels is applied to a concrete case of data services program, and sub-categories of each data services level and user types are developed based on the authors' services record. [ABSTRACT FROM AUTHOR] Copyright of Program is the property of Emerald Publishing and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
annote = {Wang, Minglu; Source Info: 2013, Vol. 47 Issue 3, p282; Thesaurus Term: Academic library research; Thesaurus Term: Library user research; Thesaurus Term: Universities {\&} colleges; Thesaurus Term: Information services; Thesaurus Term: Library reference services; Author-Supplied Keyword: Academic libraries; Author-Supplied Keyword: Data computing services; Author-Supplied Keyword: Data management; Author-Supplied Keyword: Data reference services; Author-Supplied Keyword: Data services; Author-Supplied Keyword: United States of America; Author-Supplied Keyword: User studies; Number of Pages: 22p; Document Type: Article},
author = {Wang, Minglu},
doi = {10.1108/PROG-04-2012-0010},
issn = {00330337},
journal = {Program},
keywords = {Academic library research Library user research Un},
number = {3},
pages = {282--303},
title = {{Supporting the research process through expanded library data services}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=lxh{\&}AN=90611229{\&}site=ehost-live},
volume = {47},
year = {2013}
}
@article{Crowe2013,
abstract = {Information is now available in an overabundance, so much so, that distinguishing the noise from the signal has become very problematic. In the past, the collection and storage of information was the primary issue. Currently, there are massive amounts of data both structured and unstructured, that need to be analyzed in an iterative, as well as in a time sensitive manner. In response to this need, data analytical tools and services have emerged as a means to solve this problem. Grey literature repositories, libraries, and information centers are well positioned to take advantage of these new tools and services. The current trend is to make grey literature more easily discoverable, accessible, and with the new data analytical tools and services, more easily analyzed. The intent of our survey of the Grey Literature community was to provide a snapshot of the Community's use, planned use, and knowledge of data analytical tools/services for big data as it affects grey literature. The survey summary that follows indicates where the Community currently stands in regards to the use of data analytical tools and services. [ABSTRACT FROM AUTHOR] Copyright of Grey Journal (TGJ) is the property of TextRelease and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
annote = {Crowe, June; Candlish, J. R.; Source Info: Autumn2013, Vol. 9 Issue 3, p157; Thesaurus Term: Information storage {\&} retrieval systems; Thesaurus Term: Data analysis; Thesaurus Term: Data libraries; Thesaurus Term: Data modeling; Thesaurus Term: Big data; Thesaurus Term: Grey literature; Subject Term: Theory of knowledge; Number of Pages: 3p; Illustrations: 2 Charts, 1 Graph; Document Type: Article},
author = {Crowe, June and Candlish, J R},
issn = {15741796},
journal = {Grey Journal (TGJ)},
keywords = {Information storage {\&} retrieval systems Data analy},
number = {3},
pages = {157--159},
title = {{Data Analytics: The next big thing in information}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=lxh{\&}AN=90595607{\&}site=ehost-live},
volume = {9},
year = {2013}
}
@article{Surkis2017,
abstract = {Background: The New York University Health Sciences Library data services team had developed educational material for research data management and data visualization and had been offering classes at the request of departments, research groups, and training programs, but many members of the medical center were unaware of these library data services. There were also indications of data skills gaps in these subject areas and other data-related topics. Case Presentation: The data services team enlisted instructors from across the medical center with data expertise to teach in a series of classes hosted by the library. We hosted eight classes branded as a series called "Data Day to Day." Seven instructors from four units in the medical center, including the library, taught the classes. A multipronged outreach approach resulted in high turnout. Evaluations indicated that attendees were very satisfied with the instruction, would use the skills learned, and were interested in future classes. Conclusions: Data Day to Day met previously unaddressed data skills gaps. Collaborating with outside instructors allowed the library to serve as a hub for a broad range of data instruction and to raise awareness of library services. We plan to offer the series three times in the coming year with an expanding roster of classes. [ABSTRACT FROM AUTHOR] Copyright of Journal of the Medical Library Association is the property of Medical Library Association and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
annote = {Surkis, Alisa 1; Email Address: alisa.surkis@med.nyu.edu; Zametkin LaPolla, Fred Willie 1; Email Address: fred.lapolla@med.nyu.edu; Contaxis, Nicole 1; Email Address: nicole.contaxis@med.nyu.edu; Read, Kevin B. 1; Email Address: kevin.read@med.nyu.edu; Affiliations: 1 : Health Sciences Library, NYU School of Medicine, 577 First Avenue, New York, NY 10016; Source Info: Apr2017, Vol. 105 Issue 2, p185; Thesaurus Term: Database management; Subject Term: Hospital libraries -- New York (State); Subject Term: Academic medical centers; Subject Term: Personnel management; Subject Term: Job performance; Subject Term: Data analysis software; Subject Term: Medical coding; Subject: New York (State); Number of Pages: 7p; Document Type: Article},
author = {Surkis, Alisa and {Zametkin LaPolla}, Fred Willie and Contaxis, Nicole and Read, Kevin B},
doi = {10.5195/jmla.2017.35},
issn = {15365050},
journal = {Journal of the Medical Library Association},
keywords = {Database management Hospital libraries -- New York},
number = {2},
pages = {185--191},
title = {{Data Day to Day: building a community of expertise to address data skills gaps in an academic medical center}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=lxh{\&}AN=122316215{\&}site=ehost-live},
volume = {105},
year = {2017}
}
@article{Milner2008,
abstract = {The model proposed by the authors of two cortical systems providing ‘vision for action' and ‘vision for perception', respectively, owed much to the inspiration of Larry Weiskrantz. In the present article some essential concepts inherent in the model are summarized, and certain clarifications and refinements are offered. Some illustrations are given of recent experiments by ourselves and others that have prompted us to sharpen these concepts. Our explicit hope in writing our book in 1995 was to provide a theoretical framework that would stimulate research in the field. Conversely, well-designed empirical contributions conceived within the framework of the model are the only way for us to progress along the route towards a fully fleshed-out specification of its workings.},
author = {Milner, A D and Goodale, M A},
doi = {https://doi.org/10.1016/j.neuropsychologia.2007.10.005},
isbn = {0028-3932},
journal = {Neuropsychologia},
keywords = {Cortex,Dorsal stream,Perception,Ventral stream,Vision,Visuomotor control},
number = {3},
pages = {774--785},
title = {{Two visual systems re-viewed}},
url = {http://www.sciencedirect.com/science/article/pii/S0028393207003545 https://ac.els-cdn.com/S0028393207003545/1-s2.0-S0028393207003545-main.pdf?{\_}tid=06b3bf6e-dd20-421b-b286-425815e82709{\&}acdnat=1544451498{\_}2ae806499c2ed3f04fb83dc763f02158},
volume = {46},
year = {2008}
}
@article{Ljung2016,
abstract = {A central topic in scientific visualization is the transfer function (TF) for volume rendering. The TF serves a fundamental role in translating scalar and multivariate data into color and opacity to express and reveal the relevant features present in the data studied. Beyond this core functionality, TFs also serve as a tool for encoding and utilizing domain knowledge and as an expression for visual design of material appearances. TFs also enable interactive volumetric exploration of complex data. The purpose of this state-of-the-art report (STAR) is to provide an overview of research into the various aspects of TFs, which lead to interpretation of the underlying data through the use of meaningful visual representations. The STAR classifies TF research into the following aspects: dimensionality, derived attributes, aggregated attributes, rendering aspects, automation, and user interfaces. The STAR concludes with some interesting research challenges that form the basis of an agenda for the development of next generation TF tools and methodologies.},
annote = {Dr4zk
Times Cited:19
Cited References Count:142},
author = {Ljung, Patric and Kr{\"{u}}ger, Jens and Groller, Eduard and Hadwiger, Markus and Hansen, Charles D and Ynnerman, Anders},
chapter = {669},
doi = {10.1111/cgf.12934},
isbn = {01677055},
journal = {Computer Graphics Forum},
keywords = {data sets,dimension projection,driven transfer-functions,exploration,histograms,multidimensional transfer-functions,scalar fields,transfer-function design,transfer-function generation,visualization},
language = {English},
number = {3},
pages = {669--691},
title = {{State of the Art in Transfer Functions for Direct Volume Rendering}},
volume = {35},
year = {2016}
}
@article{Zhang1997,
abstract = {This article proposes a theoretical framework for external representation based problem solving. The Tic-Tac-Toe and its isomorphs are used to illustrate the procedures of the framework as a methodology and test the predictions of the framework as a functional model. Experimental results show that the behavior in the Tic-Tac-Toe is determined by the directly available information in external and internal representations in terms of perceptual and cognitive biases, regardless of whether the biases are consistent with, inconsistent with, or irrelevant to the task. It is shown that external representations are not merely inputs and stimuli to the internal mind and that they have much more important functions than mere memory aids. A representational determinism is suggested—the form of a representation determines what information can be perceived, what processes can be activated, and what structures can be discovered from the specific representation.},
author = {Zhang, Jiajie},
doi = {doi:10.1207/s15516709cog2102_3},
number = {2},
pages = {179--217},
title = {{The Nature of External Representations in Problem Solving}},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1207/s15516709cog2102{\_}3 https://onlinelibrary.wiley.com/doi/pdf/10.1207/s15516709cog2102{\_}3},
volume = {21},
year = {1997}
}
@incollection{Few2012,
author = {Few, Stephen},
booktitle = {Show me the numbers : designing tables and graphs to enlighten},
edition = {2nd},
isbn = {978-0970601971},
keywords = {Business presentations Charts, diagrams, etc.,Business presentations Graphic methods.,Graphic methods.},
pages = {pages 61 -- 85},
publisher = {Analytics Press},
title = {{General Designs for Communication}},
year = {2012}
}
@incollection{Yau2013,
address = {Indianapolis, IN},
annote = {2012956416
GBB303469
[electronic resource] :
Nathan Yau.
Includes bibliographical references and index.
Introduction -- Understanding data -- Visualization: the medium -- Representing data -- Exploring data visually -- Visualizing with clarity -- Designing for an audience -- Where to go from here -- Index.},
author = {Yau, Nathan},
booktitle = {Data points visualization that means something},
isbn = {9781118462195111846219X},
keywords = {Graphic methods.,Information visualization.},
pmid = {13601889},
publisher = {John Wiley {\&} Sons, Inc.},
title = {{Chapter 4: Exploring data visually}},
year = {2013}
}
@inproceedings{Chilana2015,
abstract = {Despite the enthusiasm and initiatives for making programming accessible to students outside Computer Science (CS), unfortunately, there are still many unanswered questions about how we should be teaching programming to engineers, scientists, artists or other non-CS majors. We present an in-depth case study of first-year management engineering students enrolled in a required introductory programming course at a large North American university. Based on an inductive analysis of one-on-one interviews, surveys, and weekly observations, we provide insights into students' motivations, career goals, perceptions of programming, and reactions to the Java and Processing languages. One of our key findings is that between the traditional classification of non-programmers vs. programmers, there exists a category of conversational programmers who do not necessarily want to be professional programmers or even end-user programmers, but want to learn programming so that they can speak in the programmer's language and improve their perceived job marketability in the software industry. {\textcopyright} 2015 IEEE.},
annote = {Cited By :8
Export Date: 20 July 2018},
author = {Chilana, P K and Alcock, C and Dembla, S and Ho, A and Hurst, A and Armstrong, B and Guo, P J},
doi = {10.1109/VLHCC.2015.7357224},
editor = {Fleming, S D and Li, Z and Ermel, C},
isbn = {19436092 (ISSN); 9781467374576 (ISBN)},
keywords = {Computational linguistics,Computational thinkings,Computer programming,Computer science education,Education,Education computing,End user programmers,Engineering education,Human computer interaction,Introductory programming course,Java programming language,Management engineering,Professional programmers,Software engineering,Software industry,Students,Teaching,Teaching programming,Visual languages,computational thinking,programming for non-CS majors},
language = {English},
pages = {251--259},
publisher = {IEEE Computer Society},
title = {{Perceptions of non-CS majors in intro programming: The rise of the conversational programmer}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84959902077{\&}doi=10.1109{\%}2FVLHCC.2015.7357224{\&}partnerID=40{\&}md5=b61cd836f074eade1a3c8649670b5f48 https://ieeexplore.ieee.org/ielx7/7347691/7356963/07357224.pdf?tp={\&}arnumber=7357224{\&}isnumber=7356963},
volume = {2015-Decem},
year = {2015}
}
@article{Cross1997,
abstract = {The combination of 3D magnetic resonance imaging data with polygon based computer graphic display software is ideally suited to the study of the Belousov-Zhabotinsky reaction in extended volumes. In this paper we present the first true three dimensional visualization of experimental data from the Belousov-Zhabotinsky reaction. The time evolution of a twisted scroll wave like isoconcentration surface and its organizing filament are demonstrated for a manganese-catalyzed B-Z mixture. These techniques extend the experimental study of the B-Z reaction as a class of pattern-forming systems to the third dimension. The limitations of the technique are discussed.},
annote = {Cited By :15
Export Date: 8 February 2019},
author = {Cross, A L and Armstrong, R L and Gobrecht, C and Paton, M and Ware, C},
doi = {10.1016/S0730-725X(97)00078-7},
journal = {Magnetic Resonance Imaging},
keywords = {3D Imaging,BZ Reaction,Non-linear dynamics,Self-organization},
number = {6},
pages = {719--725},
title = {{Three dimensional imaging of the Belousov-Zhabotinsky reaction using magnetic resonance}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0030796731{\&}doi=10.1016{\%}2FS0730-725X{\%}2897{\%}2900078-7{\&}partnerID=40{\&}md5=28f97831b363cf89119437f1ce2d707d},
volume = {15},
year = {1997}
}
@book{Andrienko2006,
abstract = {Exploratory data analysis (EDA) is about detecting and describing patterns, trends, and relations in data, motivated by certain purposes of investigation. As something relevant is detected in data, new questions arise, causing specific parts to be viewed in more detail. So EDA has a significant appeal: it involves hypothesis generation rather than mere hypothesis testing. The authors describe in detail and systemize approaches, techniques, and methods for exploring spatial and temporal data in particular. They start by developing a general view of data structures and characteristics and then build on top of this a general task typology, distinguishing between elementary and synoptic tasks. This typology is then applied to the description of existing approaches and technologies, resulting not just in recommendations for choosing methods but in a set of generic procedures for data exploration. Professionals practicing analysis will profit from tested solutions - illustrated in many examples - for reuse in the catalogue of techniques presented. Students and researchers will appreciate the detailed description and classification of exploration techniques, which are not limited to spatial data only. In addition, the general principles and approaches described will be useful for designers of new methods for EDA. {\textcopyright} Springer-Verlag Berlin Heidelberg 2006. All rights are reserved.},
annote = {Cited By :333
Export Date: 3 February 2019},
author = {Andrienko, N and Gennady, A},
booktitle = {Exploratory Analysis of Spatial and Temporal Data: A Systematic Approach},
doi = {10.1007/3-540-31190-4},
pages = {1--703},
title = {{Exploratory analysis of spatial and temporal data: A systematic approach}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84891421523{\&}doi=10.1007{\%}2F3-540-31190-4{\&}partnerID=40{\&}md5=06e3fb94140b5fe72a04ccd8bbc7dabb},
year = {2006}
}
@incollection{Good2018,
abstract = {In 2011, the author published an article that looked at the state of the art in novice programming environments. At the time, there had been an increase in the number of programming environments that were freely available for use by novice programmers, particularly children and young people. What was interesting was that they offered a relatively sophisticated set of development and support features within motivating and engaging environments, where programming could be seen as a means to a creative end, rather than an end in itself. Furthermore, these environments incorporated support for the social and collaborative aspects of learning. The article considered five environments-Scratch, Alice, Looking Glass, Greenfoot, and Flip- examining their characteristics and investigating the opportunities they might offer to educators and learners alike. It also considered the broader implications of such environments for both teaching and research. In this chapter, the author revisits the same five environments, looking at how they have changed in the intervening years. She considers their evolution in relation to changes in the field more broadly (e.g., an increased focus on "programming for all") and reflects on the implications for teaching, as well as research and further development. {\textcopyright} 2018 by IGI Global. All rights reserved.},
annote = {Cited By :1
Export Date: 20 July 2018
Correspondence Address: Good, J.; University of SussexUnited Kingdom},
author = {Good, J},
booktitle = {Innovative Methods, User-Friendly Tools, Coding, and Design Approaches in People-Oriented Programming},
doi = {10.4018/978-1-5225-5969-6.ch001},
isbn = {9781522559702 (ISBN); 1522559698 (ISBN); 9781522559696 (ISBN)},
language = {English},
pages = {1--41},
publisher = {IGI Global},
title = {{Novice programming environments: Lowering the barriers, supporting the progression}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049492321{\&}doi=10.4018{\%}2F978-1-5225-5969-6.ch001{\&}partnerID=40{\&}md5=24999aa2a4cf5bd661c2a0443be46c58},
year = {2018}
}
@article{Wilson2006,
abstract = {The prospects of developing software skills in the University of Toronto to enable emerging scientists to write better code by making them more productive are discussed. A software carpentry course emphasizes on small-scale and intermediate practical software issues and makes all study materials available on Websites for self study purposes. The course aims to teach computational scientists the methods to meet standards and meet the software quality in a systematic manner. It also enables a software engineer to recreate and rerun programs and test codes that are used to produce the results. Version control assists project management by its ability to undo the stakes and facilitate teamwork. GNU enables an engineer to build the programs by its easy documentation and file configuration. The continuous integration while checking codes is attained, the test suites are rerun, and results are posted to the project mailing list Websites.},
annote = {Cited By :34
Export Date: 20 July 2018
CODEN: CSENF
Correspondence Address: Wilson, G.; University of TorontoCanada; email: gvwilson@cs.utoronto.ca},
author = {Wilson, G},
doi = {10.1109/MCSE.2006.122},
isbn = {15219615 (ISSN)},
journal = {Computing in Science and Engineering},
keywords = {Codes (symbols),Computer software,Documentation,Productivity,Project management,Quality control,Test codes,Test suites,Version control,Websites},
language = {English},
number = {6},
pages = {66--69},
title = {{Software carpentry: Getting scientists to write better code by making them more productive}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-33750818722{\&}doi=10.1109{\%}2FMCSE.2006.122{\&}partnerID=40{\&}md5=f075c0b349dca7157aacb4aa96bdc57a https://ieeexplore.ieee.org/ielx5/5992/36123/01717319.pdf?tp={\&}arnumber=1717319{\&}isnumber=36123},
volume = {8},
year = {2006}
}
@incollection{Federer2018,
author = {Federer, L},
booktitle = {A Practical Guide for Informationists},
editor = {DeRosa, Antonio P},
isbn = {978-0-08-102017-3},
title = {{Providing meaningful information: Part C—Data management and visualization}},
year = {2018}
}
@article{Musen2015,
abstract = {The Center for Expanded Data Annotation and Retrieval is studying the creation of comprehensive and expressive metadata for biomedical datasets to facilitate data discovery, data interpretation, and data reuse. We take advantage of emerging community-based standard templates for describing different kinds of biomedical datasets, and we investigate the use of computational techniques to help investigators to assemble templates and to fill in their values. We are creating a repository of metadata from which we plan to identify metadata patterns that will drive predictive data entry when filling in metadata templates. The metadata repository not only will capture annotations specified when experimental datasets are initially created, but also will incorporate links to the published literature, including secondary analyses and possible refinements or retractions of experimental interpretations. By working initially with the Human Immunology Project Consortium and the developers of the ImmPort data repository, we are developing and evaluating an end-to-end solution to the problems of metadata authoring and management that will generalize to other data-management environments.},
annote = {Musen, Mark A
Bean, Carol A
Cheung, Kei-Hoi
Dumontier, Michel
Durante, Kim A
Gevaert, Olivier
Gonzalez-Beltran, Alejandra
Khatri, Purvesh
Kleinstein, Steven H
O'Connor, Martin J
Pouliot, Yannick
Rocca-Serra, Philippe
Sansone, Susanna-Assunta
Wiser, Jeffrey A
eng
BB/E025080/1/Biotechnology and Biological Sciences Research Council/United Kingdom
BB/I000771/1/Biotechnology and Biological Sciences Research Council/United Kingdom
U54 AI117925/AI/NIAID NIH HHS/
Research Support, N.I.H., Extramural
England
J Am Med Inform Assoc. 2015 Nov;22(6):1148-52. doi: 10.1093/jamia/ocv048. Epub 2015 Jun 25.},
author = {Musen, M A and Bean, C A and Cheung, K H and Dumontier, M and Durante, K A and Gevaert, O and Gonzalez-Beltran, A and Khatri, P and Kleinstein, S H and O'Connor, M J and Pouliot, Y and Rocca-Serra, P and Sansone, S A and Wiser, J A and Team, Cedar},
doi = {10.1093/jamia/ocv048},
edition = {2015/06/27},
isbn = {1527-974X (Electronic)1067-5027 (Linking)},
journal = {J Am Med Inform Assoc},
keywords = {*Biomedical Research,*Data Mining,*Datasets as Topic,Biological Ontologies,Humans,Information Storage and Retrieval,United States,data collection,data curation,datasets as topic,standards},
number = {6},
pages = {1148--1152},
pmid = {26112029},
title = {{The center for expanded data annotation and retrieval}},
url = {https://www.ncbi.nlm.nih.gov/pubmed/26112029},
volume = {22},
year = {2015}
}
@article{Simons2000,
abstract = {Across saccades, blinks, blank screens, movie cuts, and other interruptions, observers fail to detect substantial changes to the visual details of objects and scenes. This inability to spot changes ("change blindness") is the focus of this special issue of Visual Cognition. This introductory paper briefly reviews recent studies of change blindness, noting the relation of these findings to earlier research and discussing the inferences we can draw from them. Most explanations of change blindness assume that we fail to detect changes because the changed display masks or overwrites the initial display. Here I draw a distinction between intentional and incidental change detection tasks and consider how alternatives to the "overwriting" explanation may provide better explanations for change blindness. [ABSTRACT FROM AUTHOR] Copyright of Visual Cognition is the property of Taylor {\&} Francis Ltd and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
annote = {Simons, Daniel J.; Source Info: Jan2000, Vol. 7 Issue 1-3; Subject Term: BLINDNESS; Subject Term: CHANGE (Psychology); Subject Term: INFERENCE (Logic); Illustrations: 6 Diagrams; Document Type: Article},
author = {Simons, Daniel J},
doi = {10.1080/135062800394658},
isbn = {13506285},
journal = {Visual Cognition},
keywords = {BLINDNESS,CHANGE (Psychology),INFERENCE (Logic)},
number = {1-3},
pmid = {4429370},
publisher = {Taylor {\&} Francis Ltd},
title = {{Current Approaches to Change Blindness}},
url = {http://proxycu.wrlc.org/login?url=http://search.ebscohost.com/login.aspx?direct=true{\&}db=a9h{\&}AN=4429370{\&}site=ehost-live},
volume = {7},
year = {2000}
}
@article{Weldon1987,
abstract = {In Experiment 1 subjects studied a mixed list of pictures and words and then received either a free recall test or a word fragment completion test (e.g.,{\_}yr{\_}mi{\_}for pyramid) on which some fragments corresponded to previously studied items. Free recall of pictures was better than that of words. However, words produced greater priming than did pictures on the fragment completion test, although a small amount of picture priming did occur. Experiments 2 and 3 showed that the picture priming was not due to implicit naming of the pictures during study. In Experiment 4 subjects studied words and pictures and received either the word fragment completion test or a picture fragment identification test in which they had to name degraded pictures. Greater priming was obtained with words in word fragment completion, but greater priming was obtained with pictures on the picture identification test. We conclude that (1) the type of retrieval query determines whether pictures or words will exhibit superior retention, and (2)our results conform to the principle of transfer appropriate processing by which performance on transfer or retention tests benefits to the extent that the tests recapitulate operations used during learning. {\textcopyright} 1987 Psychonomic Society, Inc.},
annote = {Cited By :183
Export Date: 11 May 2016},
author = {Weldon, M S and Roediger, H L},
doi = {10.3758/BF03197030},
journal = {Memory {\&} Cognition},
number = {4},
pages = {269--280},
title = {{Altering retrieval demands reverses the picture superiority effect}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0023375092{\&}partnerID=40{\&}md5=170bd34f4b58e67e6047b8cd8bcc6a43},
volume = {15},
year = {1987}
}
@misc{Bahlai2018,
author = {Bahlai, Christie and Teal, Tracy K and Hoyt, Peter R},
title = {{Data Carpentry: Data Organization in Spreadsheets}},
url = {https://datacarpentry.org/spreadsheet-ecology-lesson/},
year = {2018}
}
@article{Read2018a,
abstract = {Providing access to the data underlying research results in published literature allows others to reproduce those results or analyze the data in new ways. Health sciences librarians and information professionals have long been advocates of data sharing. It is time for us to practice what we preach and share the data associated with our published research. This editorial describes the activity of a working group charged with developing a research data sharing policy for the Journal of the Medical Library Association. {\textcopyright} 2018, Medical Library Association. All rights reserved.},
annote = {Export Date: 20 July 2018
CODEN: JMLAC},
author = {Read, K B and Amos, L and Federer, L M and Logan, A and {Scott Plutchak}, T and Akers, K G},
doi = {10.5195/jmla.2018.431},
isbn = {15365050 (ISSN)},
journal = {Journal of the Medical Library Association},
keywords = {editorial,human,librarian,library},
language = {English},
number = {2},
pages = {155--158},
publisher = {Medical Library Association},
title = {{Practicing what we preach: Developing a data sharing policy for the journal of the medical library association}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045317939{\&}doi=10.5195{\%}2Fjmla.2018.431{\&}partnerID=40{\&}md5=b578ff45b721ab766f4c80f09f3021a5 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5886497/pdf/jmla-106-155.pdf},
volume = {106},
year = {2018}
}
@book{Lander2017c,
address = {Boston, MA},
annote = {2017934582
Jared P. Lander.},
author = {Lander, Jared P},
edition = {2nd editio},
isbn = {9780134546926 (pbk. alk. paper)},
pages = {pages cm},
pmid = {19507872},
publisher = {Addison-Wesley},
title = {{R for everyone : advanced analytics and graphics}},
year = {2017}
}
@incollection{Munzner2015,
address = {Boca Raton},
annote = {2014020715
Tamara Munzner, Department of Computer Science, University of British Columbia.
25 cm
"An A K Peters Book."
Includes bibliographical references (pages 373-395) and indexes.},
author = {Munzner, Tamara},
booktitle = {Visualization analysis and design},
isbn = {9781466508910 (Pack - Book and Ebook acid-free paper)},
keywords = {Information visualization.},
pages = {1--18},
pmid = {18165423},
publisher = {CRC Press, Taylor {\&} Francis Group},
title = {{What is Viz, and Why Do It?}},
year = {2015}
}
@incollection{Igual2017,
abstract = {In this chapter, we will become familiar with descriptive statistics that is comprised of concepts, terms, measures, and tools that help to describe, show, and summarize data in a meaningful way. When analyzing data, it is possible to use both descriptive and inferential statistics in order to analyze the results and draw some conclusions. We will discuss basic concepts, terms, and procedures, such as mean, median, variance, correlation, etc., to explore, describe, and summarize a given set of data.},
address = {Cham},
author = {Igual, Laura and Segu{\'{i}}, Santi},
booktitle = {Introduction to Data Science: A Python Approach to Concepts, Techniques and Applications},
doi = {10.1007/978-3-319-50017-1_3},
editor = {Igual, Laura and Segu{\'{i}}, Santi},
isbn = {978-3-319-50017-1},
pages = {29--50},
publisher = {Springer International Publishing},
title = {{Descriptive Statistics}},
url = {https://doi.org/10.1007/978-3-319-50017-1{\_}3},
year = {2017}
}
@book{Evergreen2017,
address = {Los Angeles},
annote = {2015045992
Stephanie D.H. Evergreen, Evergreen Data {\&} Evaluation, LLC.
Includes bibliographical references and index.},
author = {Evergreen, Stephanie D H},
isbn = {9781506303055 (pbk. alk. paper)},
keywords = {Charts, diagrams, etc.,Graphic design (Typography),Information visualization.,Presentation graphics software.,Visual communication.},
pages = {pages cm},
pmid = {18929483},
publisher = {SAGE},
title = {{Effective data visualization : the right chart for the right data}},
year = {2017}
}
@article{Kelly1983,
abstract = {Moving the retinal image of a sinusoidal grating at a constant velocity (compensated for eye movements) provides controlled spatial and temporal frequencies at every point in the stimulus field. Using this controlled-velocity technique, we have measured the detection threshold for isoluminance, red/green gratings as a function of their spatial and temporal frequencies. The chromatic contrast-threshold surface obtained in this way is analogous to the achromatic contrast-threshold surface measured previously, but the results are quite different. For very low temporal frequencies (below 0.2 Hz), the chromatic sensitivity decreases steadily with decreasing temporal frequency. Below 0.01 Hz, chromatic patterns disappear completely even at maximum contrast (although achromatic or homochromatic patterns do not). In the region above 0.2 Hz, both achromatic and chromatic thesholds can be explained by the same receptive-field-like model. When the center and the surround components of this model are additively combined, they form the chromatic threshold surface; when the sign of either component is reversed, they form the achromatic one.},
author = {Kelly, D H},
doi = {10.1364/JOSA.73.000742},
journal = {Journal of the Optical Society of America},
keywords = {Eye movements,Image stabilization,Retinal ganglion cells,Spatial frequency,Visual contrast sensitivity,Visual system},
number = {6},
pages = {742--750},
publisher = {OSA},
title = {{Spatiotemporal variation of chromatic and achromatic contrast thresholds}},
url = {http://www.osapublishing.org/abstract.cfm?URI=josa-73-6-742 https://www.osapublishing.org/josa/abstract.cfm?uri=josa-73-6-742},
volume = {73},
year = {1983}
}
@article{Poldrack2017,
abstract = {Functional neuroimaging techniques have transformed our ability to probe the neurobiological basis of behaviour and are increasingly being applied by the wider neuroscience community. However, concerns have recently been raised that the conclusions that are drawn from some human neuroimaging studies are either spurious or not generalizable. Problems such as low statistical power, flexibility in data analysis, software errors and a lack of direct replication apply to many fields, but perhaps particularly to functional MRI. Here, we discuss these problems, outline current and suggested best practices, and describe how we think the field should evolve to produce the most meaningful and reliable answers to neuroscientific questions.},
annote = {Poldrack, Russell A
Baker, Chris I
Durnez, Joke
Gorgolewski, Krzysztof J
Matthews, Paul M
Munafo, Marcus R
Nichols, Thomas E
Poline, Jean-Baptiste
Vul, Edward
Yarkoni, Tal
eng
R01 MH096906/MH/NIMH NIH HHS/
Review
England
Nat Rev Neurosci. 2017 Feb;18(2):115-126. doi: 10.1038/nrn.2016.167. Epub 2017 Jan 5.},
author = {Poldrack, R A and Baker, C I and Durnez, J and Gorgolewski, K J and Matthews, P M and Munafo, M R and Nichols, T E and Poline, J B and Vul, E and Yarkoni, T},
doi = {10.1038/nrn.2016.167},
edition = {2017/01/06},
isbn = {1471-0048 (Electronic)1471-003X (Linking)},
journal = {Nat Rev Neurosci},
keywords = {Functional Neuroimaging/*standards/statistics {\&} nu,Humans,Magnetic Resonance Imaging/*standards/statistics {\&},Practice Guidelines as Topic/standards,Reproducibility of Results,Software/standards,Statistics as Topic},
number = {2},
pages = {115--126},
pmid = {28053326},
title = {{Scanning the horizon: towards transparent and reproducible neuroimaging research}},
url = {https://www.ncbi.nlm.nih.gov/pubmed/28053326},
volume = {18},
year = {2017}
}
@article{Sutter2015,
abstract = {Long-term monitoring and research projects are essential to understand ecological change and the effectiveness of management activities. An inherent characteristic of long-term projects is the need for consistent data collection over time, requiring rigorous attention to data management and quality assurance. Recent papers have provided broad recommendations for data management; however, practitioners need more detailed guidance and examples. We present general yet detailed guidance for the development of comprehensive, concise, and effective data management for monitoring projects. The guidance is presented as a graded approach, matching the scale of data management to the needs of the organization and the complexity of the project. We address the following topics: roles and responsibilities; consistent and precise data collection; calibration of field crews and instrumentation; management of tabular, photographic, video, and sound data; data completeness and quality; development of metadata; archiving data; and evaluation of existing data from other sources. This guidance will help practitioners execute effective data management, thereby, improving the quality and usability of data for meeting project objectives as well as broader meta-analysis and macrosystem ecology research. {\textcopyright} 2015 The Wildlife Society.},
annote = {Cited By :13
Export Date: 9 August 2019
CODEN: WLSBA},
author = {Sutter, R D and Wainscott, S B and Boetsch, J R and Palmer, C J and Rugg, D J},
doi = {10.1002/wsb.548},
isbn = {00917648 (ISSN)},
journal = {Wildlife Society Bulletin},
keywords = {calibration,data management,design,ecological approach,environmental monitoring,graded approach,instrumentation,iterative design,long-term change,long-term ecological monitoring,metadata,project assessment,quality assurance},
language = {English},
number = {3},
pages = {451--463},
publisher = {Wiley-Blackwell},
title = {{Practical guidance for integrating data management into long-term ecological monitoring projects}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84955502964{\&}doi=10.1002{\%}2Fwsb.548{\&}partnerID=40{\&}md5=cf479a563bfa6914c22645144c302665 https://wildlife.onlinelibrary.wiley.com/doi/pdf/10.1002/wsb.548},
volume = {39},
year = {2015}
}
@misc{Shander2016,
abstract = {By Bill Shander.},
author = {Shander, Bill},
number = {March 01},
publisher = {@Medium},
shorttitle = {10 Tips for Better Data Storytelling – Infogram – },
title = {{10 Tips for Better Data Storytelling – Infogram – Medium}},
url = {https://medium.com/@Infogram/10-tips-for-better-data-storytelling-3808d823bde3},
volume = {2017},
year = {2016}
}
@incollection{Benevento2015a,
address = {Lexington, MA},
author = {Benevento, Daniel and Rowell, Katherine S},
booktitle = {The Best Boring Book Ever of Tableau for Healthcare},
publisher = {Breviloquent},
title = {{Introduction}},
year = {2015}
}
@misc{Michonneau2018,
author = {Michonneau, Fran{\c{c}}ois and Fournier, Auriel},
shorttitle = {Data Carpentry: R for data analysis and visualizat},
title = {{Data Carpentry: R for data analysis and visualization of Ecological Data}},
url = {http://www.datacarpentry.org/R-ecology-lesson/index.html},
year = {2018}
}
@incollection{Munzner2015a,
address = {Boca Raton},
annote = {2014020715
Tamara Munzner, Department of Computer Science, University of British Columbia.
25 cm
"An A K Peters Book."
Includes bibliographical references (pages 373-395) and indexes.},
author = {Munzner, Tamara},
booktitle = {Visualization analysis and design},
isbn = {9781466508910 (Pack - Book and Ebook acid-free paper)},
keywords = {Information visualization.},
pages = {1--18},
pmid = {18165423},
publisher = {CRC Press, Taylor {\&} Francis Group},
title = {{Arrange Tables}},
year = {2015}
}
@misc{Gemignani2014,
abstract = {"A dream come true for those looking to improve their data fluency Analytical data is a powerful tool for growing companies, but what good is it if it hides in the shadows? Bring your data to the forefront with effective visualization and communication approaches, and let Data Fluency: Empowering Your Organization with Effective Communication show you the best tools and strategies for getting the job done right. Learn the best practices of data presentation and the ways that reporting and dashboards can help organizations effectively gauge performance, identify areas for improvement, and communicate results. Topics covered in the book include data reporting and communication, audience and user needs, data presentation tools, layout and styling, and common design failures. Those responsible for analytics, reporting, or BI implementation will find a refreshing take on data and visualization in this resource, as will report, data visualization, and dashboard designers"--Provided by publisher.},
author = {Gemignani, Zach and Galentino, Richard and Gemignani, Chris and Schuermann, Patrick Jude},
isbn = {978-1118851012},
keywords = {Charts, diagrams, etc. Design.,Computer graphics.,Information visualization.,Visual communication.},
title = {{Data fluency empowering your organization with effective data communication}},
year = {2014}
}
@article{Michener2015,
author = {Michener, William K},
doi = {10.1371/journal.pcbi.1004525},
journal = {PLOS Computational Biology},
number = {10},
pages = {e1004525},
publisher = {Public Library of Science},
title = {{Ten Simple Rules for Creating a Good Data Management Plan}},
url = {https://doi.org/10.1371/journal.pcbi.1004525 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4619636/pdf/pcbi.1004525.pdf},
volume = {11},
year = {2015}
}
@article{Gehlenborg2010,
abstract = {High-throughput studies of biological systems are rapidly accumulating a wealth of 'omics'-scale data. Visualization is a key aspect of both the analysis and understanding of these data, and users now have many visualization methods and tools to choose from. The challenge is to create clear, meaningful and integrated visualizations that give biological insight, without being overwhelmed by the intrinsic complexity of the data. In this review, we discuss how visualization tools are being used to help interpret protein interaction, gene expression and metabolic profile data, and we highlight emerging new directions.},
annote = {Gehlenborg, Nils O'Donoghue, Sean I. Baliga, Nitin S. Goesmann, Alexander Hibbs, Matthew A. Kitano, Hiroaki Kohlbacher, Oliver Neuweger, Heiko Schneider, Reinhard Tenenbaum, Dan Gavin, Anne-Claude
Kohlbacher, Oliver/B-7310-2008; Schneider, Reinhard/C-5441-2009; O'Donoghue, Sean/A-9522-2012
Kohlbacher, Oliver/0000-0003-1739-4598; O'Donoghue, Sean/0000-0001-9520-6623; Goesmann, Alexander/0000-0002-7086-2568; Gavin, Anne-Claude/0000-0003-4917-2340; Gehlenborg, Nils/0000-0003-0327-8297
1548-7105
S},
author = {Gehlenborg, N and O'Donoghue, S I and Baliga, N S and Goesmann, A and Hibbs, M A and Kitano, H and Kohlbacher, O and Neuweger, H and Schneider, R and Tenenbaum, D and Gavin, A C},
doi = {10.1038/nmeth.1436},
isbn = {1548-7091},
journal = {Nature Methods},
number = {3},
pages = {S56--S68},
title = {{Visualization of omics data for systems biology}},
url = {https://www.nature.com/articles/nmeth.1436.pdf},
volume = {7},
year = {2010}
}
@article{Federer2018a,
abstract = {Objectives: Many librarians are taking on new roles in research data services. However, the emerging field of data librarianship, including specific roles and competencies, has not been clearly established. This study aims to better define data librarianship by exploring the skills and knowledge that data librarians utilize and the training that they need to succeed. Methods: Librarians who do data-related work were surveyed about their work and educational backgrounds and asked to rate the relevance of a set of data-related skills and knowledge to their work. Results: Respondents considered a broad range of skills and knowledge important to their work, especially “soft skills” and personal characteristics, like communication skills and the ability to develop relationships with researchers. Traditional library skills like cataloging and collection development were considered less important. A cluster analysis of the responses revealed two types of data librarians: data generalists, who tend to provide data services across a variety of fields, and subject specialists, who tend to provide more specialized services to a distinct discipline. Discussion: The findings of this study suggest that data librarians provide a broad range of services to their users and, therefore, need a variety of skills and expertise. Libraries hiring a data librarian may wish to consider whether their communities will be best served by a data generalist or a subject specialist and write their job postings accordingly. These findings also have implications for library schools, which could consider adjusting their curricula to better prepare their students for data librarian roles. {\textcopyright} 2018, Medical Library Association. All rights reserved.},
annote = {Export Date: 20 July 2018
CODEN: JMLAC
Correspondence Address: Federer, L.; NIH Library, National Institutes of HealthUnited States; email: lisa.federer@nih.gov},
author = {Federer, L},
doi = {10.5195/jmla.2018.306},
isbn = {15365050 (ISSN)},
journal = {Journal of the Medical Library Association},
keywords = {adult,article,cluster analysis,communication skill,documentation,human,librarian,school,scientist,student},
language = {English},
number = {3},
pages = {294--303},
publisher = {Medical Library Association},
title = {{Defining data librarianship: A survey of competencies, skills, and training}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049460450{\&}doi=10.5195{\%}2Fjmla.2018.306{\&}partnerID=40{\&}md5=c516f8fb98cca1cc28ff7ef68ed635f8 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6013124/pdf/jmla-106-294.pdf},
volume = {106},
year = {2018}
}
@incollection{Grolemund2017,
abstract = {.},
address = {Sebastopol},
author = {Grolemund, Garrett and Wickham, Hadley},
booktitle = {R for Data Science},
isbn = {978-1-491-91039-9},
pages = {555},
publisher = {O'Reilly Media},
title = {{Exploratory Data Analysis}},
year = {2017}
}
@article{Flynn2018,
abstract = {The Perpetual Diamond produces motion continuously and unambiguously in one direction despite never physically changing location. The phenomenon consists of a steady, mid-luminance diamond bordered by four thin edge strips and a surrounding background field. The direction of motion is determined by the relative phases of the luminance modulation between the edge strips and the background. Because the motion is generated entirely by changing contrast signals between the edge strips and background, the stimulus is a valuable tool for tests of spatial contrast, temporal contrast, contrast gain, and color contrast. We demonstrate that observers see motion even when the edge strips subtend only seconds of arc on the retina (which is less than the frequently reported 10 minutes of arc) and that perceived motion is due entirely to changes in the difference in contrast phase modulation, independent from the luminance phase.},
author = {Flynn, Oliver J and Shapiro, Arthur G},
doi = {10.1177/2041669518815708},
isbn = {2041-6695},
journal = {i-Perception},
number = {6},
pages = {2041669518815708},
publisher = {SAGE Publications},
title = {{The Perpetual Diamond: Contrast Reversals Along Thin Edges Create the Appearance of Motion in Objects}},
url = {https://doi.org/10.1177/2041669518815708},
volume = {9},
year = {2018}
}
@incollection{Wilkinson2005,
address = {New York},
annote = {2005043230
Leland Wilkinson ; with contributions by Graham Wills ... [et al.].
ill. (some col.) ; 24 cm.
Includes bibliographical references (p. [635]-671) and indexes.},
author = {Wilkinson, Leland and Wills, Graham},
booktitle = {The grammar of graphics},
edition = {2nd},
isbn = {0387245448},
keywords = {Statistics Graphic methods Data processing.},
pages = {xviii, 690 p.},
pmid = {13852437},
publisher = {Springer},
title = {{Data}},
year = {2005}
}
@misc{Jordan2018,
abstract = {Here's proof that YOU are making an impact!},
author = {Jordan, Kari L},
booktitle = {The Carpentries},
number = {2018-07-17},
title = {{Evidence of Carpentries' Impact on Learners}},
url = {https://carpentries.org/blog/2018/07/evidence-impact/},
volume = {2018},
year = {2018}
}
@article{Kratz2015,
annote = {Kratz, John E
Strasser, Carly
eng
Research Support, U.S. Gov't, Non-P.H.S.
England
Sci Data. 2015 Aug 4;2:150039. doi: 10.1038/sdata.2015.39. eCollection 2015.},
author = {Kratz, J E and Strasser, C},
doi = {10.1038/sdata.2015.39},
edition = {2015/09/24},
isbn = {2052-4463 (Print)2052-4463 (Linking)},
journal = {Sci Data},
keywords = {*Data Curation,*Information Dissemination,Datasets as Topic,Research Design},
pages = {150039},
pmid = {26396741},
title = {{Comment: Making data count}},
url = {https://www.ncbi.nlm.nih.gov/pubmed/26396741},
volume = {2},
year = {2015}
}
@article{Hedrich2009,
abstract = {Abstract In this study human color constancy was tested for two-dimensional (2D) and three-dimensional (3D) setups with real objects and lights. Four different illuminant changes, a natural selection task and a wide choice of target colors were used. We found that color constancy was better when the target color was learned as a 3D object in a cue-rich 3D scene than in a 2D setup. This improvement was independent of the target color and the illuminant change. We were not able to find any evidence that frequently experienced illuminant changes are better compensated for than unusual ones. Normalizing individual color constancy hit rates by the corresponding color memory hit rates yields a color constancy index, which is indicative of observers' true ability to compensate for illuminant changes.},
annote = {10.1167/9.4.16},
author = {Hedrich, Monika and Bloj, Marina and Ruppertsberg, Alexa I},
doi = {10.1167/9.4.16},
isbn = {1534-7362},
journal = {Journal of Vision},
number = {4},
pages = {16},
title = {{Color constancy improves for real 3D objects}},
url = {http://dx.doi.org/10.1167/9.4.16},
volume = {9},
year = {2009}
}
@article{Munzner2009,
abstract = {We present a nested model for the visualization design and validation with four layers: characterize the task and data in the vocabulary of the problem domain, abstract into operations and data types, design visual encoding and interaction techniques, and create algorithms to execute techniques efficiently. The output from a level above is input to the level below, bringing attention to the design challenge that an upstream error inevitably cascades to all downstream levels. This model provides prescriptive guidance for determining appropriate evaluation approaches by identifying threats to validity unique to each level. We also provide three recommendations motivated by this model: authors should distinguish between these levels when claiming contributions at more than one of them, authors should explicitly state upstream assumptions at levels above the focus of a paper, and visualization venues should accept more papers on domain characterization.},
annote = {Munzner, Tamara
eng
IEEE Trans Vis Comput Graph. 2009 Nov-Dec;15(6):921-8. doi: 10.1109/TVCG.2009.111.},
author = {Munzner, Tamara},
doi = {10.1109/TVCG.2009.111},
edition = {2009/10/17},
isbn = {1077-2626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Algorithm design and analysis,Concrete,Coupled mode analysis,Data visualization,Diseases,Electronic mail,Encoding,Models,Process design,Vocabulary,Writing,data visualisation,design,domain characterization,evaluation.,frameworks,nested process model,visual encoding,visualization design},
number = {6},
pages = {921--928},
pmid = {19834155},
title = {{A Nested Model for Visualization Design and Validation}},
url = {https://ieeexplore.ieee.org/ielx5/2945/5290686/05290695.pdf?tp={\&}arnumber=5290695{\&}isnumber=5290686},
volume = {15},
year = {2009}
}
@article{Smith2016,
abstract = {Software is a critical part of modern research and yet there is little support across the scholarly ecosystem for its acknowledgement and citation. Inspired by the activities of the FORCE11 working group focused on data citation, this document summarizes the recommendations of the FORCE11 Software Citation Working Group and its activities between June 2015 and April 2016. Based on a review of existing community practices, the goal of the working group was to produce a consolidated set of citation principles that may encourage broad adoption of a consistent policy for software citation across disciplines and venues. Our work is presented here as a set of software citation principles, a discussion of the motivations for developing the principles, reviews of existing community practice, and a discussion of the requirements these principles would place upon different stakeholders. Working examples and possible technical solutions for how these principles can be implemented will be discussed in a separate paper.},
author = {Smith, Arfon M and Katz, Daniel S and Niemeyer, Kyle E},
doi = {10.7717/peerj-cs.86},
editor = {Peroni, Silvio},
isbn = {2376-5992},
journal = {Peerj Computer Science},
keywords = {Attribution,Software citation,Software credit},
pages = {e86},
title = {{Software citation principles}},
url = {https://doi.org/10.7717/peerj-cs.86},
volume = {2},
year = {2016}
}
@incollection{Lander2017d,
author = {Lander, Jared P},
booktitle = {R for Everyone},
edition = {2nd},
title = {{Reshaping Data with tidyverse}},
year = {2017}
}
@article{Wright1940,
annote = {Export Date: 14 January 2019},
author = {Wright, W D},
doi = {10.1038/146155a0},
journal = {Nature},
number = {3692},
pages = {155--158},
title = {{Colour vision and chromaticity scales}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-51149215530{\&}doi=10.1038{\%}2F146155a0{\&}partnerID=40{\&}md5=a1bbb67a4781b21b15e75e23959f633a},
volume = {146},
year = {1940}
}
@article{Campbell1967,
abstract = {1. Differences of threshold contrast are predicted from optical theory for a grating acuity target in monochromatic and white light. The greatest differences, up to 65{\%}, are predicted for gratings of lower contrast and pitch than those normally used in measurements of visual acuity.2. Using three subjects, we measured contrast thresholds with 1.5 and 2.5 mm diameter artificial pupils for natural and paralysed accommodation, using a tungsten lamp and wave-lengths of 546 and 578 mm.3. Excellent agreement is obtained between predicted and measured differences.4. Results confirm that observed acuity and sensitivity differences between white and monochromatic lights are largely optical in origin, but involve at least two independent colour mechanisms as spectral weighting functions. Stiles's pi(4) and pi(5) sensitivities afford a much better fit to observed differences than the C.I.E. visibility curve.},
annote = {Campbell, F W
Gubisch, R W
Journal Article
England
J Physiol. 1967 Sep;192(2):345-58.},
author = {Campbell, F W and Gubisch, R W},
edition = {1967/09/01},
isbn = {0022-3751 (Print)0022-3751},
journal = {J Physiol},
keywords = {*Color Perception,*Optics and Photonics,Accommodation, Ocular/physiology,Humans,Pupil/physiology,Retina/*physiology,Vision, Ocular/*physiology},
language = {eng},
number = {2},
pages = {345--358},
pmid = {6050153},
title = {{The effect of chromatic aberration on visual acuity}},
url = {https://physoc.onlinelibrary.wiley.com/doi/pdf/10.1113/jphysiol.1967.sp008304},
volume = {192},
year = {1967}
}
@misc{Tweedie1997,
address = {Atlanta, Georgia, USA},
author = {Tweedie, Lisa},
booktitle = {Proceedings of the ACM SIGCHI Conference on Human factors in computing systems},
doi = {10.1145/258549.258803},
pages = {375--382},
publisher = {ACM},
title = {{Characterizing interactive externalizations}},
year = {1997}
}
@inproceedings{Rodrigo2009,
abstract = {We study which observable affective states and behaviors relate to students' achievement within a CS1 programming course. To this end, we use a combination of human observation, midterm test scores, and logs of student interactions with the compiler within an Integrated Development Environment (IDE). We find that confusion, boredom and engagement in IDE-related on-task conversation are associated with lower achievement. We find that a student's midterm score can be tractably predicted with simple measures such as the student's average number of errors, number of pairs of compilations in error, number pairs of compilations with the same error, pairs of compilations with the same edit location and pairs of compilations with the same error location. This creates the potential to respond to evidence that a student is at-risk for poor performance before they have even completed a programming assignment. {\textcopyright} 2009 ACM.},
annote = {Cited By :39
Export Date: 20 July 2018
Correspondence Address: Rodrigo, M. M. T.; Department of Information Systems and Computer Science, Ateneo de Manila University, Loyola Heights, Quezon City, Philippines; email: mrodrigo@ateneo.edu},
author = {Rodrigo, M M T and Baker, R S and Jadud, M C and Amarra, A C M and Dy, T and Espejo-Lahoz, M B V and Lim, S A L and Pascua, S A M S and Sugay, J O and Tabanao, E S},
doi = {10.1145/1562877.1562929},
isbn = {9781605583815 (ISBN)},
keywords = {Achievement,Affect,Affective state,Average numbers,Computer science,Education computing,Engineering education,Engineering research,Error location,Human observations,Innovation,Integrated development environment,Integrodifferential equations,Novice Programmers,Novice programmer,Poor performance,Programming assignments,Programming course,Student interactions,Students,Teaching,Web services},
language = {English},
pages = {156--160},
title = {{Affective and behavioral predictors of novice programmer achievement}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-77049099808{\&}doi=10.1145{\%}2F1562877.1562929{\&}partnerID=40{\&}md5=a06f7303eab5cd6d0d32352f99c9fc29 https://dl.acm.org/citation.cfm?doid=1562877.1562929},
year = {2009}
}
@article{Wyss2017,
abstract = {Nowadays, there is a consensus that good teaching and learning needs instructional variation and personalised forms of learning. In teacher education, these concepts have been implemented for years, and prospective teachers are taught accordingly; it is thus assumed that the teaching of novice teachers is in accordance with these new teaching concepts. In the research project ‘ALPHA', the teaching of novice teachers at the beginning and at the end of their first year in the profession and the teaching of experienced teachers with five or more years of teaching experience was videotaped, so that longitudinal and cross-sectional comparisons were possible. The lessons were analysed by applying a coding system on the instruction and by employing a rater inventory in order to understand the structure and quality of the lessons. Overall, the results indicate high levels of whole class teaching with a rather high level of traditional classroom instruction both for the novice and the experienced teachers. However, the proportions vary depending on the location of teacher education. The results provide evidence that the new teaching concepts learned on the teacher education programme are not necessarily implemented in the classroom and provide possible reasons why this might be the case. {\textcopyright} 2017 Informa UK Limited, trading as Taylor {\&} Francis Group.},
annote = {Export Date: 20 July 2018
Correspondence Address: Wyss, C.; Department of Research and Development, Zurich University of Teacher EducationSwitzerland; email: corinne.wyss@phzh.ch},
author = {Wyss, C and Kocher, M and Baer, M},
doi = {10.1080/02607476.2017.1286782},
isbn = {02607476 (ISSN)},
journal = {Journal of Education for Teaching},
keywords = {Video-based research,cross-national analysis,quality of teaching,teacher professionalisation},
language = {English},
number = {2},
pages = {191--205},
publisher = {Routledge},
title = {{The dilemma of dealing with persistent teaching traditions: findings of a video study}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85013031100{\&}doi=10.1080{\%}2F02607476.2017.1286782{\&}partnerID=40{\&}md5=8bfcc0df8db720fd118d291e27da1918 https://www.tandfonline.com/doi/full/10.1080/02607476.2017.1286782},
volume = {43},
year = {2017}
}
@article{Bechhofer2010,
author = {Bechhofer, Sean and Bechhofer, Sean and {De Roure}, David and Gamble, Matthew and Goble, Carole and Buchan, Iain},
doi = {10.1038/npre.2010.4626.1},
isbn = {1756-0357},
journal = {Nature Precedings},
title = {{Research Objects: Towards Exchange and Reuse of Digital Knowledge}},
year = {2010}
}
@article{Julesz1981,
abstract = {Research with texture pairs having identical second-order statistics has revealed that the pre-attentive texture discrimination system cannot globally process third- and higher-order statistics, and that discrimination is the result of a few local conspicuous features, called textons. It seems that only the first-order statistics of these textons have perceptual significance, and the relative phase between textons cannot be perceived without detailed scrutiny by focal attention. {\textcopyright} 1981 Nature Publishing Group.},
annote = {Cited By :1091
Export Date: 9 February 2019},
author = {Julesz, B},
doi = {10.1038/290091a0},
journal = {Nature},
number = {5802},
pages = {91--97},
title = {{Textons, the elements of texture perception, and their interactions}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0019522390{\&}doi=10.1038{\%}2F290091a0{\&}partnerID=40{\&}md5=e77b2ad2c83a5ea37a1165a0b657d36a},
volume = {290},
year = {1981}
}
@incollection{Camoes2016,
abstract = {"This book will teach you how to think about and organize data in ways that directly relate to your work, using the skills you already have. In other words, you don't need to be a graphic designer to create functional, elegant charts, this book will show you how. Although all of the examples in this book were created in Microsoft Excel, this is not a book about how to use Excel. Data at Work will help you to know which type of chart to use and how to format it, regardless of which spreadsheet application you use and whether or not you have any design experience."--Publisher description.},
author = {Cam{\~{o}}es, Jorge},
booktitle = {Data at Work: Best practices for creating effective charts and information graphics in Microsoft Excel},
isbn = {01342686369780134268637},
keywords = {Business Computer programs.,Electronic spreadsheets.,Excel.,Information visualization.,Informationsgrafik.,Unternehmen.,Visualisierung.},
publisher = {New Riders},
title = {{Visual Perception}},
year = {2016}
}
@misc{FORCE112018,
abstract = {Join in the discussion - leave your comments below FAIR Data Principles},
author = {FORCE11},
keywords = {FORCE11, community, scholars, librarians, archivis},
number = {October 25},
title = {{The FAIR Data Principles}},
url = {https://www.force11.org/group/fairgroup/fairprinciples},
volume = {2018},
year = {2018}
}
@article{Martin2016,
abstract = {Many academic institutions and their libraries have developed research data services, but sometimes institutional objectives, professional organizations, and librarians' current and future roles aren't always in sync. In this issue of the Journal of eScience Librarianship, librarians report on moving forward with various services, but frequently face institutional and professional obstacles.},
author = {Martin, Elaine},
chapter = {e1092},
doi = {10.7191/jeslib.2015.1092},
isbn = {21613974},
journal = {Journal of eScience Librarianship},
number = {2},
pages = {e1092--e1092},
title = {{The Role of Librarians in Data Science: A Call to Action}},
url = {http://escholarship.umassmed.edu/jeslib/vol4/iss2/7/ https://escholarship.umassmed.edu/cgi/viewcontent.cgi?article=1092{\&}context=jeslib},
volume = {4},
year = {2016}
}
@article{ACRLResearchPlanningandReviewCommittee2018,
abstract = {E very other year, the ACRL Research Planning and Review Committee produces a document on top trends in higher education as they relate to academic librarianship. Topics in this edition of ACRL Top Trends will be familiar to some readers who will hopefully learn of new materials to expand their knowledge. Other readers will be made aware of trends that are outside of their experience. This is the nature of trends in our current technological and educational environments: change is continual, but it affects different libraries at different rates. The 2018 top trends share several overarching themes, including the impact of market forces, technology, and the political environment on libraries.},
author = {{ACRL Research Planning and Review Committee}},
journal = {College {\&} Research Libraries News; Vol 79, No 6 (2018): JuneDO - 10.5860/crln.79.6.286},
title = {{2018 top trends in academic libraries: A review of the trends and issues affecting academic libraries in higher education}},
url = {https://crln.acrl.org/index.php/crlnews/article/view/17001/18750},
year = {2018}
}
@incollection{Grolemund2017b,
abstract = {.},
address = {Sebastopol},
author = {Grolemund, Garrett and Wickham, Hadley},
booktitle = {R for Data Science},
isbn = {978-1-491-91039-9},
publisher = {O'Reilly Media},
title = {{Tidy Data with tidyr}},
year = {2017}
}
@article{Wilson2014,
abstract = {Over the last 15 years, Software Carpentry has evolved from a week-long training course at the US National Laboratories into a worldwide volunteer effort to raise standards in scientific computing. This article explains what we have learned along the way, the challenges we now face, and our plans for the future. {\textcopyright} 2014 Wilson G.},
annote = {Cited By :29
Export Date: 20 July 2018
Correspondence Address: Wilson, G.; Mozilla Science LabUnited States},
author = {Wilson, G},
doi = {10.12688/f1000research.3-62.v1},
isbn = {20461402 (ISSN)},
journal = {F1000Research},
keywords = {Article,automation,computer analysis,computer program,computer system,data analysis software,learning algorithm,online system,process development,software carpentry,web browser},
language = {English},
publisher = {Faculty of 1000 Ltd},
title = {{Software Carpentry: Lessons learned}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84903634174{\&}doi=10.12688{\%}2Ff1000research.3-62.v1{\&}partnerID=40{\&}md5=9c9b043f82ff66cad002be0c5a43c359 https://f1000researchdata.s3.amazonaws.com/manuscripts/3787/5fa1d44b-9cc2-4392-84b7-894134e84249{\_}3536 -},
volume = {3},
year = {2014}
}
@article{Borer2009,
author = {Borer, Elizabeth T and Seabloom, Eric W and Jones, Matthew B and Schildhauer, Mark},
doi = {10.1890/0012-9623-90.2.205},
isbn = {0012-9623},
journal = {The Bulletin of the Ecological Society of America},
number = {2},
pages = {205--214},
publisher = {John Wiley {\&} Sons, Ltd},
title = {{Some Simple Guidelines for Effective Data Management}},
url = {https://doi.org/10.1890/0012-9623-90.2.205},
volume = {90},
year = {2009}
}
@incollection{Remington2012,
address = {Saint Louis},
author = {Remington, Lee Ann},
booktitle = {Clinical Anatomy and Physiology of the Visual System (Third Edition)},
doi = {https://doi.org/10.1016/B978-1-4377-1926-0.10013-X},
editor = {Remington, Lee Ann},
isbn = {978-1-4377-1926-0},
pages = {233--252},
publisher = {Butterworth-Heinemann},
title = {{Chapter 13 - Visual Pathway}},
url = {http://www.sciencedirect.com/science/article/pii/B978143771926010013X},
year = {2012}
}
@article{Borland2007,
author = {Borland, D and Taylor, R M},
doi = {10.1109/MCG.2007.323435},
isbn = {0272-1716},
journal = {IEEE Computer Graphics and Applications},
keywords = {Color,Conference proceedings,Encoding,Gray-scale,Hazards,Isosurfaces,Magnetic resonance imaging,Tensile stress,Transfer functions,color map,colour graphics,data visualisation,data visualization,rainbow color map,visualization toolkits},
number = {2},
pages = {14--17},
title = {{Rainbow Color Map (Still) Considered Harmful}},
volume = {27},
year = {2007}
}
@book{Jones2014,
address = {Sebastopol, CA},
annote = {2014469432
Ben Jones.
Subtitle on cover: Designing, developing, and delivering data visualizations
illustrations (some color) ; 23 cm
Includes index.
Communicating data -- Introduction to Tableau -- How much and how many -- Ratios and rates -- Proportions and percentages -- Mean and median -- Variation and uncertainty -- Multiple quantities -- Changes over time -- Maps and location -- Advanced maps -- The joy of dashboards -- Building dashboards -- Advanced dashboard features.},
author = {Jones, Ben},
edition = {First Edit},
isbn = {14493720239781449372026},
keywords = {Data mining.,Information visualization Computer programs.,Query languages (Computer science)},
pages = {xvi, 315 pages},
pmid = {18377988},
publisher = {O'Reilly Media},
title = {{Communicating data with Tableau}},
year = {2014}
}
@book{Ambrose2010,
abstract = {From the Inside Flap: Any conversation about effective teaching must begin with a consideration of how students learn. However, instructors may find a gap between resources that focus on the technical research on learning and those that provide practical classroom strategies. How Learning Works provides the bridge for such a gap. In this volume, the authors introduce seven general principles of learning, distilled from the research literature as well as from twenty-seven years of experience working one-on-one with college faculty. They have drawn on research from a breadth of perspectives (cognitive, developmental, and social psychology; educational research; anthropology; demographics; and organizational behavior) to identify a set of key principles underlying learning-from how effective organization enhances retrieval and use of information to what impacts motivation. These principles provide instructors with an understanding of student learning that can help them see why certain teaching approaches are or are not supporting student learning, generate or refine teaching approaches and strategies that more effectively foster student learning in specific contexts, and transfer and apply these principles to new courses. For anyone who wants to improve his or her students' learning, it is crucial to understand how that learning works and how to best foster it. This vital resource is grounded in learning theory and based on research evidence, while being easy to understand and apply to college teaching.},
annote = {2010003939
GBB011763
Susan A. Ambrose [and four others] ; foreword by Richard E. Mayer.
Seven research-based principles for smart teaching
illustrations ; 24 cm.
Includes bibliographical references (pages 261-284) and index.
Foreword /Richard E Mayer -- Introduction : Bridging learning research and teaching practice -- How does students' prior knowledge affect their learning? -- How does the way students organize knowledge affect their learning? -- What factors motivate students to learn? -- How do students develop mastery? -- What kinds of practice and feedback enhance learning? -- Why do student development and course climate matter for student learning? -- How do students become self-directed learners? -- Conclusion : Applying the seven principles to ourselves -- Appendix A: What is student self-assessment and how can we use it? -- Appendix B: What are concept maps and how can we use them? -- Appendix C: What are rubrics and how can we use them? -- Appendix D: What are learning objectives and how can we use them? -- Appendix E: What are ground rules and how can we use them? -- Appendix F: What are exam wrappers and how can we use them? -- Appendix G: What are checklists and how can we use them? -- Appendix H: What is reader response/peer review and how can we use it?
Purchased with funds from the University Libraries Endowment (Campus College Libraries); 2015
Purchased with funds from the University Libraries Endowment (Campus College Libraries); 2016
Jossey-Bass higher and adult education series.},
author = {Ambrose, Susan A},
booktitle = {The Jossey-Bass higher and adult education series},
edition = {First edit},
isbn = {97804704841040470484101},
keywords = {Case studies.,Educational innovations Case studies.,Educational innovations.,Effective teaching Case studies.,Effective teaching.,Fallstudie.,Learning, Psychology of Case studies.,Learning, Psychology of.,Learning.,Reference works.,School improvement programs Case studies.,School improvement programs.,Schulentwicklungsplanung.,Teaching methods.,Unterrichtserfolg.},
pages = {xxii, 301 pages},
title = {{How learning works : seven research-based principles for smart teaching}},
year = {2010}
}
@article{Anderson2007,
abstract = {Objectives: A. Identify the current state of data management needs of academic biomedical researchers. B. Explore their anticipated data management and analysis needs. C. Identify barriers to addressing those needs. Design: A multimodal needs analysis was conducted using a combination of an online survey and in-depth one-on-one semi-structured interviews. Subjects were recruited via an e-mail list representing a wide range of academic biomedical researchers in the Pacific Northwest. Measurements: The results from 286 survey respondents were used to provide triangulation of the qualitative analysis of data gathered from 15 semi-structured in-depth interviews. Results: Three major themes were identified: 1) there continues to be widespread use of basic general-purpose applications for core data management; 2) there is broad perceived need for additional support in managing and analyzing large datasets; and 3) the barriers to acquiring currently available tools are most commonly related to financial burdens on small labs and unmet expectations of institutional support. Conclusion: Themes identified in this study suggest that at least some common data management needs will best be served by improving access to basic level tools such that researchers can solve their own problems. Additionally, institutions and informaticians should focus on three components: 1) facilitate and encourage the use of modern data exchange models and standards, enabling researchers to leverage a common layer of interoperability and analysis; 2) improve the ability of researchers to maintain provenance of data and models as they evolve over time though tools and the leveraging of standards; and 3) develop and support information management service cores that could assist in these previous components while providing researchers with unique data analysis and information design support within a spectrum of informatics capabilities. {\textcopyright} 2007 J Am Med Inform Assoc.},
annote = {Cited By :77
Export Date: 15 July 2019
CODEN: JAMAF
Correspondence Address: Anderson, N.R.; Division of Biomedical and Health Informatics, Department of Medical Education and Biomedical Informatics, University of Washington, Seattle, WA, United States; email: nicka@u.washington.edu},
author = {Anderson, N R and Lee, E S and Brockenbrough, J S and Minie, M E and Fuller, S and Brinkley, J and Tarczy-Hornoch, P},
doi = {10.1197/jamia.M2114},
isbn = {10675027 (ISSN)},
journal = {Journal of the American Medical Informatics Association},
keywords = {Biomedical Research,Data Collection,Information Management,Information Storage and Retrieval,Information Systems,Internet,Interviews,Needs Assessment,article,e-mail,health survey,information processing,medical research,model,nonhuman,online analysis,qualitative analysis,semi structured interview,standard},
language = {English},
number = {4},
pages = {478--488},
title = {{Issues in Biomedical Research Data Management and Analysis: Needs and Barriers}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-34250696127{\&}doi=10.1197{\%}2Fjamia.M2114{\&}partnerID=40{\&}md5=ae9ec99d29032f6361e3797ff8c95ba7 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2244904/pdf/478.S106750270700103X.main.pdf},
volume = {14},
year = {2007}
}
@incollection{Kirk2012a,
address = {Birmingham, UK},
author = {Kirk, Andy},
booktitle = {Data visualization a successful design process.},
keywords = {Electronic books.,Information visualization.,Software visualization.},
pages = {160--181},
pmid = {12581277},
publisher = {Packt Pub.},
title = {{Chapter 6: Constructing and Evaluating Your Design Solution}},
year = {2012}
}
@incollection{Munzner2015c,
address = {Boca Raton},
annote = {2014020715
Tamara Munzner, Department of Computer Science, University of British Columbia.
25 cm
"An A K Peters Book."
Includes bibliographical references (pages 373-395) and indexes.},
author = {Munzner, Tamara},
booktitle = {Visualization analysis and design},
isbn = {9781466508910 (Pack - Book and Ebook acid-free paper)},
keywords = {Information visualization.},
pages = {95--115},
pmid = {18165423},
publisher = {CRC Press, Taylor {\&} Francis Group},
title = {{Marks and Channels}},
year = {2015}
}
@book{Healy2018,
address = {Princeton, NJ},
annote = {2018935810
Kieran Healy.},
author = {Healy, Kieran},
isbn = {9780691181615 (hardcover)9780691181622 (pbk.)},
pages = {pages cm},
pmid = {20376673},
publisher = {Princeton University Press},
title = {{Data visualization : a practical introduction}},
year = {2018}
}
@unpublished{Chapple2017,
author = {Chapple, Mike},
publisher = {Lynda.com},
title = {{Data Wrangling in R}},
url = {http://lynda.com},
year = {2017}
}
@article{Pawlik2017,
abstract = {Quality training in computational skills for life scientists is essential to allow them to deliver robust, reproducible and cutting-edge research. A pan-European bioinformatics programme, ELIXIR, has adopted a well-established and progressive programme of computational lab and data skills training from Software and Data Carpentry, aimed at increasing the number of skilled life scientists and building a sustainable training community in this field. This article describes the Pilot action, which introduced the Carpentry training model to the ELIXIR community. {\textcopyright} 2017 Pawlik A et al.},
annote = {Export Date: 20 July 2018
Correspondence Address: Pawlik, A.; New Zealand eScience InfrastructureNew Zealand; email: aleksandra.pawlik@nesi.org.nz},
author = {Pawlik, A and van Gelder, C W G and Nenadic, A and Palagi, P M and Korpelainen, E and Lijnzaad, P and Marek, D and Sansone, S A and Hancock, J and Goble, C},
doi = {10.12688/f1000research.11718.1},
isbn = {20461402 (ISSN)},
journal = {F1000Research},
keywords = {Bioinformatics,Capacity building,Data analysis,Data carpentry,IT and computational skills,Life sciences,Software carpentry,Training,biomedicine,elixir,human,model,scientist,skill,software},
language = {English},
publisher = {Faculty of 1000 Ltd},
title = {{Developing a strategy for computational lab skills training through Software and Data Carpentry: Experiences from the ELIXIR Pilot action}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027260069{\&}doi=10.12688{\%}2Ff1000research.11718.1{\&}partnerID=40{\&}md5=986620b65a78f5c5ec8e4a88ba16b996 https://f1000researchdata.s3.amazonaws.com/manuscripts/12660/91ae9450-9df0-4a1a-9aa8-90c7ed45a6dd{\_}11718{\_}},
volume = {6},
year = {2017}
}
@inproceedings{Giabbanelli2016,
abstract = {Integrating data and models is an important and still challenging goal in science. Computational modeling has been taught for decades and regularly revised, for example in the 2000s where it became more inclusive of data mining. As we are now in the 'data science' era, we have the occasion (and often the incentive) to teach in an integrative manner computational modeling and data science. In this paper, we reviewed the content of courses and programs on computational modeling and/or data science. From this review and our teaching experience, we formed a set of design principles for an integrative course. We independently implemented these principles in two public research universities, in Canada and the US, for a course targeting graduate students and upper-division undergraduates. We discuss and contrast these implementations, and suggest ways in which the teaching of computational science can continue to be revised going forward. {\textcopyright} The Authors. Published by Elsevier B.V.},
annote = {Cited By :2
Export Date: 20 July 2018},
author = {Giabbanelli, P J and Mago, V K},
doi = {10.1016/j.procs.2016.05.517},
editor = {Connolly, M},
isbn = {18770509 (ISSN)},
keywords = {Computation theory,Computational model,Computational science,Course content,Course contents,Curricula,Data analytics,Data mining,Design Principles,Education,Simulations,Students,Teaching,Teaching experience,Upper division undergraduate},
language = {English},
pages = {1968--1977},
publisher = {Elsevier B.V.},
title = {{Teaching computational modeling in the data science era}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84978476720{\&}doi=10.1016{\%}2Fj.procs.2016.05.517{\&}partnerID=40{\&}md5=1d992a3a6eabf1261e2c5aa1d736808d https://ac.els-cdn.com/S1877050916310055/1-s2.0-S1877050916310055-main.pdf?{\_}tid=40b58d96-9aa1-41d2-9320-2fd},
volume = {80},
year = {2016}
}
@article{Edwards2011,
abstract = {When scientists from two or more disciplines work together on related problems, they often face what we call ?science friction?. As science becomes more data-driven, collaborative, and interdisciplinary, demand increases for interoperability among data, tools, and services. Metadata ? usually viewed simply as ?data about data?, describing objects such as books, journal articles, or datasets ? serve key roles in interoperability. Yet we find that metadata may be a source of friction between scientific collaborators, impeding data sharing. We propose an alternative view of metadata, focusing on its role in an ephemeral process of scientific communication, rather than as an enduring outcome or product. We report examples of highly useful, yet ad hoc, incomplete, loosely structured, and mutable, descriptions of data found in our ethnographic studies of several large projects in the environmental sciences. Based on this evidence, we argue that while metadata products can be powerful resources, usually they must be supplemented with metadata processes. Metadata-as-process suggests the very large role of the ad hoc, the incomplete, and the unfinished in everyday scientific work.},
author = {Edwards, Paul N and Mayernik, Matthew S and Batcheller, Archer L and Bowker, Geoffrey C and Borgman, Christine L},
doi = {10.1177/0306312711413314},
isbn = {0306-3127},
journal = {Social Studies of Science},
number = {5},
pages = {667--690},
publisher = {SAGE Publications Ltd},
title = {{Science friction: Data, metadata, and collaboration}},
url = {https://doi.org/10.1177/0306312711413314 https://escholarship.org/content/qt2tj4g7sc/qt2tj4g7sc.pdf?t=otp981},
volume = {41},
year = {2011}
}
@article{Moors2016,
abstract = {The review first discusses componential explanations of automaticity, which specify non/automaticity features (e.g., un/controlled, un/conscious, non/efficient, fast/slow) and their interrelations. Reframing these features as factors that influence processes (e.g., goals, attention, and time) broadens the range of factors that can be considered (e.g., adding stimulus intensity and representational quality). The evidence reviewed challenges the view of a perfect coherence among goals, attention, and consciousness, and supports the alternative view that (a) these and other factors influence the quality of representations in an additive way (e.g., little time can be compensated by extra attention or extra stimulus intensity) and that (b) a first threshold of this quality is required for unconscious processing and a second threshold for conscious processing. The review closes with a discussion of causal explanations of automaticity, which specify factors involved in automatization such as repetition and complexity, and a discussion of mechanistic explanations, which specify the low-level processes underlying automatization.},
annote = {Moors, Agnes
eng
Research Support, Non-U.S. Gov't
Review
Annu Rev Psychol. 2016;67:263-87. doi: 10.1146/annurev-psych-122414-033550. Epub 2015 Aug 28.},
author = {Moors, A},
doi = {10.1146/annurev-psych-122414-033550},
edition = {2015/09/04},
isbn = {1545-2085 (Electronic)0066-4308 (Linking)},
journal = {Annu Rev Psychol},
keywords = {*Goals,Attention/*physiology,Consciousness/*physiology,Humans,attention,complexity,conscious,control,practice,representation},
pages = {263--287},
pmid = {26331343},
title = {{Automaticity: Componential, Causal, and Mechanistic Explanations}},
url = {https://www.ncbi.nlm.nih.gov/pubmed/26331343},
volume = {67},
year = {2016}
}
@inproceedings{VonHausswolff2017,
abstract = {Students are nowadays being introduced to the digital age as part of their formal education. This includes practical programming skills as well as more conceptual thinking tools developed in the discipline of computer science, sometimes denoted Computational Thinking (CT). The connection between CT and doing programming is sometimes thought of as the connection between theory and practice. The pragmatic thinker Dewey embraced practice in learning and argued that learning and knowing always come from experiencing the world. According to this view, there are no epistemological differences between theory and practice. In computer programming the student's active learning in the form of physical motor movement is important. Using the pragmatic way of analyzing learning to program puts a focus on the situated thinking during the practical programming, which relates to theories about CT. This research is focusing on the practical hands-on part of novice programming and in this aims at getting insights about factors important when learning to program that could inform teachers in the Computer Science classroom. {\textcopyright} 2017 Copyright is held by the owner/author(s).},
annote = {Export Date: 20 July 2018},
author = {{Von Hausswolff}, K},
doi = {10.1145/3141880.3143780},
isbn = {9781450353014 (ISBN)},
keywords = {Computation theory,Computational thinking,Computational thinkings,Computer programming,Computer science education,Education,Education computing,Novice programming,Practice,Pragmatism,Students,Teaching},
language = {English},
pages = {203--204},
publisher = {Association for Computing Machinery},
title = {{Practical thinking in programming education}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85040705149{\&}doi=10.1145{\%}2F3141880.3143780{\&}partnerID=40{\&}md5=7de6d857f8d255470b1bec680aa4cd24 https://dl.acm.org/citation.cfm?doid=3141880.3143780},
year = {2017}
}
@book{Wickham2016,
abstract = {"This book introduces you to R, RStudio, and the tidyverse, a collection of R packages designed to work together to make data science fast, fluent, and fun. Suitable for readers with no previous programming experience"--},
address = {Sebastopol, CA},
annote = {2017300238
Hadley Wickham and Garrett Grolemund.
illustrations (some color) ; 23 cm
Includes bibliographical references and index.
Part I. Explore. Data visualization with ggplot2 -- Workflow: basics -- Data transformation with dplyr -- Workflow: scripts -- Exploratory data analysis -- Workflow: projects -- Part II. Wrangle. Tibbles with tibble -- Data import with readr --Tidy data with tidyr -- Relational data with dplyr -- Strings with stringr -- Factors with forcats -- Dates and times with lubridate -- Part III. Program. Pipes with magrittr -- Functions -- Vectors -- Iteration with purrr -- Part IV. Model. Model basics with modelr -- Model building -- Many models with purrr and broom -- Part V. Communicate. R Markdown -- Graphics for communication with ggplot2 -- R Markdown formats -- R Markdown workflow.},
author = {Wickham, Hadley and Grolemund, Garrett},
edition = {First edit},
isbn = {9781491910399 (softcover)1491910364},
keywords = {Big data.,Data mining Computer programs.,Databases.,Electronic data processing.,Information visualization Computer programs.,R (Computer program language),Statistics.},
pages = {xxv, 492 pages},
pmid = {20146192},
publisher = {O'Reilly},
title = {{R for data science : import, tidy, transform, visualize, and model data}},
year = {2016}
}
@unpublished{Shaffer2018,
author = {Shaffer, Jeffrey A},
booktitle = {Introduction to Data Visualization in Tableau},
publisher = {University of Cincinnati},
title = {{Lecture 1.3: Introduction to Data Visualization {\&} Visual Perception}},
year = {2018}
}
@misc{StatisticsHowTo2013,
author = {{Statistics How To}},
number = {January 10},
title = {{What are Quartiles?}},
url = {https://www.statisticshowto.datasciencecentral.com/what-are-quartiles/},
volume = {2019},
year = {2013}
}
@article{Gonzalez-Beltran2015,
abstract = {MOTIVATION: Reproducing the results from a scientific paper can be challenging due to the absence of data and the computational tools required for their analysis. In addition, details relating to the procedures used to obtain the published results can be difficult to discern due to the use of natural language when reporting how experiments have been performed. The Investigation/Study/Assay (ISA), Nanopublications (NP), and Research Objects (RO) models are conceptual data modelling frameworks that can structure such information from scientific papers. Computational workflow platforms can also be used to reproduce analyses of data in a principled manner. We assessed the extent by which ISA, NP, and RO models, together with the Galaxy workflow system, can capture the experimental processes and reproduce the findings of a previously published paper reporting on the development of SOAPdenovo2, a de novo genome assembler. RESULTS: Executable workflows were developed using Galaxy, which reproduced results that were consistent with the published findings. A structured representation of the information in the SOAPdenovo2 paper was produced by combining the use of ISA, NP, and RO models. By structuring the information in the published paper using these data and scientific workflow modelling frameworks, it was possible to explicitly declare elements of experimental design, variables, and findings. The models served as guides in the curation of scientific information and this led to the identification of inconsistencies in the original published paper, thereby allowing its authors to publish corrections in the form of an errata. AVAILABILITY: SOAPdenovo2 scripts, data, and results are available through the GigaScience Database: http://dx.doi.org/10.5524/100044; the workflows are available from GigaGalaxy: http://galaxy.cbiit.cuhk.edu.hk; and the representations using the ISA, NP, and RO models are available through the SOAPdenovo2 case study website http://isa-tools.github.io/soapdenovo2/. CONTACT: philippe.rocca-serra@oerc.ox.ac.uk and susanna-assunta.sansone@oerc.ox.ac.uk.},
annote = {Gonzalez-Beltran, Alejandra
Li, Peter
Zhao, Jun
Avila-Garcia, Maria Susana
Roos, Marco
Thompson, Mark
van der Horst, Eelke
Kaliyaperumal, Rajaram
Luo, Ruibang
Lee, Tin-Lap
Lam, Tak-Wah
Edmunds, Scott C
Sansone, Susanna-Assunta
Rocca-Serra, Philippe
eng
BB/H024921/1/Biotechnology and Biological Sciences Research Council/United Kingdom
BB/I025840/1/Biotechnology and Biological Sciences Research Council/United Kingdom
BB/I000771/1/Biotechnology and Biological Sciences Research Council/United Kingdom
BB/L024101/1/Biotechnology and Biological Sciences Research Council/United Kingdom
BB/E025080/1/Biotechnology and Biological Sciences Research Council/United Kingdom
Research Support, Non-U.S. Gov't
PLoS One. 2015 Jul 8;10(7):e0127612. doi: 10.1371/journal.pone.0127612. eCollection 2015.},
author = {Gonzalez-Beltran, A and Li, P and Zhao, J and Avila-Garcia, M S and Roos, M and Thompson, M and van der Horst, E and Kaliyaperumal, R and Luo, R and Lee, T L and Lam, T W and Edmunds, S C and Sansone, S A and Rocca-Serra, P},
doi = {10.1371/journal.pone.0127612},
edition = {2015/07/15},
isbn = {1932-6203 (Electronic)1932-6203 (Linking)},
journal = {PLoS ONE},
keywords = {*Models, Theoretical,*Peer Review, Research,Computational Biology/*methods,Reproducibility of Results},
number = {7},
pages = {e0127612},
pmid = {26154165},
title = {{From Peer-Reviewed to Peer-Reproduced in Scholarly Publishing: The Complementary Roles of Data Models and Workflows in Bioinformatics}},
url = {https://www.ncbi.nlm.nih.gov/pubmed/26154165},
volume = {10},
year = {2015}
}
@incollection{Yau2013a,
address = {Indianapolis, IN},
annote = {2012956416
GBB303469
[electronic resource] :
Nathan Yau.
Includes bibliographical references and index.
Introduction -- Understanding data -- Visualization: the medium -- Representing data -- Exploring data visually -- Visualizing with clarity -- Designing for an audience -- Where to go from here -- Index.},
author = {Yau, Nathan},
booktitle = {Data points visualization that means something},
isbn = {9781118462195111846219X},
keywords = {Graphic methods.,Information visualization.},
pmid = {13601889},
publisher = {John Wiley {\&} Sons, Inc.},
title = {{Chapter 1: Understanding Data}},
year = {2013}
}
@incollection{Lander2017e,
author = {Lander, Jared P},
booktitle = {R for Everyone},
edition = {2nd},
title = {{Faster Group Manipulation with dplyr}},
year = {2017}
}
@article{Gehlenborg2012,
author = {Gehlenborg, Nils and Wong, Bang},
doi = {10.1038/nmeth.1862},
journal = {Nature Methods},
pages = {115},
publisher = {Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.},
title = {{Networks}},
url = {https://doi.org/10.1038/nmeth.1862},
volume = {9},
year = {2012}
}
@inproceedings{VonHausswolff2017a,
abstract = {More and a wider range of students are learning to program as part of their formal education in Sweden as well as in other countries. In computer programming as in other laboratory subjects, the student's active learning in the form of physical motor movement is important. Nevertheless, there are gaps in understanding how, when, and why practical hands-on learning has positive effects. To study the effects of hands-on for novices leaning to program, an experiment in a controlled setting is planned, along with an in-depth study in an authentic classroom setting. The theoretical and methodological basis is a pragmatic view of knowledge and learning, resulting in a mixed methodology approach. This research aims at getting insights that could inform teachers in the CS classroom in making appropriate didactical decisions, both at university level and in upper secondary school. Another more general aim is to understand the reasons for why hands-on is beneficial for learning. {\textcopyright} 2017 ACM.},
annote = {Cited By :1
Export Date: 20 July 2018
Correspondence Address: Von Hausswolff, K.; Department of Information Technology, Uppsala University, Box 337, Sweden; email: kristina.von.hausswolff@it.uu.se},
author = {{Von Hausswolff}, K},
doi = {10.1145/3105726.3105735},
isbn = {9781450349680 (ISBN)},
keywords = {Classroom settings,Computer programming,Education,Hands-on learning,Methodology approaches,Novice programming,Pair programming,Pair-programming,Practice,Pragmatism,Programming education,Students,Teaching},
language = {English},
pages = {279--280},
publisher = {Association for Computing Machinery, Inc},
title = {{Hands-on in computer programming education}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85030160140{\&}doi=10.1145{\%}2F3105726.3105735{\&}partnerID=40{\&}md5=49b2350270000292c2f0de2d35b63c8e https://dl.acm.org/citation.cfm?doid=3105726.3105735},
year = {2017}
}
@article{Mayer2000,
abstract = {Recent years have seen remarkable advances in sonar technology, positioning capabilities, and computer processing power that have revolutionized the way we image the seafloor. The massive amounts of data produced by these systems present many challenges but also offer tremendous opportunities in terms of visualization and analysis. We have developed a suite of interactive 3-D visualization and exploration tools specifically designed to facilitate the interpretation and analysis of very large (10's to 100's of megabytes), complex, multi-component spatial data sets. If properly georeferenced and treated, these complex data sets can be presented in a natural and intuitive manner that allows the integration of multiple components each at their inherent level of resolution and without compromising the quantitative nature of the data. Artificial sun-illumination, shading, and 3-D rendering can be used with digital bathymetric data (DTM's) to form natural looking and easily interpretable, yet quantitative, landscapes, Color can be used to represent depth or other parameters (like backscatter or sediment properties) which can be draped over the DTM, or high resolution imagery can be texture mapped on bathymetric data. When combined with interactive analytical tools, this environment has facilitated the use of multibeam sonar and other data sets in a range of geologic, environmental, fisheries, and engineering applications.},
annote = {Br32x
Times Cited:2
Cited References Count:9},
author = {Mayer, L A and Paton, M and Gee, L and Gardner, J V and Ware, C},
journal = {Oceans 2000 Mts/Ieee - Where Marine Science and Technology Meet, Vols 1-3, Conference Proceedings},
language = {English},
pages = {913--919},
title = {{Interactive 3-D visualization: A tool for seafloor navigation, exploration and engineering}},
year = {2000}
}
@article{Pinfield2014,
abstract = {The management of research data is now a major challenge for research organisations. Vast quantities of born-digital data are being produced in a wide variety of forms at a rapid rate in universities. This paper analyses the contribution of academic libraries to research data management (RDM) in the wider institutional context. In particular it: examines the roles and relationships involved in RDM, identifies the main components of an RDM programme, evaluates the major drivers for RDM activities, and analyses the key factors influencing the shape of RDM developments. The study is written from the perspective of library professionals, analysing data from 26 semi-structured interviews of library staff from different UK institutions. This is an early qualitative contribution to the topic complementing existing quantitative and case study approaches. Results show that although libraries are playing a significant role in RDM, there is uncertainty and variation in the relationship with other stakeholders such as ITservices and research support offices. Current emphases in RDM programmes are on developments of policies and guidelines, with some early work on technology infrastructures and support services. Drivers for developments include storage, security, quality, compliance, preservation, and sharing with libraries associated most closely with the last three. The paper also highlights a 'jurisdictional' driver in which libraries are claiming a role in this space. A wide range of factors, including governance, resourcing and skills, are identified as influencing ongoing developments. From the analysis, a model is constructed designed to capture the main aspects of an institutional RDM programme. This model helps to clarify the different issues involved in RDM, identifying layers of activity, multiple stakeholders and drivers, and a large number of factors influencing the implementation of any initiative. Institutions may usefully benchmark their activities against the data and model in order to inform ongoing RDM activity. {\textcopyright} 2014 Pinfield et al.},
annote = {Cited By :18
Export Date: 20 July 2018
CODEN: POLNC
Correspondence Address: Pinfield, S.; Information School, University of SheffieldUnited Kingdom},
author = {Pinfield, S and Cox, A M and Smith, J},
doi = {10.1371/journal.pone.0114734},
isbn = {19326203 (ISSN)},
journal = {PLoS ONE},
keywords = {Academies and Institutes,Article,Biomedical Research,Data Collection,Databases, Bibliographic,Humans,Library Administration,United Kingdom,bibliographic database,conceptual framework,consultation,data base,decision making,good clinical practice,human,information processing,leadership,library,library science,life cycle,medical research,methodology,organization,organization and management,policy,procedures,process development,program development,qualitative analysis,quantitative analysis,research data management,research ethics,resource allocation,responsibility,scientist,semi structured interview,standards,telephone interview,university},
language = {English},
number = {12},
publisher = {Public Library of Science},
title = {{Research data management and libraries: Relationships, activities, drivers and influences}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84915749468{\&}doi=10.1371{\%}2Fjournal.pone.0114734{\&}partnerID=40{\&}md5=b1b5b4c94ca751d3ddea5d4f7abd91eb http://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0114734{\&}type=printable},
volume = {9},
year = {2014}
}
@article{Wickham2014,
abstract = {A huge amount of effort is spent cleaning data to get it ready for analysis, but there has been little research on how to make data cleaning as easy and effective as possible. This paper tackles a small, but important, component of data cleaning: data tidying. Tidy datasets are easy to manipulate, model and visualize, and have a specific structure: each variable is a column, each observation is a row, and each type of observational unit is a table. This framework makes it easy to tidy messy datasets because only a small set of tools are needed to deal with a wide range of un-tidy datasets. This structure also makes it easier to develop tidy tools for data analysis, tools that both input and output tidy datasets. The advantages of a consistent data structure and matching tools are demonstrated with a case study free from mundane data manipulation chores.},
annote = {Ap1do
Times Cited:21
Cited References Count:19},
author = {Wickham, Hadley},
isbn = {1548-7660},
journal = {Journal of Statistical Software},
keywords = {data cleaning,data tidying,r,relational databases},
language = {English},
number = {10},
pages = {1--23},
title = {{Tidy Data}},
volume = {59},
year = {2014}
}
@article{Bostock2011,
abstract = {Data-Driven Documents (D3) is a novel representation-transparent approach to visualization for the web. Rather than hide the underlying scenegraph within a toolkit-specific abstraction, D3 enables direct inspection and manipulation of a native representation: the standard document object model (DOM). With D3, designers selectively bind input data to arbitrary document elements, applying dynamic transforms to both generate and modify content. We show how representational transparency improves expressiveness and better integrates with developer tools than prior approaches, while offering comparable notational efficiency and retaining powerful declarative components. Immediate evaluation of operators further simplifies debugging and allows iterative development. Additionally, we demonstrate how D3 transforms naturally enable animation and interaction with dramatic performance improvements over intermediate representations. {\textcopyright} 2011 IEEE.},
annote = {Cited By :1125
Export Date: 15 July 2019
CODEN: ITVGE
Correspondence Address: Bostock, M.; Computer Science Department, Stanford University, Stanford, CA 94305, United States; email: mbostock@stanford.edu},
author = {Bostock, M and Ogievetsky, V and Heer, J},
doi = {10.1109/TVCG.2011.185},
isbn = {10772626 (ISSN)},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {2D graphics,2D graphics.,Animation,Data visualization,Data-driven,Information systems,Information visualization,Input datas,Intermediate representations,Iterative development,Performance improvements,Scenegraph,Standard documents,Visualization,XML,toolkits,user interfaces},
language = {English},
number = {12},
pages = {2301--2309},
title = {{D3 data-driven documents}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-80855141795{\&}doi=10.1109{\%}2FTVCG.2011.185{\&}partnerID=40{\&}md5=2df49b52e2e05c00b06bc4181af3d9c9 https://ieeexplore.ieee.org/document/6064996/},
volume = {17},
year = {2011}
}
@inproceedings{Wang2018,
abstract = {Conversational programmers represent a class of learners who are not required to write any code, yet try to learn pro-gramming to improve their participation in technical con-versations. We carried out interviews with 23 conversation-al programmers to better understand the challenges they face in technical conversations, what resources they choose to learn programming, how they perceive the learning pro-cess, and to what extent learning programming actually helps them. Among our key findings, we found that conver-sational programmers often did not know where to even begin the learning process and ended up using formal and informal learning resources that focus largely on program-ming syntax and logic. However, since the end goal of con-versational programmers was not to build artifacts, modern learning resources usually failed these learners in their pur-suits of improving their technical conversations. Our find-ings point to design opportunities in HCI to invent learner-centered approaches that address the needs of conversation-al programmers and help them establish common ground in technical conversations. {\textcopyright} 2018 Association for Computing Machinery.},
annote = {Cited By :1
Export Date: 20 July 2018},
author = {Wang, A Y and Mitts, R and Guo, P J and Chilana, P K},
doi = {10.1145/3173574.3174085},
isbn = {9781450356206 (ISBN); 9781450356213 (ISBN)},
keywords = {Computation theory,Conversational programmers,Human computer interaction,Human engineering,Informal learning,Learner centered design,Learner-centered approach,Learner-centered design,Learning programming,Learning resource,Learning systems,Pro-gramming literacy,Technical conversations},
language = {English},
publisher = {Association for Computing Machinery},
title = {{Mismatch of expectations: How modern learning resources fail conversational programmers}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046957385{\&}doi=10.1145{\%}2F3173574.3174085{\&}partnerID=40{\&}md5=8029dec9e770c37d4450617d8e970c59 https://dl.acm.org/citation.cfm?doid=3173574.3174085},
volume = {2018-April},
year = {2018}
}
@inproceedings{Crow2018,
abstract = {A variety of intelligent tutoring systems have been created for the purpose of teaching computer programming. Most published literature focuses on systems that have been developed to teach programming within tertiary courses. A majority of systems have been developed to teach introductory programming concepts; other systems tutor more specific aspects of programming like scope or recursion. Literature reports that these systems address many of the difficulties associated with teaching programming to novices; however, individual systems vary greatly, and there is a large range of supplementary features developed in these systems. Most intelligent programming tutors involve some form of interactive programming exercises, but the use of supplementary features like plans, quizzes and worked solutions vary greatly between different systems. This systematic review reports key information about existing systems and the prevalence of different features within them. An overview of how supplementary features are integrated into these systems is given, along with implications for how intelligent programming tutors could be improved by supporting a wider range of supplementary features.},
annote = {Export Date: 20 July 2018},
author = {Crow, T and Luxton-Reilly, A and Wuensche, B},
doi = {10.1145/3160489.3160492},
isbn = {9781450363402 (ISBN)},
keywords = {Computer aided instruction,Computer programming,Computer science education,Computer systems programming,Education computing,Intelligent tutoring,Intelligent tutoring system,Introductory programming,Novice programming,Programming education,Programming exercise,Teaching,Teaching programming},
language = {English},
pages = {53--62},
publisher = {Association for Computing Machinery},
title = {{Intelligent Tutoring Systems for Programming Education: A Systematic Review}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85042093609{\&}doi=10.1145{\%}2F3160489.3160492{\&}partnerID=40{\&}md5=758aef5e2fb63f9c5987ad5f0aa95aa0 https://dl.acm.org/citation.cfm?doid=3160489.3160492},
year = {2018}
}
@article{Cleveland1984,
abstract = {The subject of graphical methods for data analysis and for data presentation needs a scientific foundation. In this article we take a few steps in the direction of establishing such a foundation. Our approach is based on graphical perception-the visual decoding of information encoded on graphs-and it includes both theory and experimentation to test the theory. The theory deals with a small but important piece of the whole process of graphical perception. The first part is an identification of a set of elementary perceptual tasks that are carried out when people extract quantitative information from graphs. The second part is an ordering of the tasks on the basis of how accurately people perform them. Elements of the theory are tested by experimentation in which subjects record their judgments of the quantitative information on graphs. The experiments validate these elements but also suggest that the set of elementary tasks should be expanded. The theory provides a guideline for graph construction: Graphs should employ elementary tasks as high in the ordering as possible. This principle is applied to a variety of graphs, including bar charts, divided bar charts, pie charts, and statistical maps with shading. The conclusion is that radical surgery on these popular graphs is needed, and as replacements we offer alternative graphical forms-dot charts, dot charts with grouping, and framed-rectangle charts.},
author = {Cleveland, William S and McGill, Robert},
doi = {10.2307/2288400},
isbn = {01621459},
journal = {Journal of the American Statistical Association},
number = {387},
pages = {531--554},
publisher = {[American Statistical Association, Taylor {\&} Francis, Ltd.]},
title = {{Graphical Perception: Theory, Experimentation, and Application to the Development of Graphical Methods}},
url = {http://www.jstor.org/stable/2288400},
volume = {79},
year = {1984}
}
@misc{Kline2018,
author = {Kline, Don},
publisher = {University of Calgary Departments of Psychology {\&} Surgery (Ophthalmology)},
title = {{Theories of Colour Vision}},
url = {https://psyc.ucalgary.ca/PACE/VA-Lab/colourperceptionweb/theories.htm},
volume = {2018},
year = {2018}
}
@inproceedings{Duke2000,
abstract = {Over the years there has been an ongoing debate about which computer language to adopt for a first programming subject. Although some may not agree, the current consensus is that the object-oriented languages are winning the argument, and Java has increasingly become the language of choice for teaching beginners. But choosing the language is only the first step in designing a first programming subject. The adoption of an object-oriented language such as Java offers an opportunity to completely rethink our approach to teaching first-year programming, an opportunity that should not be missed. In this paper we identify what we see as the non language-specific core issues, and discuss how we approached these issues when designing and teaching a programming subject for beginners. {\textcopyright} 2000 ACM.},
annote = {Cited By :28
Export Date: 20 July 2018},
author = {Duke, R and Salzman, E and Burmeister, J and Poon, J and Murray, L},
doi = {10.1145/359369.359380},
editor = {Ellis, A},
isbn = {1581132719 (ISBN)},
keywords = {Computer programming,First year programming,Java programming language,Object oriented programming,Teaching programming},
language = {English},
pages = {79--86},
publisher = {Association for Computing Machinery},
title = {{Teaching programming to beginners -choosing the language is just the first step}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995660739{\&}doi=10.1145{\%}2F359369.359380{\&}partnerID=40{\&}md5=a3eba08d8622513766e2e8de2427587d https://dl.acm.org/citation.cfm?doid=359369.359380},
volume = {Part F1291},
year = {2000}
}
@book{Camoes2016a,
abstract = {"This book will teach you how to think about and organize data in ways that directly relate to your work, using the skills you already have. In other words, you don't need to be a graphic designer to create functional, elegant charts, this book will show you how. Although all of the examples in this book were created in Microsoft Excel, this is not a book about how to use Excel. Data at Work will help you to know which type of chart to use and how to format it, regardless of which spreadsheet application you use and whether or not you have any design experience."--Publisher description.},
author = {Cam{\~{o}}es, Jorge},
booktitle = {Voices that matter},
isbn = {01342686369780134268637},
keywords = {Business Computer programs.,Electronic spreadsheets.,Excel.,Information visualization.,Informationsgrafik.,Unternehmen.,Visualisierung.},
pages = {xxii, 426 pages},
publisher = {New Riders},
title = {{Data at Work: Best practices for creating effective charts and information graphics in Microsoft Excel}},
year = {2016}
}
@article{Costello2014,
abstract = {There is increasing pressure from the scientific community, including funding agencies, journals and peers, for authors to publish the biodiversity data used in published articles and other scientific literature. This enables reproducibility of research and creates new opportunities for integrating data between research projects and analysing data in additional ways. The long-term availability of data is especially important in conservation science because field data can be costly to collect. In addition, historic data, especially on threatened species and their associated biota, become more valuable over time. This paper summarises current standards and best practices for the management and publication of biodiversity data. It includes recommendations for citing sources of species determination and standards for formatting species distribution data. Whenever possible, data should be published for inclusion in data access platforms that integrate datasets (e.g. GBIF, GenBank) and so enable new analyses and broader impact. Data centres (e.g. PANGAEA) provide added value in quality checks on data. A minimum standard recommended is that data should be permanently archived in an online, open-access repository with sufficient metadata for potential users to understand how and why they were collected.},
author = {Costello, Mark J and Wieczorek, John},
doi = {https://doi.org/10.1016/j.biocon.2013.10.018},
isbn = {0006-3207},
journal = {Biological Conservation},
keywords = {Biodiversity informatics,Conservation,Data standards,Global Biodiversity Information Facility,Methods,Ocean Biogeographic Information System,Species 2000,World Register of Marine Species},
pages = {68--73},
title = {{Best practice for biodiversity data management and publication}},
url = {http://www.sciencedirect.com/science/article/pii/S000632071300373X https://pdf.sciencedirectassets.com/271811/1-s2.0-S0006320714X00054/1-s2.0-S000632071300373X/main.pdf?X-Amz-Security-Token=AgoJb3JpZ2luX2VjEAoaCXVzLWVhc3QtMSJHMEUCIG0xv97ZQz3o{\%}252Bz{\%}252FIklG7{\%}25},
volume = {173},
year = {2014}
}
@article{Via2013,
abstract = {The mountains of data thrusting from the new landscape of modern high-throughput biology are irrevocably changing biomedical research and creating a near-insatiable demand for training in data management and manipulation and data mining and analysis. Among life scientists, from clinicians to environmental researchers, a common theme is the need not just to use, and gain familiarity with, bioinformatics tools and resources but also to understand their underlying fundamental theoretical and practical concepts. Providing bioinformatics training to empower life scientists to handle and analyse their data efficiently, and progress their research, is a challenge across the globe. Delivering good training goes beyond traditional lectures and resource-centric demos, using interactivity, problem- solving exercises and cooperative learning to substantially enhance training quality and learning outcomes. In this context, this article discusses various pragmatic criteria for identifying training needs and learning objectives, for selecting suitable trainees and trainers, for developing and maintaining training skills and evaluating training quality. Adherence to these criteria may help not only to guide course organizers and trainers on the path towards bioinformatics training excellence but, importantly, also to improve the training experience for life scientists. {\textcopyright} The Author 2013.},
annote = {Cited By :18
Export Date: 20 July 2018
Correspondence Address: Via, A.; Department of Physics, Sapienza University, P.le Aldo Moro 5, 00185 Rome, Italy; email: allegra.via@uniroma1.it},
author = {Via, A and Blicher, T and Bongcam-Rudloff, E and Brazas, M D and Brooksbank, C and Budd, A and {De Las Rivas}, J and Dreyer, J and Fernandes, P L and {Van Gelder}, C and Jacob, J and Jimenez, R C and Loveland, J and Moran, F and Mulder, N and Nyr{\"{o}}nen, T and Rother, K and Schneider, M V and Attwood, T K},
doi = {10.1093/bib/bbt043},
isbn = {14675463 (ISSN)},
journal = {Briefings in Bioinformatics},
keywords = {Bioinformatics,Bioinformatics courses,Biological Science Disciplines,Computational Biology,Database Management Systems,Programming Languages,Software Design,Train the trainers,Training,Training life scientists,article,biology,biomedicine,computer language,computer program,curriculum,data base,data mining,education,teaching},
language = {English},
number = {5},
pages = {528--537},
publisher = {Oxford University Press},
title = {{Best practices in bioinformatics training for life scientists}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84896940346{\&}doi=10.1093{\%}2Fbib{\%}2Fbbt043{\&}partnerID=40{\&}md5=abb29d019be4e81bf92d5a2b7e33ceaa https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3771230/pdf/bbt043.pdf},
volume = {14},
year = {2013}
}
@incollection{Ware2013a,
abstract = {"This is a book about what the science of perception can tell us about visualization. There is a gold mine of information about how we see to be found in more than a century of work by vision researchers. The purpose of this book is to extract from that large body of research literature those design principles that apply to displaying information effectively"--},
address = {Waltham, MA},
annote = {2012009489
Colin Ware.
illustrations (some color) ; 25 cm.
Includes bibliographical references (pages [459]-496) and index.
Machine generated contents note: Chapter 1. Foundations for an Applied Science of Data Visualization Chapter 2. The Environment, Optics, Resolution, and the Display Chapter 3. Lightness, Brightness, Contrast and Constancy Chapter 4. Color Chapter 5. Visual Salience and Finding Information Chapter 6. Static and Moving Patterns Chapter 7. Space Perception Chapter 8. Visual Objects and Data Objects Chapter 9. Images, Narrative, and Gestures for Explanation Chapter 10. Interacting with Visualizations Chapter 11. Visual Thinking Processes.},
author = {Ware, Colin},
booktitle = {Information visualization: perception for design},
edition = {Third edit},
isbn = {9780123814647 (hardback)},
keywords = {Information visualization.,Visual perception.,Visualization.},
pages = {31--62},
pmid = {17195003},
publisher = {Morgan Kaufmann},
title = {{The Environment, Optics, Resolution, and the Display}},
year = {2013}
}
@misc{Team2017,
abstract = {R Core Team (2017). R: A language and environment for statistical computing. R Foundation for Statistical Computing, Vienna, Austria. URL http://www.R-project.org/.},
author = {Team, R Core},
pages = {R Foundation for Statistical Computing--R Foundatio},
title = {{R Core Team (2017). R: A language and environment for statistical computing}},
year = {2017}
}
@article{Theeuwes1992,
abstract = {Three visual-search experiments tested whether the preattentive parallel stage can-selectively guide the attentive stage to a particular known-to-be-relevant target feature. Subjects searched multielement displays for a salient green circle that had a unique form when surrounded by green nontarget squares or had a unique color when surrounded by red nontarget circles. In the distractor conditions, a salient item in the other dimension was present as well. As an extension of earlier findings (Theeuwes, 1991), the results showed that complete top-down selectivity toward a particular feature was not possible, not even after extended and consistent practice. The results reveal that selectivity depends on the relative discriminability of the stimulus dimensions: the presence of an irrelevant item with a unique color interferes with parallel search for a unique form, and vice versa. {\textcopyright} 1992 Psychonomic Society, Inc.},
annote = {Cited By :873
Export Date: 9 February 2019},
author = {Theeuwes, J},
doi = {10.3758/BF03211656},
journal = {Perception {\&} Psychophysics},
number = {6},
pages = {599--606},
title = {{Perceptual selectivity for color and form}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026872014{\&}doi=10.3758{\%}2FBF03211656{\&}partnerID=40{\&}md5=e8c3949c13bb7057d305b0e3687f0660 https://link.springer.com/content/pdf/10.3758{\%}2FBF03211656.pdf},
volume = {51},
year = {1992}
}
@incollection{Benevento2015b,
address = {Lexington, MA},
author = {Benevento, Daniel and Rowell, Katherine S},
booktitle = {The Best Boring Book Ever of Tableau for Healthcare},
publisher = {Breviloquent},
title = {{Bullet Graph}},
year = {2015}
}
@article{Baxter2013,
author = {Baxter, Rob and Coveney, Peter and Kanso, Riam and Michelini, Alberto and Elbers, Willem and Wittenburg, Peter and Lecarpentier, Damien},
chapter = {279},
doi = {10.2218/ijdc.v8i1.260},
isbn = {1746-8256},
journal = {International Journal of Digital Curation},
number = {1},
pages = {279--287},
title = {{EUDAT: A New Cross-Disciplinary Data Infrastructure for Science}},
volume = {8},
year = {2013}
}
@article{Dorch2015,
abstract = {We present here evidence for the existence of a citation advantage within astrophysics for papers that link to data. Using simple measures based on publication data from NASA Astrophysics Data System we find a citation advantage for papers with links to data receiving on the average significantly more citations per paper than papers without links to data. Furthermore, using INSPEC and Web of Science databases we investigate whether either papers of an experimental or theoretical nature display different citation behavior.},
author = {Dorch, Bertil F and Drachen, Thea M and Ellegaard, Ole},
doi = {10.1017/S1743921316002696},
edition = {2016/10/27},
isbn = {1743-9213},
journal = {Proceedings of the International Astronomical Union},
keywords = {astronomical data bases,methods,sociology of astronomy,statistical},
number = {A29A},
pages = {172--175},
publisher = {Cambridge University Press},
title = {{The data sharing advantage in astrophysics}},
url = {https://www.cambridge.org/core/article/data-sharing-advantage-in-astrophysics/54EA324FD5D927D3A853F19F6F295A31},
volume = {11},
year = {2015}
}
@book{Borner2015,
address = {Cambridge, Massachusetts},
annote = {2014028219
Katy Börner.
illustrations (some color), maps (some color) ; 29 x 34 cm
One of a series of three publications influenced by the travelling exhibit Places {\&} Spaces: Mapping Science, curated by the Cyberinfrastructure for Network Science Center at Indiana University.
Includes bibliographical references and indexes.
Science and technology facts -- Envisioning science and technology -- Science maps in action -- Outlook.},
author = {Börner, Katy},
isbn = {9780262028813 (hardcover alk. paper)0262028816 (hardcover alk. paper)},
keywords = {Communication in science Data processing.,Graph design.,Information visualization.,Science Atlases.,Science Study and teaching Graphic methods.,Statistics Graphic methods.,Technical illustration.},
pages = {xi, 211 pages},
pmid = {18232070},
publisher = {The MIT Press},
title = {{Atlas of knowledge : anyone can map}},
year = {2015}
}
@inproceedings{Aivaloglou2016,
abstract = {Block-based programming languages like Scratch, Alice and Blockly are becoming increasingly common as introductory languages in programming education. There is substantial research showing that these visual programming environments are suitable for teaching programming concepts. But, what do people do when they use Scratch? In this paper we explore the characteristics of Scratch programs. To this end we have scraped the Scratch public repository and retrieved 250,000 projects. We present an analysis of these projects in three di erent dimensions. Initially, we look at the types of blocks used and the size of the projects. We then investigate complexity, used abstractions and programming concepts. Finally we detect code smells such as large scripts, dead code and duplicated code blocks. Our results show that 1) most Scratch programs are small, however Scratch programs consisting of over 100 sprites exist, 2) programming abstraction concepts like procedures are not commonly used and 3) Scratch programs do su er from code smells including large scripts and unmatched broadcast signals. {\textcopyright} 2016 ACM.},
annote = {Cited By :21
Export Date: 20 July 2018},
author = {Aivaloglou, E and Hermans, F},
doi = {10.1145/2960310.2960325},
isbn = {9781450344494 (ISBN)},
keywords = {Abstracting,Block based,Block-based languages,Code smell,Code smells,Codes (symbols),Computer programming,Odors,Programming abstractions,Programming education,Programming practices,Scratch,Static analysis,Teaching programming,Visual programming environments},
language = {English},
pages = {53--61},
publisher = {Association for Computing Machinery, Inc},
title = {{How kids code and how we know: An exploratory study on the scratch repository}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85000613380{\&}doi=10.1145{\%}2F2960310.2960325{\&}partnerID=40{\&}md5=60ca29776041094ddf87056070d6f6c0 https://dl.acm.org/citation.cfm?doid=2960310.2960325},
year = {2016}
}
@inproceedings{Heer2009,
abstract = {We investigate techniques for visualizing time series data and evaluate their effect in value comparison tasks. We compare line charts with horizon graphs-a space-efficient time series visualization technique-across a range of chart sizes, measuring the speed and accuracy of subjects' estimates of value differences between charts. We identify transition points at which reducing the chart height results in significantly differing drops in estimation accuracy across the compared chart types, and we find optimal positions in the speed-accuracy tradeoff curve at which viewers performed quickly without attendant drops in accuracy. Based on these results, we propose approaches for increasing data density that optimize graphical perception. Copyright 2009 ACM.},
annote = {Cited By :127
Export Date: 15 July 2019
Correspondence Address: Computer Science Department, Stanford University, Stanford, CA 94305, United States},
author = {Heer, J and Kong, N and Agrawala, M},
doi = {10.1145/1518701.1518897},
isbn = {9781605582474 (ISBN)},
keywords = {Drops,Flow visualization,Graphical perception,Graphical perceptions,Horizon graphs,Human engineering,Line charts,Optimal position,Optimization,Time series,Time series visualization,Time-series data,Trade-off curves,Transition point,Visualization},
language = {English},
pages = {1303--1312},
title = {{Sizing the horizon: The effects of chart size and layering on the graphical perception of time series visualizations}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84892463502{\&}doi=10.1145{\%}2F1518701.1518897{\&}partnerID=40{\&}md5=758901d2cd61f219c54672b49bed2fa8 https://dl.acm.org/citation.cfm?doid=1518701.1518897},
year = {2009}
}
@misc{AdobeCorporation2018,
abstract = {Learn how to work with various tools to choose colors in Adobe Photoshop.},
author = {{Adobe Corporation}},
keywords = {CC,Color fundamentals,Reference,color},
number = {October 18},
title = {{Choose colors in Adobe Photoshop}},
url = {https://helpx.adobe.com/nz/photoshop/using/choosing-colors.html},
volume = {2018},
year = {2018}
}
@incollection{Forrester2016,
author = {Forrester, John V and Dick, Andrew D and McMenamin, Paul G and Roberts, Fiona and Pearlman, Eric},
booktitle = {The Eye (Fourth Edition)},
doi = {https://doi.org/10.1016/B978-0-7020-5554-6.00001-0},
editor = {Forrester, John V and Dick, Andrew D and McMenamin, Paul G and Roberts, Fiona and Pearlman, Eric},
isbn = {978-0-7020-5554-6},
pages = {1--102.e2},
publisher = {W.B. Saunders},
title = {{Chapter 1 - Anatomy of the eye and orbit}},
url = {http://www.sciencedirect.com/science/article/pii/B9780702055546000010},
year = {2016}
}
@incollection{Grolemund2017c,
abstract = {.},
address = {Sebastopol},
author = {Grolemund, Garrett and Wickham, Hadley},
booktitle = {R for Data Science},
isbn = {978-1-491-91039-9},
publisher = {O'Reilly Media},
title = {{Workflow: Projects}},
year = {2017}
}
@article{Blischak2016,
author = {Blischak, John D and Davenport, Emily R and Wilson, Greg},
doi = {10.1371/journal.pcbi.1004668},
journal = {PLOS Computational Biology},
number = {1},
pages = {e1004668},
publisher = {Public Library of Science},
title = {{A Quick Introduction to Version Control with Git and GitHub}},
url = {https://doi.org/10.1371/journal.pcbi.1004668 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4718703/pdf/pcbi.1004668.pdf},
volume = {12},
year = {2016}
}
@inproceedings{Vihavainen2011,
abstract = {Learning a craft like programming is efficient when novices learn from people who already master the craft. In this paper we define Extreme Apprenticeship, an extension to the cognitive apprenticeship model. Our model is based on a set of values and practices that emphasize learning by doing together with continuous feedback as the most efficient means for learning. We show how the method was applied to a CS I programming course. Application of the method resulted in a significant decrease in the dropout rates in comparison with the previous traditionally conducted course instances.},
annote = {Cited By :68
Export Date: 20 July 2018
Correspondence Address: Vihavainen, A.; University of Helsinki, Department of Computer Science, P.O. Box 68 (Gustaf H{\"{a}}llstr{\"{o}}min katu 2b), Fi-00014 Helsinki, Finland; email: avihavai@cs.helsinki.fi},
author = {Vihavainen, A and Paksula, M and Luukkainen, M},
doi = {10.1145/1953163.1953196},
isbn = {9781450305006 (ISBN)},
keywords = {Apprentices,Best practices,Best-practices,Cognitive apprenticeship,Computer science,Continuous feedback,Course material,Curricula,Education computing,Engineering education,Instructional design,Instructional designs,Learning by doing,Management,Motivation,Programming education,Teaching},
language = {English},
pages = {93--98},
title = {{Extreme apprenticeship method in teaching programming for beginners}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79954427994{\&}doi=10.1145{\%}2F1953163.1953196{\&}partnerID=40{\&}md5=cb6b8c81fb6737c949892ce6967f3c27 https://dl.acm.org/citation.cfm?doid=1953163.1953196},
year = {2011}
}
@unpublished{Stone2006,
address = {Baltimore, MD},
author = {Stone, Maureen},
publisher = {IEEE Visualization: VIS2006},
title = {{Color in Information Display: Part 1}},
url = {http://www.stonesc.com/Vis06/},
year = {2006}
}
@incollection{Benevento2015c,
address = {Lexington, MA},
author = {Benevento, Daniel and Rowell, Katherine S},
booktitle = {The Best Boring Book Ever of Tableau for Healthcare},
publisher = {Breviloquent},
title = {{Chapter 8: Highlight Tables and Heat Maps}},
year = {2015}
}
@book{Bruce2017,
address = {Sebastopol, CA},
annote = {2017302988
Peter Bruce and Andrew Bruce.
illustrations ; 24 cm
Includes bibliographical references (pages 285-286) and index.
Exploratory data analysis -- Data and sampling distributions -- Statistical experiments and significance testing -- Regression and prediction -- Classification -- Statistical machine learning -- Unsupervised learning.},
author = {Bruce, Peter C and Bruce, Andrew},
edition = {First edit},
isbn = {97814919529621491952962},
keywords = {Big data Mathematics.,Data Mining,Datenanalyse,Mathematical analysis Statistical methods.,Quantitative research Statistical methods.,Statistik},
pages = {xvi, 298 pages},
pmid = {20182357},
publisher = {O'Reilly},
title = {{Practical statistics for data scientists: 50 essential concepts}},
year = {2017}
}
@article{McNeely2014,
author = {McNeely, Connie},
journal = {Review of Policy Research},
pages = {4},
title = {{The Big (Data) Bang: Policy, Prospects, and Challenges}},
volume = {31},
year = {2014}
}
@inproceedings{Puig2017,
abstract = {The vast majority of high-energy physicists use and produce software every day. Software skills are usually acquired "on the go" and dedicated training courses are rare. The LHCb Starterkit is a new training format for getting LHCb collaborators started in effectively using software to perform their research. The course focuses on teaching basic skills for research computing. Unlike traditional tutorials we focus on starting with basics, performing all the material live, with a high degree of interactivity, giving priority to understanding the tools as opposed to handing out recipes that work "as if by magic". The LHCb Starterkit was started by two young members of the collaboration inspired by the principles of Software Carpentry, and the material is created in a collaborative fashion using the tools we teach. Three successful entry-level workshops, as well as an advance one, have taken place since the start of the initiative in 2015, and were taught largely by PhD students to other PhD students. {\textcopyright} Published under licence by IOP Publishing Ltd.},
annote = {Export Date: 20 July 2018
Correspondence Address: Puig, A.; Universitat Z{\"{u}}richSwitzerland; email: albert.puig@cern.ch},
author = {Puig, A},
doi = {10.1088/1742-6596/898/8/082054},
edition = {8},
isbn = {17426588 (ISSN)},
keywords = {High energy physics,Interactivity,On The Go,Research computing,Software skills,Teaching,Training course},
language = {English},
publisher = {Institute of Physics Publishing},
title = {{The LHCb Starterkit}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85038444002{\&}doi=10.1088{\%}2F1742-6596{\%}2F898{\%}2F8{\%}2F082054{\&}partnerID=40{\&}md5=467cd4c38faca162c2f32853f3fe7b5c http://iopscience.iop.org/article/10.1088/1742-6596/898/8/082054/pdf},
volume = {898},
year = {2017}
}
@article{Federer2013,
abstract = {Question:How can an embedded research informationist add value to the scientific output of research teams? Setting:The University of California-Los Angeles (UCLA) Louise M. Darling Biomedical Library is an academic health sciences library serving the clinical, educational, and research needs of the UCLA community. Methods:A grant from the National Library of Medicine funded a librarian to join a UCLA research team as an informationist. The informationist meets regularly with the research team and provides guidance related to data management, preservation, and other information-related issues. Main Results:Early results suggest that the informationist's involvement has influenced the team's data gathering, storage, and curation methods. The UCLA Library has also changed the librarian's title to research informationist to reflect the new activities that she performs. Conclusion:The research informationist role provides an opportunity for librarians to become effective members of research teams and improve research output.},
annote = {Cited By :16
Export Date: 20 July 2018
CODEN: JMLAC
Correspondence Address: Federer, L.; UCLA Louise M. Darling Biomedical Library, University of California-Los Angeles, 12-077 Center for Health Sciences, Box 951798, Los Angeles, CA 90095, United States; email: lmfederer@library.ucla.edu},
author = {Federer, L},
doi = {10.3163/1536-5050.101.4.011},
isbn = {15365050 (ISSN)},
journal = {Journal of the Medical Library Association},
keywords = {Academic Medical Centers,Biomedical Research,Humans,Librarians,Libraries, Medical,Library Services,Professional Role,article,human,librarian,library,manpower,medical research,methodology,organization and management,professional standard,university hospital},
language = {English},
number = {4},
pages = {298--302},
title = {{The librarian as research informationist: A case study}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84887147855{\&}doi=10.3163{\%}2F1536-5050.101.4.011{\&}partnerID=40{\&}md5=9333c9589c0fe5b824fed7ad68818294 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3794685/pdf/mlab-101-04-298.pdf},
volume = {101},
year = {2013}
}
@article{McLure2014,
abstract = {Colorado State University librarians conducted five focus groups with thirty-one faculty, research scientists, and research associates. The groups explored: (1) The nature of data sets that these researchers create or maintain; (2) How participants manage their data; (3) Needs for support that the participants identify in relation to sharing, curating, and preserving their data; and (4) The feasibility of adapting the Purdue University Libraries' Data Curation Profiles Toolkit1 interview protocol for use in focus groups with researchers. The authors report their review of related literature, themes that emerged from analysis of the focus groups, and implications for related library services. {\textcopyright} 2014 by Johns Hopkins University Press.},
annote = {Cited By :17
Export Date: 20 July 2018},
author = {McLure, M and Level, A V and Cranston, C L and Oehlerts, B and Culbertson, M},
doi = {10.1353/pla.2014.0009},
isbn = {15312542 (ISSN)},
journal = {Portal},
language = {English},
number = {2},
pages = {139--164},
publisher = {Johns Hopkins University Press},
title = {{Data Curation: A study of researcher practices and needs}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84897951904{\&}doi=10.1353{\%}2Fpla.2014.0009{\&}partnerID=40{\&}md5=2f50513473dbbcde5ae355e1daff4bb7 http://muse.jhu.edu/article/541840},
volume = {14},
year = {2014}
}
@article{Schonlau2002,
author = {Schonlau, M},
journal = {Stata Journal},
keywords = {dendrogram tree clustering nonhierarchical large d},
number = {4},
pages = {391--402},
title = {{The clustergram: A graph for visualizing hierarchical and nonhierarchical cluster analyses}},
url = {http://www.stata-journal.com/article.html?article=st0028},
volume = {2},
year = {2002}
}
@article{Cervone2016,
abstract = {Purpose - This paper aims to describe the emerging field of data science, its significance in the larger information landscape and some issues that distinguish the problems of data science and informatics from traditional approaches in the information sciences. Design/methodology/approach - Through a general overview of the topic, the author discusses some of the major aspects of how work in the data sciences and informatics differ from traditional library and information science. Findings - Data science and informatics, as emerging fields, are expanding our understanding of how the massive amount of information currently being generated can be collected, managed and used. While these may not be traditional "library" problems, the contributions of the library and information science communities are critical to help address aspects of these issues. Originality/value - The emerging fields of data science and informatics have not been extensively explored from the perspective of the information professional. This paper is designed to help information professionals better understand some of the implications of data science in a changing information environment. [ABSTRACT FROM AUTHOR] Copyright of Digital Library Perspectives is the property of Emerald Publishing and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
annote = {Cervone, H Frank 1; Email Address: fcervone@uic.edu; Affiliations: 1 : University of Illinois, Chicago, Chicago, Illinois, USA; Source Info: 2016, Vol. 32 Issue 1, p7; Thesaurus Term: Data science (Information science); Thesaurus Term: Information science; Thesaurus Term: Databases; Thesaurus Term: Big data; Subject Term: Statistics; Author-Supplied Keyword: Data science; Author-Supplied Keyword: Informatics; Author-Supplied Keyword: Information studies; Author-Supplied Keyword: Information work; Author-Supplied Keyword: Unstructured data; Number of Pages: 4p; Document Type: Article; Full Text Word Count: 1525},
author = {Cervone, H Frank},
doi = {10.1108/DLP-10-2015-0022},
issn = {20595816},
journal = {Digital Library Perspectives},
keywords = {Data science (Information science) Information sci},
number = {1},
pages = {7--10},
title = {{Informatics and data science: an overview for the information professional}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=lxh{\&}AN=118252258{\&}site=ehost-live},
volume = {32},
year = {2016}
}
@article{Verhaar2017,
abstract = {At Leiden University, it is increasingly recognised that effective data management forms an integral component of responsible research. To actively promote the stewardship of all the research data that are produced at Leiden University, a comprehensive, institution-wide programme was launched in 2015, which centrally aims to encourage its researchers to carefully plan the temporal storage, long-term preservation and potential reuse of their data. This programme, which is managed centrally by the Department of Academic Affairs, and which receives important contributions from academic staff, from Leiden University Libraries, and from the University's central ICT organisation, basically consists of three parts. Firstly, a basic central policy has been formulated, containing clear guidelines for activities before, during and after research projects. The central aim of this institutional policy is to ensure that all Leiden-based research projects can effectively comply with the most common requirements stipulated by funding agencies, academic publishers, the Dutch standard evaluation protocol and the European data protection directive. As a second part of the data management programme, faculties have organised workshops and meetings, concentrating on the rationale and on the technical and organisational practicalities of effective data management in order to bring about a discipline-specific protocol. Data librarians employed by Leiden University Libraries have developed educational materials and provide training for PhDs in the principles and benefits of good data management. Thirdly, to ensure that scholars can genuinely make a reasoned selection among the many tools that are currently available, a central catalogue was developed which lists and characterises the most relevant data management services. The catalogue currently provides information about, amongst many other aspects, the organisations behind these services, the main academic disciplines which are targeted and the accepted file formats and metadata formats. The various aspects of these facilities have been classified using terminology provided by conceptual models developed by the UKDA, ANDS and the DCC. Using Leiden University's policy guidelines as criteria, the overall suitability of each service has also been evaluated. Leiden University's data management programme has a total duration of three years, and its basic objective is to offer a comprehensive form of support, in which the data management policy which is propagated centrally is complemented by various forms of assistance which ought to make it easier for scholars to adhere to this policy. The catalogue of data management services also aims to bolster the implementation of an adequate technical infrastructure, as the qualitative evaluations of the services enable policy-makers and developers to quickly establish gaps or other shortcomings within existing facilities. [ABSTRACT FROM AUTHOR] Copyright of Liber Quarterly: The Journal of European Research Libraries is the property of Universiteit Utrecht and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
annote = {Verhaar, Peter 1; Email Address: p.a.f.verhaar@library.leidenuniv.nl; Schoots, Fieke 1; Email Address: s.p.schoots@library.leidenuniv.nl; Sesink, Laurents 1; Email Address: l.b.j.sesink@library.leidenuniv.nl; Frederiks, Floor 1; Email Address: f.frederiks@BB.leidenuniv.nl; Affiliations: 1 : Leiden University, The Netherlands; Source Info: 2017, Vol. 27 Issue 1, p1; Thesaurus Term: Information science; Thesaurus Term: Information {\&} communication technologies; Subject Term: Data -- Management; Subject Term: Management information systems; Author-Supplied Keyword: data management; Author-Supplied Keyword: digital scholarship; Author-Supplied Keyword: open science; Author-Supplied Keyword: research support; Number of Pages: 22p; Document Type: Article},
author = {Verhaar, Peter and Schoots, Fieke and Sesink, Laurents and Frederiks, Floor},
doi = {10.18352/lq.10185},
issn = {14355205},
journal = {Liber Quarterly: The Journal of European Research Libraries},
keywords = {Information science Information {\&} communication te},
number = {1},
pages = {1--22},
title = {{Fostering Effective Data Management Practices at Leiden University}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=lxh{\&}AN=121616551{\&}site=ehost-live},
volume = {27},
year = {2017}
}
@article{Southall2017,
abstract = {This article outlines the involvement of the Bodleian Libraries at the University of Oxford in developing new services for research data management. It offers reflections on what such additional support means for academic librarians, specifically considering support offered by subject consultants and a series of research data management (RDM) training workshops. The need to reshape library roles, teams and collections to accommodate developments in support for research data and its management is discussed. Additional actions being carried out within the Bodleian Libraries to help further meet these needs are outlined and include the development of the role of a Data Librarian and engagement of a network of librarians with this expanding area of professional knowledge. This review of what has been achieved so far provides fellow practitioners with valuable lessons and pointers to consider when reviewing the support required within their own institutions. [ABSTRACT FROM AUTHOR] Copyright of New Review of Academic Librarianship is the property of Routledge and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
annote = {Southall, John 1; Scutt, Catherine 2; Email Address: catherine.scutt@bodleian.ox.ac.uk; Affiliations: 1 : Social Science Library, University of Oxford, Oxford, United Kingdom; 2 : Education Library, University of Oxford, Oxford, United Kingdom; Source Info: 2017, Vol. 23 Issue 2/3, p303; Thesaurus Term: Data library administration; Thesaurus Term: Training of librarians; Thesaurus Term: Academic libraries; Thesaurus Term: Academic library personnel; Thesaurus Term: Computers in research; Subject Term: Communication in learning {\&} scholarship; Author-Supplied Keyword: Library staff development; Author-Supplied Keyword: researchers; Author-Supplied Keyword: roles; Author-Supplied Keyword: scholarly communication; Author-Supplied Keyword: university libraries; Number of Pages: 20p; Document Type: Article},
author = {Southall, John and Scutt, Catherine},
doi = {10.1080/13614533.2017.1318766},
issn = {13614533},
journal = {New Review of Academic Librarianship},
keywords = {Data library administration Training of librarians},
number = {2/3},
pages = {303--322},
title = {{Training for Research Data Management at the Bodleian Libraries: National Contexts and Local Implementation for Researchers and Librarians}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=lxh{\&}AN=124803799{\&}site=ehost-live},
volume = {23},
year = {2017}
}
@article{Dechman2014,
abstract = {This article reports collaborative research study from a small university. Twenty-seven faculty members were interviewed to determine attitudes and behaviors pertaining to using data in the classroom and whether easier access to secondary data allows for integration into a broader range of courses. The results of this study suggest a lack of awareness and skill deficits among faculty. These findings provide insights for librarians interested in working with faculty in supporting and promoting the use of open data online analysis, along with traditional quantitative data services in the social sciences and professional disciplines. Preliminary strategies developed in the year following this research study are also discussed. [ABSTRACT FROM PUBLISHER] Copyright of Behavioral {\&} Social Sciences Librarian is the property of Taylor {\&} Francis Ltd and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
annote = {Dechman, Margaret K. 1; Syms, Laura R. 1; Affiliations: 1 : Cape Breton University, Sydney, Nova Scotia, Canada; Source Info: Oct-Dec2014, Vol. 33 Issue 4, p188; Thesaurus Term: Database management; Thesaurus Term: Research -- Methodology; Thesaurus Term: Information literacy; Thesaurus Term: Access to information; Subject Term: Universities {\&} colleges -- Canada; Subject Term: College teachers; Subject Term: Interprofessional relations; Subject Term: Interviewing; Subject Term: Social sciences; Subject Term: Teaching methods; Subject Term: Thematic analysis; Subject Term: Data analysis -- Software; Subject Term: Medical coding; Subject: Canada; Author-Supplied Keyword: data literacy; Author-Supplied Keyword: faculty–librarian collaboration; Author-Supplied Keyword: library data services; Author-Supplied Keyword: online data analysis; Author-Supplied Keyword: open data; Author-Supplied Keyword: secondary data; Number of Pages: 20p; Document Type: Article},
author = {Dechman, Margaret K and Syms, Laura R},
doi = {10.1080/01639269.2014.964617},
issn = {01639269},
journal = {Behavioral {\&} Social Sciences Librarian},
keywords = {Database management Research -- Methodology Inform},
number = {4},
pages = {188--207},
title = {{Working Together to Maximize the Utilization of Open Data Across Social Science and Professional Disciplines}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=lxh{\&}AN=99338176{\&}site=ehost-live},
volume = {33},
year = {2014}
}
@article{Harris2009,
annote = {Cited By :4304 Export Date: 17 November 2017},
author = {Harris, P A and Taylor, R and Thielke, R and Payne, J and Gonzalez, N and Conde, J G},
doi = {10.1016/j.jbi.2008.08.010},
journal = {Journal of Biomedical Informatics},
number = {2},
pages = {377--381},
title = {{Research electronic data capture (REDCap)-A metadata-driven methodology and workflow process for providing translational research informatics support}},
volume = {42},
year = {2009}
}
@article{Clement2017,
abstract = {This paper describes a collaborative approach taken by librarians at five small, regional liberal arts colleges to developing/enhancing research data management services on their campuses. The five colleges collectively belong to a consortium known as the Northwest Five Consortium. Over 10 months, librarians from the five schools collaborated to plan a data management and curation workshop with the goals of developing relationships with researchers working with data, developing their own research data management skills and services, and building a model for future training and outreach around institutional research data management services. This workshop brought together research teams including faculty, students, and librarians, and incorporated active learning modules as well as in-depth pre-workshop discussion. This article will discuss the context and background for this workshop, the model itself, and the outcomes and possibilities for future developments. [ABSTRACT FROM AUTHOR] Copyright of IFLA Journal is the property of Sage Publications, Ltd. and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
annote = {Clement, Ryan 1; Email Address: rclement@middlebury.edu; Blau, Amy 2; Abbaspour, Parvaneh 3; Gandour-Rood, Eli 4; Affiliations: 1 : Middlebury College, USA; 2 : Whitman College, USA; 3 : Lewis {\&} Clark College, USA; 4 : University of Puget Sound, USA; Source Info: Mar2017, Vol. 43 Issue 1, p105; Thesaurus Term: Information resources management; Thesaurus Term: Universities {\&} colleges; Subject Term: College campuses; Subject Term: Forums (Discussion {\&} debate); Subject Term: Consortia; Author-Supplied Keyword: Communities of practice; Author-Supplied Keyword: data services; Author-Supplied Keyword: information literacy and instruction; Author-Supplied Keyword: preservation and conservation; Author-Supplied Keyword: research data management; Number of Pages: 14p; Document Type: Article; Full Text Word Count: 8499},
author = {Clement, Ryan and Blau, Amy and Abbaspour, Parvaneh and Gandour-Rood, Eli},
doi = {10.1177/0340035216678239},
issn = {03400352},
journal = {IFLA Journal},
keywords = {Information resources management Universities {\&} co},
number = {1},
pages = {105--118},
title = {{Team-based data management instruction at small liberal arts colleges}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=lxh{\&}AN=121559485{\&}site=ehost-live},
volume = {43},
year = {2017}
}
@article{Read2015,
abstract = {Objective: The research obtained information to plan data-related products and services. Methods: Biomedical researchers in an academic medical center were selected using purposive sampling and interviewed using open-ended questions based on a literature review. Interviews were conducted until saturation was achieved. Results: Interview responses informed library planners about researchers' key data issues. Conclusions: This approach proved valuable for planning data management products and services and raising library visibility among clients in the research data realm. [ABSTRACT FROM AUTHOR] Copyright of Journal of the Medical Library Association is the property of Medical Library Association and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
annote = {Read, Kevin B. 1; Email Address: kevin.read@nyumc.org; Surkis, Alisa 2; Email Address: alisa.surkis@nyumc.org; Larson, Catherine 3; Email Address: Catherine.Larson@med.nyu.edu; McCrillis, Aileen 3; Email Address: Aileen.mccrillis@med.nyu.edu; Graff, Alice 4; Email Address: alice.graff@nyumc.org; Nicholson, Joey 5; Email Address: Joey.nicholson@med.nyu.edu; Juanchan Xu 6; Email Address: Juanchan.xu@med.nyu.edu; Affiliations: 1 : (Principal Investigator), Knowledge Management Librarian, Health Sciences Libraries, New York University, 577 First Avenue, New York, NY 10016; 2 : Translational Science Librarian, Health Sciences Libraries, New York University, 577 First Avenue, New York, NY 10016; 3 : Web Services Librarian, Health Sciences Libraries, New York University, 577 First Avenue, New York, NY 10016; 4 : Research Librarian/User Experience Librarian, Health Sciences Libraries, New York University, 577 First Avenue, New York, NY 10016; 5 : Education and Curriculum Librarian, Health Sciences Libraries, New York University, 577 First Avenue, New York, NY 10016; 6 : Ontology Manager, Health Sciences Libraries, New York University, 577 First Avenue, New York, NY 10016; Source Info: Jul2015, Vol. 103 Issue 3, p131; Thesaurus Term: Database management; Thesaurus Term: Medical libraries; Thesaurus Term: Research; Subject Term: Academic medical centers; Subject Term: Grounded theory; Subject Term: Interviewing; Subject Term: Science; Subject Term: Judgment sampling; Subject Term: Medical coding; Author-Supplied Keyword: Data management; Author-Supplied Keyword: health sciences libraries; Author-Supplied Keyword: interview methods; Author-Supplied Keyword: medical libraries; Number of Pages: 5p; Document Type: Article},
author = {Read, Kevin B and Surkis, Alisa and Larson, Catherine and McCrillis, Aileen and Graff, Alice and Nicholson, Joey and Juanchan, Xu},
doi = {10.3163/1536-5050.103.3.005},
issn = {15365050},
journal = {Journal of the Medical Library Association},
keywords = {Database management Medical libraries Research Aca},
number = {3},
pages = {131--135},
title = {{Starting the data conversation: informing data services at an academic health sciences library}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=lxh{\&}AN=108704527{\&}site=ehost-live},
volume = {103},
year = {2015}
}
@inproceedings{Schulte2006,
abstract = {In this article, we try to create a general, worldwide picture of teachers' opinion about what should be taught in introductory programming courses. We focus on the debate about restructuring CS1. The study explores what teachers believe is important to teach, what they actually teach, and what students find most difficult (according to their teachers), what is the general approach to teaching (programming language, IDE, object-orientation or not, type of institution), what topics are taught, and what role do the areas that novices find difficult play in introductory programming courses In addition, we explore how these specific topics fit into a larger conceptual classification: Earlier studies of topics taught in introductory programming focuses only on one dimension of a given topic - either relevance or difficulty. In this study, we evaluate each topic regarding three dimensions: relevance, difficulty and the cognitive level (according to Bloom's taxonomy). This allows giving a more faceted picture of teachers' beliefs in teaching introductory programming courses. Furthermore, we assess the role of findings from the eighties in today's teaching: The need to understand five different areas of programming. Are these areas still in focus; are they relevant, and what is the connection to the topics taught - especially object-oriented (OO) topics? A special focus is given on students' understanding of the execution of a (OO) program; one of the five areas. In order to connect the ideas of a notional machine to OO concepts we present a four levelled competence hierarchy for object-interaction. Teachers assessed the area 'understanding the notional machine' as least important. Despite this, they assessed the herachy of object-interaction - meant as basis for a notional machine for the OO-paradigm - as an important aspect. Although teachers stress the importance of teaching general abstract structures, teaching seems to focus on concrete programming issues. A conclusion for further research on teaching OO programming and concerning the hierarchy of object interaction is that teaching is not only a matter of topics, but also a matter of perspective on teaching the topics. Copyright 2006 ACM.},
annote = {Cited By :56
Export Date: 20 July 2018
Correspondence Address: Schulte, C.; Department of Computer Science, Free University Berlin, Takustrasse 9, D-14195 Berlin, Germany; email: schulte@inf.fu-berlin.de},
author = {Schulte, C and Bennedsen, J},
doi = {10.1145/1151588.1151593},
isbn = {1595934944 (ISBN); 9781595934949 (ISBN)},
keywords = {Abstract structures,CS1,Classification (of information),Cognitive systems,Course design,Course designs,Curricula,Engineering education,Learning systems,OO programming,Object interaction,Object interactions,Object oriented programming,Program comprehension,Teaching},
language = {English},
pages = {17--28},
title = {{What do teachers teach in introductory programming?}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-34247339383{\&}doi=10.1145{\%}2F1151588.1151593{\&}partnerID=40{\&}md5=1d6c0f25184857caad75fcbe57c63083 https://dl.acm.org/citation.cfm?doid=1151588.1151593},
volume = {2006},
year = {2006}
}
@article{Wilkinson2009,
abstract = {The cluster heat map is an ingenious display that simultaneously reveals row and column hierarchical cluster structure in a data matrix. It consists of a rectangular tiling, with each tile shaded on a color scale to represent the value of the corresponding element of the data matrix. The rows (columns) of the tiling are ordered such that similar rows (columns) are near each other. On the vertical and horizontal margins of the tiling are hierarchical cluster trees. This cluster heat map is a synthesis of several different graphic displays developed by statisticians over more than a century. We locate the earliest sources of this display in late 19th century publications, and trace a diverse 20th century statistical literature that provided a foundation for this most widely used of all bioinformatics displays.},
annote = {477fi
Times Cited:205
Cited References Count:43},
author = {Wilkinson, Leland and Friendly, Michael},
chapter = {179},
doi = {10.1198/tas.2009.0033},
isbn = {0003-13051537-2731},
journal = {The American Statistician},
keywords = {cluster analysis,decomposition,heatmap,microarray,patterns,proximity measures,seriation,visualization},
language = {English},
number = {2},
pages = {179--184},
title = {{The History of the Cluster Heat Map}},
volume = {63},
year = {2009}
}
@article{Treisman1992,
abstract = {The characteristics of automatized performance resemble those of preattentive processing in some respects. In the context of visual search tasks, these include spatially parallel processing, involuntary calling of attention, learning without awareness, and time-sharing with other tasks. However, this article reports some evidence suggesting that extended practice produces its effects through different mechanisms from those that underlie preattentive processing. The dramatic changes in search rate seem to depend not on the formation of new preattentive detectors for the task-relevant stimuli, nor on learned abstracted procedures for responding quickly and efficiently, but rather on changes that are very specific both to the particular stimuli and to the particular task used in practice. We suggest that the improved performance may depend on the accumulation of separate memory traces for each individual experience of a display (see Logan, 1988), and we show that the traces differ for conjunction search in which stimuli must be individuated and for feature search where a global response to the display is sufficient.},
annote = {Treisman, A
Vieira, A
Hayes, A
Journal Article
Research Support, U.S. Gov't, Non-P.H.S.
United States
Am J Psychol. 1992 Summer;105(2):341-62.},
author = {Treisman, A and Vieira, A and Hayes, A},
edition = {1992/01/01},
isbn = {0002-9556 (Print)0002-9556},
journal = {Am J Psychol},
keywords = {*Attention,*Awareness,*Mental Recall,*Pattern Recognition, Visual,*Practice (Psychology),Color Perception,Discrimination Learning,Humans,Orientation,Reaction Time},
language = {eng},
number = {2},
pages = {341--362},
pmid = {1621885},
title = {{Automaticity and preattentive processing}},
volume = {105},
year = {1992}
}
@misc{OfficeoftheNationalCoordinatorofHealthInformationTechnology2018,
author = {{Office of the National Coordinator of Health Information Technology}},
number = {October 27},
title = {{Health Information Exchange}},
url = {https://www.healthit.gov/topic/health-it-basics/health-information-exchange},
volume = {2018},
year = {2018}
}
@article{Wittenberg2017,
abstract = {University of California, Berkeley's Library and the central Research Information Technologies unit have collaborated to develop a research data management program that leverages each organization's expertise and resources to create a unified service. The service offers a range of workshops, consultation, and an online resource. Because of this collaboration, service areas that are often fully embedded in IT, like backup and secure storage, as well as services in the Library domain, like resource discovery and instruction, are integrated into a single research data management program. This case study discusses the establishment of the program, the obstacles in implementing it, and outcomes of the collaborative model. {\textcopyright} 2017, {\textcopyright} The Author(s) 2017.},
annote = {Cited By :8
Export Date: 15 July 2019
Correspondence Address: Wittenberg, J.; Indiana University, 107 S Indiana Ave, United States; email: jamie.wittenberg@gmail.com},
author = {Wittenberg, J and Elings, M},
doi = {10.1177/0340035216686982},
isbn = {03400352 (ISSN)},
journal = {IFLA Journal},
keywords = {Academic libraries,LIS as a profession,data services},
language = {English},
number = {1},
pages = {89--97},
publisher = {SAGE Publications Ltd},
title = {{Building a Research Data Management Service at the University of California, Berkeley: A tale of collaboration}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85014588509{\&}doi=10.1177{\%}2F0340035216686982{\&}partnerID=40{\&}md5=5671111898bf1d95a6c09145f0267e18},
volume = {43},
year = {2017}
}
@article{Partlo2014,
abstract = {While institutions, methodology and geography all present barriers for communication and development of infrastructure, sometimes the greatest barriers may be in reaching not across the world but across the hallway. Engaging in the work of unified infrastructure requires finding language that bridges modes of inquiry and meaning, so that all participants see their place in the whole. This work of finding shared language involves translation at many levels. Data librarians know that not everyone means the same thing by 'data' and increasingly they seek language that spans the practices of social science, sciences, humanities, and performing arts. This paper aims to highlight some of the ways in which data professionals are already adept at translation. Drawing on examples from work as a subject librarian and data professional at an undergraduate institution, I will elaborate on ways in which translation permeates the daily work of data librarians, from helping new researchers learn the language and methods of a field, to supporting faculty as they expand their teaching and research across disciplines. Additionally, librarians' role as semi-outsiders within the institution situates them well to help drive conversations spanning disciplinary modes of thinking, in which faculty may also find themselves as semi-outsiders. [ABSTRACT FROM AUTHOR] Copyright of IASSIST Quarterly is the property of IASSIST Quarterly and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
annote = {Partlo, Kristin 1; Email Address: kpartlo@carleton.edu; Affiliations: 1 : Reference {\&} Instruction Librarian for Social Sciences and Data at Carleton College in Minnesota, USA; Source Info: 2014, Vol. 38 Issue 2, p12; Thesaurus Term: Librarians; Subject Term: Translators; Subject Term: Translating services; Author-Supplied Keyword: Critique; Author-Supplied Keyword: Data profession; Author-Supplied Keyword: Data Theory; Author-Supplied Keyword: Language; Author-Supplied Keyword: Translation; Number of Pages: 4p; Document Type: Article},
author = {Partlo, Kristin},
issn = {07391137},
journal = {IASSIST Quarterly},
keywords = {Librarians Translators Translating services Critiq},
number = {2},
pages = {12--15},
title = {{From Data to the Creation of Meaning Part II: Data Librarian as Translator}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=lxh{\&}AN=102065485{\&}site=ehost-live},
volume = {38},
year = {2014}
}
@article{Koltay2015,
abstract = {Purpose – The role of data literacy is discussed in the light of such activities as data a quality, data management, data curation, and data citation. The differing terms and their relationship to the most important literacies are examined. The paper aims to discuss these issues. Design/methodology/approach – By stressing the importance of data literacy in fulfilling the mission of the contemporary academic library, the paper centres on information literacy, while the characteristics of other relevant literacies are also examined. The content of data literacy education is explained in the context of data-related activities. Findings – It can be concluded that there is a need for data literacy and it is advantageous to have a unified terminology. Data literacy can be offered both to researchers, who need to become data literate science workers and have the goal to educate data management professionals. Several lists of competencies contain important skills and abilities, many of them indicating the close relationship between data literacy and information literacy. It is vital to take a critical stance on hopes and fears, related to the promises of widespread ability of (big) data. Originality/value – The paper intends to be an add-on to the body of knowledge about information literacy and other literacies in the light of research data and data literacy. [ABSTRACT FROM AUTHOR] Copyright of Records Management Journal is the property of Emerald Publishing and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
annote = {Koltay, Tibor 1; Affiliations: 1 : Department of Information and Library Studies, Szent Istv{\'{a}}n University, J{\'{a}}szber{\'{e}}ny, Hungary; Source Info: 2015, Vol. 71 Issue 2, p401; Thesaurus Term: Information literacy; Thesaurus Term: Database management; Thesaurus Term: Data quality; Thesaurus Term: Information retrieval; Thesaurus Term: Data science (Information science); Author-Supplied Keyword: Academic libraries; Author-Supplied Keyword: Data; Author-Supplied Keyword: Research; Number of Pages: 15p; Document Type: Article},
author = {Koltay, Tibor},
doi = {10.1108/JD-02-2014-0026},
issn = {09565698},
journal = {Records Management Journal},
keywords = {Information literacy Database management Data qual},
number = {2},
pages = {401--415},
title = {{Data literacy: in search of a name and identity}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=lxh{\&}AN=103019050{\&}site=ehost-live},
volume = {71},
year = {2015}
}
@article{Wittenberg2017a,
abstract = {University of California, Berkeley's Library and the central Research Information Technologies unit have collaborated to develop a research data management program that leverages each organization's expertise and resources to create a unified service. The service offers a range of workshops, consultation, and an online resource. Because of this collaboration, service areas that are often fully embedded in IT, like backup and secure storage, as well as services in the Library domain, like resource discovery and instruction, are integrated into a single research data management program. This case study discusses the establishment of the program, the obstacles in implementing it, and outcomes of the collaborative model. [ABSTRACT FROM AUTHOR] Copyright of IFLA Journal is the property of Sage Publications, Ltd. and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
annote = {Wittenberg, Jamie 1; Email Address: jamie.wittenberg@gmail.com; Elings, Mary 2; Affiliations: 1 : Indiana University, Bloomington, USA; 2 : University of California, Berkeley, USA; Source Info: Mar2017, Vol. 43 Issue 1, p89; Thesaurus Term: Information resources management; Thesaurus Term: Information technology; Thesaurus Term: Automated library acquisitions systems; Subject Term: Research universities {\&} colleges; Author-Supplied Keyword: Academic libraries; Author-Supplied Keyword: data services; Author-Supplied Keyword: LIS as a profession; Number of Pages: 9p; Document Type: Article; Full Text Word Count: 6094},
author = {Wittenberg, Jamie and Elings, Mary},
doi = {10.1177/0340035216686982},
issn = {03400352},
journal = {IFLA Journal},
keywords = {Information resources management Information techn},
number = {1},
pages = {89--97},
title = {{Building a Research Data Management Service at the University of California, Berkeley}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=lxh{\&}AN=121559487{\&}site=ehost-live},
volume = {43},
year = {2017}
}
@inproceedings{Amar2005,
abstract = {Existing system level taxonomies of visualization tasks are geared more towards the design of particular representations than the facilitation of user analytic activity. We present a set of ten low level analysis tasks that largely capture people's activities while employing information visualization tools for understanding data. To help develop these tasks, we collected nearly 200 sample questions from students about how they would analyze five particular data sets from different domains. The questions, while not being totally comprehensive, illustrated the sheer variety of analytic questions typically posed by users when employing information visualization systems. We hope that the presented set of tasks is useful for information visualization system designers as a kind of common substrate to discuss the relative analytic capabilities of the systems. Further, the tasks may provide a form of checklist for system designers.},
author = {Amar, R and Eagan, J and Stasko, J},
booktitle = {IEEE Symposium on Information Visualization, 2005. INFOVIS 2005.},
doi = {10.1109/INFVIS.2005.1532136},
isbn = {1522-404X},
keywords = {Algorithm design and analysis,Chromium,Computer applications,Data visualization,Educational institutions,Information analysis,Motion pictures,Performance analysis,Taxonomy,analytic question,data analysis,data set analysis,data visualisation,information visualization system,information visualization tool,low level analysis task,system level taxonomy,user analytic activity,user interfaces,visualization task},
pages = {111--117},
title = {{Low-level components of analytic activity in information visualization}},
year = {2005}
}
@misc{SoftwareCarpentry2017,
author = {{Software Carpentry}},
title = {{R for Reproducible Scientific Analysis: Project Management With RStudio}},
url = {http://swcarpentry.github.io/r-novice-gapminder/02-project-intro/},
year = {2017}
}
@article{Torigoe2008,
abstract = {Abstract A poster is one method of informing the world about results from a research project. Whether serving as an aid for a presentation or standing alone, it should provide information about a project. Both substantive and stylistic qualities should contribute to effectively communicating one's conclusions. This appendix gives general guidelines and suggestions for poster content, layout, and design to assist in preparing an effective poster.},
author = {Torigoe, Sharon and Huang, Nick and Hall, Matthew and Ngo, Benson},
doi = {10.1002/9780470089941.eta05as00},
isbn = {1948-3430},
journal = {Current Protocols in Essential Laboratory Techniques},
keywords = {communication,poster,presentation},
number = {1},
pages = {A.5A.1--A.5A.14},
publisher = {Wiley-Blackwell},
title = {{Preparing and Presenting a Poster}},
url = {https://doi.org/10.1002/9780470089941.eta05as00},
volume = {00},
year = {2008}
}
@article{Coates2018,
author = {Coates, Heather L and Carlson, Jake and Clement, Ryan and Henderson, Margaret and Johnston, Lisa R and Shorish, Yasmeen},
doi = {10.7710/2162-3309.2226},
isbn = {2162-3309},
journal = {Journal of Librarianship and Scholarly Communication},
number = {1},
title = {{How are we Measuring Up? Evaluating Research Data Services in Academic Libraries}},
volume = {6},
year = {2018}
}
@article{Antell2014,
author = {Antell, Karen and Foote, Jody Bales and Turner, Jaymie and Shults, Brian},
chapter = {557},
doi = {10.5860/crl.75.4.557},
isbn = {2150-67010010-0870},
journal = {College {\&} Research Libraries},
number = {4},
pages = {557--574},
title = {{Dealing with Data: Science Librarians' Participation in Data Management at Association of Research Libraries Institutions}},
volume = {75},
year = {2014}
}
@article{Derrington1984,
abstract = {This paper introduces a new technique for the analysis of the chromatic properties of neurones, and applies it to cells in the lateral geniculate nucleus (l.g.n.) of macaque. The method exploits the fact that for any cell that combines linearly the signals from cones there is a restricted set of lights to which it is equally sensitive, and whose members can be exchanged for one another without evoking a response. Stimuli are represented in a three‐dimensional space defined by an axis along which only luminance varies, without change in chromaticity, a 'constant B' axis along which chromaticity varies without changing the excitation of blue‐sensitive (B) cones, a 'constant R {\&} G' axis along which chromaticity varies without change in the excitation of red‐sensitive (R) or green‐sensitive (G) cones. The orthogonal axes intersect at a white point. The isoluminant plane defined by the intersection of the 'constant B' and 'constant R {\&} G' axes contains lights that vary only in chromaticity. In polar coordinates the constant B axis is assigned the azimuth 0‐180 deg, and the constant R {\&} G axis the azimuth 90‐270 deg. Luminance is expressed as elevation above or below the isoluminant plane (‐90 to +90 deg). For any cell that combines cone signals linearly, there is one plane in this space, passing through the white point, that contains all lights that can be exchanged silently. The position of this 'null plane' provides the 'signature' of the cell, and is specified by its azimuth (the direction in which it intersects the isoluminant plane of the stimulus space) and its elevation (its angle of inclination to the isoluminant plane). A colour television receiver was used to produce sinusoidal gratings whose chromaticity and luminance could be modulated along any vector passing through the white point in the space described. The spatial and temporal frequencies of modulation could be varied over a large range. When stimulated by patterns of low spatial and low temporal frequency, two groups of cells in the parvocellular laminae of the l.g.n. were distinguished by the locations of their null planes. The null planes of the larger group were narrowly distributed about an azimuth of 92.6 deg and more broadly about an elevation of 51.5 deg, which suggests that they receive opposed, but not equally balanced, inputs from only R and G cones. These we call R‐G cells.(ABSTRACT TRUNCATED AT 400 WORDS) {\textcopyright} 1984 The Physiological Society},
annote = {Cited By :1043
Export Date: 14 January 2019},
author = {Derrington, A M and Krauskopf, J and Lennie, P},
doi = {10.1113/jphysiol.1984.sp015499},
journal = {The Journal of Physiology},
number = {1},
pages = {241--265},
title = {{Chromatic mechanisms in lateral geniculate nucleus of macaque}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0021646382{\&}doi=10.1113{\%}2Fjphysiol.1984.sp015499{\&}partnerID=40{\&}md5=4785dfd7fed7e1d353164ea50d84fb73},
volume = {357},
year = {1984}
}
@article{Harrower2003,
abstract = {Choosing effective colour schemes for thematic maps is surprisingly difficult. Color Brewer is an online tool designed to take some of the guesswork out of this process by helping users select appropriate colour schemes for their specific mapping needs by considering: the number of data classes; the nature of their data (matched with sequential, diverging and qualitative schemes): and the end-use environment for the map (e.g., CRT, LCD, printed, projected, photocopied). ColorBrewer contains 'learn more' tutorials to help guide users, prompts them to test-drive colour schemes as both map and legend, and provides output in five colour specification systems.},
annote = {Cited By :504
Export Date: 17 August 2019
Correspondence Address: Harrower, M.; Department of Geography, University of Wisconsin-Madison, 550 North Park Street, Madison, WI 53706, United States; email: maharrower@wisc.edu},
author = {Harrower, M and Brewer, C A},
doi = {10.1179/000870403235002042},
isbn = {00087041 (ISSN)},
journal = {Cartographic Journal},
keywords = {cartography,color,mapping,software,thematic mapping},
language = {English},
number = {1},
pages = {27--37},
title = {{ColorBrewer.org: An online tool for selecting colour schemes for maps}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0041813144{\&}doi=10.1179{\%}2F000870403235002042{\&}partnerID=40{\&}md5=367332d3b1835339bee32d7f026f8c14 https://www.tandfonline.com/doi/abs/10.1179/000870403235002042},
volume = {40},
year = {2003}
}
@article{Bosse2017,
abstract = {Computer programming courses are mandatory for many majors. However, the high rate of failures shows that students have difficulties in assimilating the topics. The objective of this research is to understand these difficulties. Analyzing diaries filled out by students and interviews with instructors, we identified difficulties related to language and understanding and some strategies used to mitigate them. The analysis and understanding of the difficulties may support the creation of teaching strategies and tools to facilitate the teaching and learning of computer programming. {\textcopyright} 2003-2012 IEEE.},
annote = {Export Date: 20 July 2018
Correspondence Address: Bosse, Y.; Federal University of Mato Grosso Do sulBrazil; email: yorah.bosse@ufms.br},
author = {Bosse, Y and Gerosa, M A},
doi = {10.1109/TLA.2017.8070426},
isbn = {15480992 (ISSN)},
journal = {IEEE Latin America Transactions},
keywords = {Computational thinkings,Computer programming,Difficulties,Education,Students,Teaching,barriers,computational thinking,introduction to programming,novices,programming learning},
language = {Portuguese},
number = {11},
pages = {2191--2199},
publisher = {IEEE Computer Society},
title = {{Difficulties of Programming Learning from the Point of View of Students and Instructors}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032615697{\&}doi=10.1109{\%}2FTLA.2017.8070426{\&}partnerID=40{\&}md5=769df26a8afbf6161c5cc7f898bb02d8 https://ieeexplore.ieee.org/ielx7/9907/8070403/08070426.pdf?tp={\&}arnumber=8070426{\&}isnumber=8070403},
volume = {15},
year = {2017}
}
@article{Neisser1977,
abstract = {Views J. J. Gibson's accounting for the stimulus with ecological optics as a revolutionary step that renders geometric optics obsolete. The idea that sensations are the building blocks from which a meaningful world is constructed is replaced by the notion that visual proprioception, or ego motion, and invariants in the optical array are central. It is contended that Gibson ignores what happens in the organism during perception and depends exclusively on the variables of light when he claims that the environment can be directly perceived and that perception need not be supplemented by concepts or inferences. An appropriate anticipatory scheme for accepting information and for exploration is called for to extend the theoretical possibilities that Gibson has established. (16 ref) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
address = {United Kingdom},
author = {Neisser, Ulric},
doi = {10.1111/j.1468-5914.1977.tb00375.x},
isbn = {1468-5914(Electronic),0021-8308(Print)},
journal = {Journal for the Theory of Social Behaviour},
keywords = {*Cognitive Processes,*Perception,*Theories,*Visual Perception,Consequence},
number = {1},
pages = {17--28},
publisher = {Blackwell Publishing},
title = {{Gibson's ecological optics: Consequences of a different stimulus description}},
volume = {7},
year = {1977}
}
@misc{Wright2018,
author = {Wright, Susan and McKinley, Jennah},
number = {October 14},
publisher = {New Mexico State University - Board of Regents},
title = {{NMSU: A Guide To Color}},
url = {https://aces.nmsu.edu/pubs/{\_}c/C316/welcome.html},
volume = {2018},
year = {2018}
}
@article{Raya1990,
abstract = {Three-dimensional image data produced by medical imaging scanners usually have unequal scanning resolution in different dimensions, the slice separation usually being much greater than the pixel size within an individual slice. The general practice in the three-dimensional display of organs based on such data is to first interpolate between slices to obtain isotropic resolution and then perform object identification and display operations. This implies that, if user interaction is required on a slice-by-slice basis to identify the object of interest (which often is the case), the effort needed is much (two-ten times) more than that required if the uninterpolated slice data were used for identifying the object. The situation becomes much (ten-50 times) worse if a fourth dimension of time is also involved, as in the case of a dynamic organ such as a beating heart. We present a new shape-based interpolation scheme for multidimensional images, which consists of first segmenting the given image data into a binary image, converting the binary image back into a gray image wherein the gray value of a point represents its shortest distance (positive value for points of the object and negative for those outside) from the cross-sectional boundary, and then interpolating the gray image. The set of all points with nonnegative values associated with them in the interpolated image constitutes the interpolated object. The method not only greatly minimizes the user involvement in interactive segmentation, but also leads to more accurate representation and depiction of dynamic as well as static objects. We present the general methodology and the implementation details of the new method and compare it on a qualitative and quantitative basis to the existing methods. The generality of the proposed scheme is illustrated with a number of medical imaging examples. {\textcopyright} 1990 IEEE},
annote = {Cited By :350
Export Date: 17 August 2019
Correspondence Address: Raya, S.P.; PURA Labs Inc., 603 S. Valencia Ave, Brea, CA 92621, United States},
author = {Raya, S P and Udupa, J K},
doi = {10.1109/42.52980},
isbn = {02780062 (ISSN)},
journal = {IEEE Transactions on Medical Imaging},
keywords = {Computer Programming--Algorithms,Image Processing,Imaging Techniques,Mathematical Techniques--Interpolation,Multidimensional Images,Shape Based Image Interpolation},
language = {English},
number = {1},
pages = {32--42},
title = {{Shape-Based Interpolation of Multidimensional Objects}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0025401290{\&}doi=10.1109{\%}2F42.52980{\&}partnerID=40{\&}md5=2615e7300a50f89c93663145a6e8c655 https://ieeexplore.ieee.org/document/52980/},
volume = {9},
year = {1990}
}
@misc{MylesWhite2017,
author = {{Myles White}, John},
title = {{ProjectTemplate}},
url = {http://projecttemplate.net/index.html},
year = {2017}
}
@inproceedings{Ritz2018,
abstract = {Much of modern biology requires quantitative and computational skills for the proper analysis of large-scale datasets, and there is a recognized need for computational training in undergraduate biology programs. This experience report describes a four-week unit designed to introduce fundamental computer science concepts and molecular biology concepts in an integrated fashion. The unit serves as the first four weeks of an introductory course taught within the Biology Department at an undergraduate institution, and is designed to introduce computational thinking to non-computational science majors. Survey results reveal that the course has attracted students from all years (first years through seniors), the majority of students have been women, and students have large self-perceived learning gains in computer science concepts. The unit shows promise for engaging non-computational students through applications in introductory molecular biology. {\textcopyright} 2018 Association for Computing Machinery.},
annote = {Export Date: 20 July 2018
Correspondence Address: Ritz, A.; Reed College, Biology Department, 3203 SE Woodstock Boulevard, United States; email: aritz@reed.edu},
author = {Ritz, A},
doi = {10.1145/3159450.3159590},
isbn = {9781450351034 (ISBN)},
keywords = {Biomolecules,Biophysics,Computational biology,Computational science,Computational skills,Computational thinking,Computational thinkings,Computer programming,Education computing,Introductory programming,Large-scale datasets,Personnel training,Students,Surveys,Undergraduate education,Undergraduate institutions},
language = {English},
pages = {239--244},
publisher = {Association for Computing Machinery, Inc},
title = {{Programming the central dogma: An integrated unit on computer science and molecular biology concepts}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046107661{\&}doi=10.1145{\%}2F3159450.3159590{\&}partnerID=40{\&}md5=a0636d0b6b87ff9dc9bab624ea7f08fe http://delivery.acm.org/10.1145/3160000/3159590/p239-ritz.pdf?ip=137.187.166.165{\&}id=3159590{\&}acc=OA{\&}key=4D4702B0},
volume = {2018-Janua},
year = {2018}
}
@article{Bressler1995,
abstract = {The well-known parcellation of the mammalian cerebral cortex into a large number of functionally distinct cytoarchitectonic areas presents a problem for understanding the complex cortical integrative functions that underlie cognition. How do cortical areas having unique individual functional properties cooperate to accomplish these complex operations? Do neurons distributed throughout the cerebral cortex act together in large-scale functional assemblages? This review examines the substantial body of evidence supporting the view that complex integrative functions are carried out by large-scale networks of cortical areas. Pathway tracing studies in non-human primates have revealed widely distributed networks of interconnected cortical areas, providing an anatomical substrate for large-scale parallel processing of information in the cerebral cortex. Functional coactivation of multiple cortical areas has been demonstrated by neurophysiological studies in non-human primates and several different cognitive functions have been shown to depend on multiple distributed areas by human neuropsychological studies. Electriphysiological studies on interareal synchronization have provided evidence that active neurons in different cortical areas may become not only coactive, but also functionally interdependent. The computational advantages of synchronization between cortical areas in large-scale networks have been elucidated by studies using artificial neural network models. Recent observations of time-varying multi-areal cortical synchronization suggest that the functional topology of a large-scale cortical network is dynamically reorganized during visuomotor behavior. {\textcopyright} 1995.},
annote = {Cited By :331
Export Date: 17 August 2019
CODEN: BRERD
Correspondence Address: Bressler, S.L.; Center for Complex Systems, Florida Atlantic University, 777 Glades Road, Boca Raton, FL 33431, United States},
author = {Bressler, S L},
doi = {10.1016/0165-0173(94)00016-I},
isbn = {01650173 (ISSN)},
journal = {Brain Research Reviews},
keywords = {Animal,Cerebral cortex,Cognition,Cross-correlation,Nerve Net,Neural network,Support, U.S. Gov't, P.H.S.,Temporal synchronization,animal experiment,brain cortex,electrophysiology,human,human experiment,nerve cell network,neuropsychology,nonhuman,normal human,primate,priority journal,rat,review},
language = {English},
number = {3},
pages = {288--304},
title = {{Large-scale cortical networks and cognition}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0029008978{\&}doi=10.1016{\%}2F0165-0173{\%}2894{\%}2900016-I{\&}partnerID=40{\&}md5=a1adb372b8f448b89ebcc7c505113552 https://www.sciencedirect.com/science/article/pii/016501739400016I?via{\%}3Dihub},
volume = {20},
year = {1995}
}
@incollection{Kirk2016,
address = {Thousand Oaks, CA},
annote = {2015957322
Andy Kirk.},
author = {Kirk, Andy},
booktitle = {Data visualisation : a handbook for data driven design},
isbn = {97814739605419781473912137},
pages = {pages cm},
pmid = {18855341},
publisher = {SAGE Publications},
title = {{Visualisation Workflow}},
year = {2016}
}
@incollection{Igual2017a,
abstract = {In this chapter, first we introduce some of the cornerstone tools that data scientists use and then we offer a basic overview of the Python language and its data science ecosystem. Examples of the most common data structures and basic functions that data scientists perform are explained to provide the basis for a better understanding of later chapters.},
address = {Cham},
author = {Igual, Laura and Segu{\'{i}}, Santi},
booktitle = {Introduction to Data Science: A Python Approach to Concepts, Techniques and Applications},
doi = {10.1007/978-3-319-50017-1_2},
editor = {Igual, Laura and Segu{\'{i}}, Santi},
isbn = {978-3-319-50017-1},
pages = {5--28},
publisher = {Springer International Publishing},
title = {{Toolboxes for Data Scientists}},
url = {https://doi.org/10.1007/978-3-319-50017-1{\_}2},
year = {2017}
}
@unpublished{Brennan2015,
address = {Bethesda},
author = {Brennan, P},
publisher = {NINR Big Data Bootcamp},
title = {{Big Data in Nursing}},
year = {2015}
}
@misc{CornellUniversity2019,
author = {{Cornell University}},
title = {{Guide to writing "readme" style metadata | Research Data Management Service Group}},
url = {https://data.research.cornell.edu/content/readme},
year = {2019}
}
@unpublished{Anderson2017,
address = {bioRxiv},
author = {Anderson, Warwick and Apweiler, Rolf and Bateman, Alex and Bauer, Guntram A and Berman, Helen and Blake, Judith A and Blomberg, Niklas and Burley, Stephen K and Cochrane, Guy and {Di Francesco}, Valentina and Donohue, Tim and Durinx, Christine and Game, Alfred and Green, Eric and Gojobori, Takashi and Goodhand, Peter and Hamosh, Ada and Hermjakob, Henning and Kanehisa, Minoru and Kiley, Robert and McEntyre, Johanna and McKibbin, Rowan and Miyano, Satoru and Pauly, Barbara and Perrimon, Norbert and Ragan, Mark A and Richards, Geoffrey and Teo, Yik-Ying and Westerfield, Monte and Westhof, Eric and Lasko, Paul F},
doi = {10.1101/110825},
title = {{Towards Coordinated International Support of Core Data Resources for the Life Sciences}},
url = {https://www.biorxiv.org/content/10.1101/110825v3},
year = {2017}
}
@article{Bates2014,
abstract = {The US health care system is rapidly adopting electronic health records, which will dramatically increase the quantity of clinical data that are available electronically. Simultaneously, rapid progress has been made in clinical analytics-techniques for analyzing large quantities of data and gleaning new insights from that analysis-which is part of what is known as big data. As a result, there are unprecedented opportunities to use big data to reduce the costs of health care in the United States. We present six use cases-that is, key examples-where some of the clearest opportunities exist to reduce costs through the use of big data: high-cost patients, readmissions, triage, decompensation (when a patient's condition worsens), adverse events, and treatment optimization for diseases affecting multiple organ systems. We discuss the types of insights that are likely to emerge from clinical analytics, the types of data needed to obtain such insights, and the infrastructure-analytics, algorithms, registries, assessment scores, monitoring devices, and so forth-that organizations will need to perform the necessary analyses and to implement changes that will improve care while reducing costs. Our findings have policy implications for regulatory oversight, ways to address privacy concerns, and the support of research on analytics. {\textcopyright} 2014 by Project HOPE - The People-to-People Health Foundation.},
annote = {Cited By :138 Export Date: 14 March 2018},
author = {Bates, D W and Saria, S and Ohno-Machado, L and Shah, A and Escobar, G},
doi = {10.1377/hlthaff.2014.0041},
edition = {2014/07/10},
isbn = {1544-5208 (Electronic)0278-2715 (Linking)},
journal = {Health Affairs},
keywords = {APACHE,Data Mining,Datasets as Topic,Delivery of Health Care,Disease Management,Electronic Health Records,Humans,Risk Factors,Triage,United States,adverse outcome,algorithm,antibiotic agent,antibiotic therapy,article,big data,clinical research,critically ill patient,data analysis,devices,drug safety,economics,electronic health record,emergency health service,health care cost,health care delivery,health care organization,health care policy,health care system,high risk patient,hospital patient,hospital readmission,human,infection,information processing,intensive care unit,kidney failure,monitoring,morbidity,mortality,newborn sepsis,outcome assessment,privacy,procedures,register,risk factor,scoring system},
number = {7},
pages = {1123--1131},
pmid = {25006137},
title = {{Big data in health care: Using analytics to identify and manage high-risk and high-cost patients}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905990877{\&}doi=10.1377{\%}2Fhlthaff.2014.0041{\&}partnerID=40{\&}md5=60dfaf61eeb5cdb29fd7ca4ec954db94},
volume = {33},
year = {2014}
}
@article{Larkin1987,
abstract = {We distinguish diagrammatic from sentential paper-and-pencil representations of information by developing alternative models of information-processing systems that are informationally equivalent and that can be characterized as sentential or diagrammatic. Sentential representations are sequential, like the propositions in a text. Diagrammatic representations are indexed by location in a plane. Diagrammatic representations also typically display information that is only implicit in sentential representations and that therefore has to be computed, sometimes at great cost, to make it explicit for use. We then contrast the computational efficiency of these representations for solving several illustrative problems in mathematics and physics. When two representations are informationally equivalent, their computational efficiency depends on the information-processing operators that act on them. Two sets of operators may differ in their capabilities for recognizing patterns, in the inferences they can carry out directly, and in their control strategies (in particular, the control of search). Diagrammatic and sentential representations support operators that differ in all of these respects. Operators working on one representation may recognize features readily or make inferences directly that are difficult to realize in the other representation. Most important, however, are differences in the efficiency of search for information and in the explicitness of information. In the representations we call diagrammatic, information is organized by location, and often much of the information needed to make an inference is present and explicit at a single location. In addition, cues to the next logical step in the problem may be present at an adjacent location. Therefore problem solving can proceed through a smooth traversal of the diagram, and may require very little search or computation of elements that had been implicit.},
author = {Larkin, Jill H and Simon, Herbert A},
doi = {10.1111/j.1551-6708.1987.tb00863.x},
isbn = {0364-0213},
journal = {Cognitive Science},
number = {1},
pages = {65--100},
publisher = {Wiley/Blackwell (10.1111)},
title = {{Why a Diagram is (Sometimes) Worth Ten Thousand Words}},
url = {https://doi.org/10.1111/j.1551-6708.1987.tb00863.x https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.1551-6708.1987.tb00863.x},
volume = {11},
year = {1987}
}
@article{Pretorius2009,
abstract = {Information visualization is a user-centered design discipline. In this article we argue, however, that designing information visualization techniques often requires more than designing for user requirements. Additionally, the data that are to be visualized must also be carefully considered. An approach based on both the user and their data is encapsulated by two questions, which we argue information visualization designers should continually ask themselves: What does the user want to see? and What do the data want to be? As we show by presenting cases, these two points of departure are mutually reinforcing. By focusing on the data, new insight is gained into the requirements of the user, and vice versa, resulting in more effective visualization techniques. {\textcopyright} 2009 Palgrave Macmillan.},
annote = {Cited By :20
Export Date: 26 June 2019
Correspondence Address: Pretorius, A. J.; Department of Mathematics and Computer Science, Technische Universiteit Eindhoven, PO Box 513, 5600 MB Eindhoven, Netherlands},
author = {Pretorius, A J and {Van Wijk}, J J},
doi = {10.1057/ivs.2009.13},
isbn = {14738716 (ISSN)},
journal = {Information Visualization},
keywords = {Case study,Data visualization,Data-centered design,Design,Design study,Evaluation,Information analysis,Information systems,Information visualization,Research,User-centered design,Visualization},
language = {English},
number = {3},
pages = {153--166},
title = {{What does the user want to see? What do the data want to be}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-69249159948{\&}doi=10.1057{\%}2Fivs.2009.13{\&}partnerID=40{\&}md5=12b27f087a4b2fc5bff3f652ddfe67a1},
volume = {8},
year = {2009}
}
@unpublished{Federer2017,
author = {Federer, Lisa},
publisher = {NNLM Beyond the SEA Webinar Series},
title = {{Data Science 101}},
year = {2017}
}
@book{Berinato2016,
abstract = {"A good visualization can communicate the nature and potential impact of ideas more powerfully than any other form of communication. For a long time, "dataviz" was left to specialists-data scientists and professional designers. No longer. A new generation of tools and massive amounts of available data make it easy for anyone to create visualizations that communicate ideas far more effectively than generic spreadsheet charts ever could. What's more, building good charts is quickly becoming a need-to-have skill for managers-if you're not doing it, another manager is, and they're getting noticed for it, and getting credit for your company's success. In Good Charts, dataviz maven Scott Berinato provides an essential guide to how visualization works and how to use this new language to impress and persuade. Dataviz is where spreadsheets and word processors were in the early 1980s-on the cusp of changing how we work. Berinato lays out a system for thinking visually and building better charts through a process of talking, sketching, and prototyping. The book goes well beyond proffering a set of static rules for making visualizations and taps into well-established and vanguard research in visual perception and neuroscience, as well as the emerging field of visualization science, to explore why good charts (and bad ones) create "feelings behind our eyes." Along the way, Berinato also includes many engaging vignettes of dataviz pros, illustrating the ideas in practice. Good Charts will help you turn plain, uninspiring charts that merely present information into smart, effective visualizations that powerfully convey ideas. This is your go-to guide for dataviz-the new language of business." --},
address = {Boston, Massachusetts},
annote = {2015046676
Scott Berinato.
19 x 25 cm
Includes bibliographical references (233-245) and index.},
author = {Berinato, Scott},
isbn = {9781633690707 (paperback)},
keywords = {BUSINESS {\&} ECONOMICS / Business Communication / Ge,BUSINESS {\&} ECONOMICS / Business Communication / Me,BUSINESS {\&} ECONOMICS / Strategic Planning.,Business presentations Charts, diagrams, etc.,Communication in management.,Visual communication.},
pages = {255 pages},
pmid = {18936654},
publisher = {Harvard Business Review Press},
title = {{Good charts : the HBR guide to making smarter, more persuasive data visualizations}},
year = {2016}
}
@incollection{Wilkinson2005a,
address = {New York},
annote = {2005043230
Leland Wilkinson ; with contributions by Graham Wills ... [et al.].
ill. (some col.) ; 24 cm.
Includes bibliographical references (p. [635]-671) and indexes.},
author = {Wilkinson, Leland and Wills, Graham},
booktitle = {The grammar of graphics},
edition = {2nd},
isbn = {0387245448},
keywords = {Statistics Graphic methods Data processing.},
pages = {85--109},
pmid = {13852437},
publisher = {Springer},
title = {{Scales}},
year = {2005}
}
@inproceedings{Smith1978,
author = {Smith, Alvy Ray},
booktitle = {SIGGRAPH '78 Proceedings of the 5th annual conference on Computer graphics and interactive techniques},
doi = {10.1145/965139.807361},
isbn = {0097-8930},
number = {3},
pages = {12--19},
title = {{Color gamut transform pairs}},
volume = {12},
year = {1978}
}
@inproceedings{Alzaid2017,
abstract = {Programming novices usually find acquiring the ability to write programs challenging at first, however, they overcome this obstacle as they encounter more opportunities in the learning process. Providing learners with distributed practices and the ability to self-assess their programming knowledge is key to measure their development and guide them towards programming proficiency. In this work, we introduced QuizIT, a programming learning tool designed for novices. We conducted a classroom study and collected a semester long data to measure the effectives of the tool to achieve the design objectives. We analyzed the study data and provided the preliminary results from statistical perspective, as well as evaluating the effectiveness of the tool from learners' outcome. The data showed the positive effect of learners' usage of the tool on their course performance. We reported correlations exists in the data between effort (by actively benefiting and reflecting to the small learning opportunities) and the course outcome. {\textcopyright} 2017 IEEE.},
annote = {Export Date: 20 July 2018
CODEN: PFECD},
author = {Alzaid, M and Trivedi, D and Hsiao, I H},
doi = {10.1109/FIE.2017.8190593},
isbn = {15394565 (ISSN); 9781509059195 (ISBN)},
keywords = {Course performance,Curricula,Design objectives,Learning opportunity,Programming knowledge,Programming learning,Programming proficiency,QuizIT,Self assessment,Self-assessment,Teaching},
language = {English},
pages = {1--9},
publisher = {Institute of Electrical and Electronics Engineers Inc.},
title = {{The effects of bite-size distributed practices for programming novices}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85043269261{\&}doi=10.1109{\%}2FFIE.2017.8190593{\&}partnerID=40{\&}md5=baccaab466ecec25e945cad80fd10450 https://ieeexplore.ieee.org/ielx7/8124740/8190427/08190593.pdf?tp={\&}arnumber=8190593{\&}isnumber=8190427},
volume = {2017-Octob},
year = {2017}
}
@article{Tversky1971,
author = {Tversky, Amos and Kahneman, Daniel},
chapter = {105},
doi = {10.1037/h0031322},
isbn = {1939-14550033-2909},
journal = {Psychological Bulletin},
number = {2},
pages = {105--110},
title = {{Belief in the law of small numbers}},
volume = {76},
year = {1971}
}
@incollection{Wilkinson2005b,
address = {New York},
annote = {2005043230
Leland Wilkinson ; with contributions by Graham Wills ... [et al.].
ill. (some col.) ; 24 cm.
Includes bibliographical references (p. [635]-671) and indexes.},
author = {Wilkinson, Leland and Wills, Graham},
booktitle = {The grammar of graphics},
edition = {2nd},
isbn = {0387245448},
keywords = {Statistics Graphic methods Data processing.},
pages = {2--19},
pmid = {13852437},
publisher = {Springer},
title = {{Introduction}},
year = {2005}
}
@misc{Knaflic2015,
address = {Hoboken, New Jersey},
author = {Knaflic, Cole Nussbaumer},
isbn = {9781119002253 (pbk.)1119002257},
keywords = {Business communication.,Business presentations.,Computer graphics.,Information visualization.},
pages = {xiii, 267 pages},
publisher = {Wiley},
title = {{Storytelling with data a data visualization guide for business professionals}},
year = {2015}
}
@article{Koulouri2014,
abstract = {Teaching programming to beginners is a complex task. In this article, the effects of three factors - choice of programming language, problem-solving training, and the use of formative assessment - on learning to program were investigated. The study adopted an iterative methodological approach carried out across 4 consecutive years. To evaluate the effects of each factor (implemented as a single change in each iteration) on students' learning performance, the study used quantitative, objective metrics. The findings revealed that using a syntactically simple language (Python) instead of a more complex one (Java) facilitated students' learning of programming concepts. Moreover, teaching problem solving before programming yielded significant improvements in student performance. These two factors were found to have variable effects on the acquisition of basic programming concepts. Finally, it was observed that effective formative feedback in the context of introductory programming depends on multiple parameters. The article discusses the implications of these findings, identifies avenues for further research, and argues for the importance of studies in computer science education anchored on sound research methodologies to produce generalizable results. 2014 Copyright is held by the owner/author(s).},
annote = {Cited By :21
Export Date: 20 July 2018},
author = {Koulouri, T and Lauria, S and Macredie, R D},
doi = {10.1145/2662412},
isbn = {19466226 (ISSN)},
journal = {ACM Transactions on Computing Education},
keywords = {CS1,Computer and information science educations,Computer programming,Computer programming languages,Curricula,Curriculum,Education,Education computing,Empirical studies,Engineering education,Experimentation,Formative feedback,Formative feedbacks,Human engineering,Human factors,Iterative methods,Java programming language,K.3.2 [computers and education]: computer and info,Learning programming,Measurement,Measurements,Novice programmer,Novice programmers,Problem oriented languages,Problem solving,Programming languages,Students,Teaching strategies,Teaching strategy},
language = {English},
number = {4},
publisher = {Association for Computing Machinery},
title = {{Teaching introductory programming: A quantitative evaluation of different approaches}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84995571199{\&}doi=10.1145{\%}2F2662412{\&}partnerID=40{\&}md5=7a3f0c6c45058d2a5e8072064b58a2eb https://dl.acm.org/citation.cfm?doid=2698235.2662412},
volume = {14},
year = {2014}
}
@misc{Rucker2018,
author = {Rucker, Don},
booktitle = {Health Affairs Blog: June 19, 2018},
doi = {DOI: 10.1377/hblog20180618.138568},
number = {October 25},
title = {{Achieving The Interoperability Promise Of 21st Century Cures}},
volume = {2018},
year = {2018}
}
@inproceedings{Joblove1978,
author = {Joblove, George H and Greenberg, Donald},
booktitle = {SIGGRAPH '78 Proceedings of the 5th annual conference on Computer graphics and interactive techniques},
title = {{Color Spaces for Computer Graphics}},
year = {1978}
}
@misc{Schwabish2014,
abstract = {Jon Schwabish and Severino Ribecca recently released a poster taxonomy of different types of charts, and how they all relate to each other. We think this is a great resource for designers everywhere, so we were especially interested in their take on the project. The Graphic Continuum began as I Read more...},
author = {Schwabish, Jon},
booktitle = {Scribblelive},
number = {April 1},
publisher = {Scribblelive},
title = {{The Graphic Continuum}},
url = {http://www.scribblelive.com/blog/2014/10/01/graphic-continuum/},
volume = {2017},
year = {2014}
}
@article{Lyon2016,
abstract = {This article presents a case study where students aspiring to professional library roles who need to understand diverse disciplinary research data practices are placed in a laboratory with domain researchers during an immersive module within graduate MLIS programs at the School of Information Sciences (iSchool), University of Pittsburgh. A qualitative analysis of evaluation commentary from faculty researchers and MLIS students demonstrates their positive bilateral learning experiences. The potential extension of the immersive model for the delivery of research data services directly to researchers at their point of need is explored and a connection made with the established concept of an informationist, as a medical library specialist working in a clinical setting. The re-engineering challenges for academic libraries in operationalizing the immersive model for research data services are articulated, together with the challenges for iSchools in building workforce capacity and capability for immersive team science. {\textcopyright} 2016, {\textcopyright} Published with license by Taylor {\&} Francis Group, LLC.},
annote = {Cited By :5
Export Date: 15 July 2019
Correspondence Address: Lyon, L.; School of Information Sciences, University of Pittsburgh, 135 North Bellefield Avenue, United States; email: elyon@pitt.edu},
author = {Lyon, L},
doi = {10.1080/13614533.2016.1159969},
isbn = {13614533 (ISSN)},
journal = {New Review of Academic Librarianship},
keywords = {academic library service models,data curation education,immersive team science,research data management},
language = {English},
number = {4},
pages = {391--409},
publisher = {Routledge},
title = {{Librarians in the Lab: Toward Radically Re-Engineering Data Curation Services at the Research Coalface}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84962383284{\&}doi=10.1080{\%}2F13614533.2016.1159969{\&}partnerID=40{\&}md5=5b5166bfab8185c8d78768883b03cb3d https://www.tandfonline.com/doi/full/10.1080/13614533.2016.1159969},
volume = {22},
year = {2016}
}
@article{Ma2011,
abstract = {The teaching of introductory computer programming seems far from successful, with many first-year students performing more poorly than expected. One possible reason for this is that novices hold 'non-viable' mental models (internal explanations of how something works) of key programming concepts which then cause misconceptions and difficulties. An initial study investigated the apparent viability of novices' models of fundamental programming concepts, focusing on value and reference assignment. This revealed that many students appeared to hold 'non-viable' mental models of these key concepts and that those students who appeared to hold viable mental models performed significantly better in programming tasks than those with non-viable models. To address this, a teaching model integrating cognitive conflict and program visualisation is proposed. A series of studies found that this teaching model is potentially effective in enhancing engagement with learning materials and may therefore help novice programmers develop a better understanding of key concepts. {\textcopyright} 2011 Taylor {\&} Francis.},
annote = {Cited By :22
Export Date: 20 July 2018
Correspondence Address: Roper, M.; Department of Computer and Information Sciences, University of Strathclyde, Glasgow, Scotland, United Kingdom; email: marc.roper@cis.strath.ac.uk},
author = {Ma, L and Ferguson, J and Roper, M and Wood, M},
doi = {10.1080/08993408.2011.554722},
isbn = {08993408 (ISSN)},
journal = {Computer Science Education},
keywords = {Assignment,Constructivism,Empirical studies,Mental models,Novice programmers,Teaching/learning strategies},
language = {English},
number = {1},
pages = {57--80},
title = {{Investigating and improving the models of programming concepts held by novice programmers}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-79953732398{\&}doi=10.1080{\%}2F08993408.2011.554722{\&}partnerID=40{\&}md5=f58bd916e13fd8df0112f4c7a55028b1 https://www.tandfonline.com/doi/abs/10.1080/08993408.2011.554722},
volume = {21},
year = {2011}
}
@article{Borner2003,
author = {B{\"{o}}rner, Katy and Chen, Chaomei and Boyack, Kevin W},
doi = {10.1002/aris.1440370106},
isbn = {0066-4200},
journal = {Annual Review of Information Science and Technology},
number = {1},
pages = {179--255},
publisher = {John Wiley {\&} Sons, Ltd},
title = {{Visualizing knowledge domains}},
url = {https://doi.org/10.1002/aris.1440370106 https://onlinelibrary.wiley.com/doi/pdf/10.1002/aris.1440370106},
volume = {37},
year = {2003}
}
@article{Mons2017,
author = {Mons, Barend and Neylon, Cameron and Velterop, Jan and Dumontier, Michel and {da Silva Santos}, Luiz Olavo Bonino and Wilkinson, Mark D},
chapter = {49},
doi = {10.3233/isu-170824},
isbn = {1875878901675265},
journal = {Information Services {\&} Use},
number = {1},
pages = {49--56},
title = {{Cloudy, increasingly FAIR; revisiting the FAIR Data guiding principles for the European Open Science Cloud}},
volume = {37},
year = {2017}
}
@article{Heidorn2007,
abstract = {Data management and integration are complicated and ongoing problems that will require commitment of resources and expertise from the various biological science communities. Primary components of successful cross-scale integration are smooth information management and migration from one context to another. We call for a broadening of the definition of bioinformatics and bioinformatics training to span biological disciplines and biological scales. Training programs are needed that educate a new kind of informatics professional, Biological Information Specialists, to work in collaboration with various discipline-specific research personnel. Biological Information Specialists are an extension of the informationist movement that began within library and information science (LIS) over 30 years ago as a professional position to fill a gap in clinical medicine. These professionals will help advance science by improving access to scientific information and by freeing scientists who are not interested in data management to concentrate on their science. {\textcopyright} 2007 Heidorn et al; licensee BioMed Central Ltd.},
annote = {Cited By :8
Export Date: 15 July 2019
Correspondence Address: Palmer, C.L.; Graduate School of Library and Information Science, University of Illinois at Urbana-Champaign, Urbana-Champaign, IL, United States; email: clpalmer@uiuc.edu},
author = {Heidorn, P B and Palmer, C L and Wright, D},
doi = {10.1186/1747-5333-2-1},
isbn = {17475333 (ISSN)},
journal = {Journal of Biomedical Discovery and Collaboration},
language = {English},
number = {1},
title = {{Biological information specialists for biological informatics}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-34248388045{\&}doi=10.1186{\%}2F1747-5333-2-1{\&}partnerID=40{\&}md5=1f5f8af8a0cfb93b28a497680273dd80 https://j-biomed-discovery.biomedcentral.com/track/pdf/10.1186/1747-5333-2-1},
volume = {2},
year = {2007}
}
@incollection{Kirk2012b,
address = {Birmingham, UK},
author = {Kirk, Andy},
booktitle = {Data visualization a successful design process},
keywords = {Electronic books.,Information visualization.,Software visualization.},
pages = {iv, 189 p.},
pmid = {12581277},
publisher = {Packt Pub.},
title = {{Chapter 2: Setting the purpose and identifying key factors}},
year = {2012}
}
@article{Schiermeier2018,
annote = {Schiermeier, Quirin
eng
England
Nature. 2018 Mar 15;555(7696):403-405. doi: 10.1038/d41586-018-03071-1.},
author = {Schiermeier, Q},
doi = {10.1038/d41586-018-03071-1},
edition = {2018/03/16},
isbn = {1476-4687 (Electronic)0028-0836 (Linking)},
journal = {Nature},
keywords = {*Information Storage and Retrieval,*Open Access Publishing,*Research Design,*Research Personnel/education/standards,Confidentiality,Copyright,Financing, Organized/organization {\&} administration,Information Management/*education/*methods,Research Report/*standards,Research Support as Topic},
number = {7696},
pages = {403--405},
pmid = {29542709},
title = {{Data management made simple}},
url = {https://www.ncbi.nlm.nih.gov/pubmed/29542709},
volume = {555},
year = {2018}
}
@article{Fecher2017,
author = {Fecher, Benedikt and Friesike, Sascha and Hebing, Marcel and Linek, Stephanie},
doi = {10.1057/palcomms.2017.51},
isbn = {2055-1045},
journal = {Palgrave Communications},
number = {1},
title = {{A reputation economy: how individual reward considerations trump systemic arguments for open access to data}},
volume = {3},
year = {2017}
}
@misc{,
number = {October 14},
publisher = {Wikipedia},
title = {{Primary color}},
url = {https://en.wikipedia.org/wiki/Primary{\_}color},
volume = {2018},
year = {2018}
}
@incollection{Wilkinson2005c,
address = {New York},
annote = {2005043230
Leland Wilkinson ; with contributions by Graham Wills ... [et al.].
ill. (some col.) ; 24 cm.
Includes bibliographical references (p. [635]-671) and indexes.},
author = {Wilkinson, Leland and Wills, Graham},
booktitle = {The grammar of graphics},
edition = {2nd},
isbn = {0387245448},
keywords = {Statistics Graphic methods Data processing.},
pages = {xviii, 690 p.},
pmid = {13852437},
publisher = {Springer},
title = {{Variables}},
year = {2005}
}
@article{Starr2015,
abstract = {Reproducibility and reusability of research results is an important concern in scientific communication and science policy. A foundational element of reproducibility and reusability is the open and persistently available presentation of research data. However, many common approaches for primary data publication in use today do not achieve sufficient long-term robustness, openness, accessibility or uniformity. Nor do they permit comprehensive exploitation by modern Web technologies. This has led to several authoritative studies recommending uniform direct citation of data archived in persistent repositories. Data are to be considered as first-class scholarly objects, and treated similarly in many ways to cited and archived scientific and scholarly literature. Here we briefly review the most current and widely agreed set of principle-based recommendations for scholarly data citation, the Joint Declaration of Data Citation Principles (JDDCP). We then present a framework for operationalizing the JDDCP; and a set of initial recommendations on identifier schemes, identifier resolution behavior, required metadata elements, and best practices for realizing programmatic machine actionability of cited data. The main target audience for the common implementation guidelines in this article consists of publishers, scholarly organizations, and persistent data repositories, including technical staff members in these organizations. But ordinary researchers can also benefit fromthese recommendations. The guidance provided here is intended to help achieve widespread, uniform human and machine accessibility of deposited data, in support of significantly improved verification, validation, reproducibility and re-use of scholarly/scientific data.},
annote = {Cited By :42
Export Date: 9 August 2019
Correspondence Address: Clark, T.; Harvard Medical SchoolUnited States; email: tim{\_}clark@harvard.edu},
author = {Starr, J and Castro, E and Crosas, M and Dumontier, M and Downs, R R and Duerr, R and Haak, L L and Haendel, M and Herman, I and Hodson, S and Hourcl{\'{e}}, J and Kratz, J E and Lin, J and Nielsen, L H and Nurnberger, A and Proell, S and Rauber, A and Sacchi, S and Smith, A and Taylor, M and Clark, T},
doi = {10.7717/peerj-cs.1},
isbn = {21678359 (ISSN)},
journal = {PeerJ},
keywords = {Computer science,Computers,Data accessibility,Data archiving,Data citation,Data repositories,Foundational elements,Machine accessibility,Reproducibilities,Reusability,Scholarly publication,Scientific communication,behavior,human,joint,machine,organization,practice guideline,publication,reproducibility,scientist,staff,validation process},
language = {English},
number = {1},
publisher = {PeerJ Inc.},
title = {{Achieving human and machine accessibility of cited data in scholarly publications}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85019316984{\&}doi=10.7717{\%}2Fpeerj-cs.1{\&}partnerID=40{\&}md5=c552597b5adcaa1d314ba52419ffcee1 https://peerj.com/articles/cs-1.pdf},
volume = {2015},
year = {2015}
}
@unpublished{Witzel,
address = {Giessen, Germany},
author = {Witzel, Christoph and Gegenfurtner, Karl},
publisher = {Department of Psychology, Giessen University},
title = {{Chromatic Contrast Sensitivity}}
}
@article{Goodman2014,
annote = {Cited By :63
Export Date: 9 August 2019
Correspondence Address: Pepe, A.; Harvard University, Cambridge, MA, United States; email: alberto.pepe@gmail.com},
author = {Goodman, A and Pepe, A and Blocker, A W and Borgman, C L and Cranmer, K and Crosas, M and {Di Stefano}, R and Gil, Y and Groth, P and Hedstrom, M and Hogg, D W and Kashyap, V and Mahabal, A and Siemiginowska, A and Slavkovic, A},
doi = {10.1371/journal.pcbi.1003542},
isbn = {1553734X (ISSN)},
journal = {PLOS Computational Biology},
keywords = {Data Interpretation, Statistical,Guidelines as Topic,article,computer program,data analysis,data processing,data synthesis,fee,information processing,information retrieval,information system,licensing,love,online monitoring,online system,practice guideline,privacy,publication,publishing,resource allocation,reward,scientific literature,scientist,statistical analysis,workflow},
language = {English},
number = {4},
publisher = {Public Library of Science},
title = {{Ten Simple Rules for the Care and Feeding of Scientific Data}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84901373612{\&}doi=10.1371{\%}2Fjournal.pcbi.1003542{\&}partnerID=40{\&}md5=c20f3c6b37d9f991ad417ad8761da47c https://journals.plos.org/ploscompbiol/article/file?id=10.1371/journal.pcbi.1003542{\&}type=printable},
volume = {10},
year = {2014}
}
@article{Tversky1974,
author = {Tversky, A and Kahneman, D},
doi = {10.1126/science.185.4157.1124},
isbn = {0036-8075},
journal = {Science},
number = {4157},
pages = {1124--1131},
publisher = {American Association for the Advancement of Science (AAAS)},
title = {{Judgment under Uncertainty: Heuristics and Biases}},
url = {https://dx.doi.org/10.1126/science.185.4157.1124},
volume = {185},
year = {1974}
}
@article{Liu2002,
abstract = {We suggest a spectral histogram, defined as the marginal distribution of filter responses, as a quantitative definition for a texton pattern. By matching spectral histograms, an arbitrary image can be transformed to an image with similar textons to the observed. We use the $\chi$2-statistic to measure the difference between two spectral histograms, which leads to a texture discrimination model. The performance of the model well matches psychophysical results on a systematic set of texture discrimination data and it exhibits the nonlinearity and asymmetry phenomena in human texture discrimination. A quantitative comparison with the Malik–Perona model is given, and a number of issues regarding the model are discussed.},
author = {Liu, Xiuwen and Wang, DeLiang},
doi = {https://doi.org/10.1016/S0042-6989(02)00297-3},
isbn = {0042-6989},
journal = {Vision Research},
keywords = {Texton modeling,Texture Synthesis,Texture discrimination,Texture perception},
number = {23},
pages = {2617--2634},
title = {{A spectral histogram model for texton modeling and texture discrimination}},
url = {http://www.sciencedirect.com/science/article/pii/S0042698902002973},
volume = {42},
year = {2002}
}
@article{Kahneman1992,
abstract = {Seven experiments (N = 205) explored a form of object-specific priming. A preview field containing 2 or more letters was followed by a target letter to be named. Displays were designed to produce perceptual interpretation of the target as a new state of an object that previously contained one of the primes. The link was produced by a shared location, a shared relative position in a moving pattern, or successive appearance in the same moving frame. An object-specific advantage was consistently observed: naming was facilitated by a preview of the target if the 2 appearances were linked to the same object. Amount and object specificity of the preview benefit were not affected by extending preview duration to 1 sec or by extending the temporal gap between fields to 590 msec. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
address = {Netherlands},
annote = {Kahneman, D
Treisman, A
Gibbs, B J
eng
Research Support, Non-U.S. Gov't
Research Support, U.S. Gov't, Non-P.H.S.
Netherlands
Cogn Psychol. 1992 Apr;24(2):175-219.},
author = {Kahneman, Daniel and Treisman, Anne and Gibbs, Brian J},
doi = {10.1016/0010-0285(92)90007-O},
edition = {1992/04/01},
isbn = {0010-0285(Print)},
journal = {Cognitive Psychology},
keywords = {*Cognitive Processes,*Priming,Naming,Stimulus Parameters},
number = {2},
pages = {175--219},
pmid = {1582172},
publisher = {Elsevier Science},
title = {{The reviewing of object files: Object-specific integration of information}},
url = {https://ac.els-cdn.com/001002859290007O/1-s2.0-001002859290007O-main.pdf?{\_}tid=faf3630a-02c8-4585-90c2-acd390bd1f9a{\&}acdnat=1544450444{\_}eaa9131ea68c612d79373a840be44c90},
volume = {24},
year = {1992}
}
@article{Krumholz2014,
abstract = {Big data in medicine-massive quantities of health care data accumulating from patients and populations and the advanced analytics that can give those data meaning-hold the prospect of becoming an engine for the knowledge generation that is necessary to address the extensive unmet information needs of patients, clinicians, administrators, researchers, and health policy makers. This article explores the ways in which big data can be harnessed to advance prediction, performance, discovery, and comparative effectiveness research to address the complexity of patients, populations, and organizations. Incorporating big data and next-generation analytics into clinical and population health research and practice will require not only new data sources but also new thinking, training, and tools. Adequately utilized, these reservoirs of data can be a practically inexhaustible source of knowledge to fuel a learning health care system. {\textcopyright} 2014 by Project HOPE - The People-to-People Health Foundation.},
annote = {Cited By :92 Export Date: 14 March 2018},
author = {Krumholz, H M},
doi = {10.1377/hlthaff.2014.0053},
edition = {2014/07/10},
isbn = {1544-5208 (Electronic)0278-2715 (Linking)},
journal = {Health Affairs},
keywords = {Data Interpretation, Statistical,Data Mining,Datasets as Topic,Decision Support Systems, Clinical,Delivery of Health Care,Humans,Learning,Medical Informatics,Thinking,article,clinical decision support system,health care delivery,health care system,human,information processing,information storage,machine learning,medical research,organization and management,procedures,statistical analysis,training},
number = {7},
pages = {1163--1170},
pmid = {25006142},
title = {{Big data and new knowledge in medicine: The thinking , training , and tools needed for a learning health system}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905965765{\&}doi=10.1377{\%}2Fhlthaff.2014.0053{\&}partnerID=40{\&}md5=2e6640077d751e306c465469217d9450 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5459394/pdf/nihms855266.pdf},
volume = {33},
year = {2014}
}
@article{Nitecki2019,
abstract = {Research depends on prior results. The cycle of transforming research output to disseminated knowledge is changing to engage more researchers to openly discover and thereby shape future contributions to scholarship. No established framework helps librarians understand the opportunities that transition offers librarians. However, through four propositions, this paper addresses some of the changes facing academic librarians as they expand their roles: 1) Research cycles embrace interactive sharing and reuse of data; 2) Managing open research data expands librarians' roles; 3) Intellectual entrepreneurship roles provide a model to empower others; 4) Librarians demonstrate their entrepreneurial leadership by creating partnerships outside the library. Now academic librarians have opportunities to strengthen their role in how higher education shapes research by shifting greater focus toward research data management [RDM]. Two seasoned administrators and librarians illustrate pathways to prepare academic librarians for these new roles. They offer two practitioners' impressions of the demands and opportunities for librarians to extend their expertise to support RDM, and illustrate how academic librarians have begun doing so through professional association work (through the Association of College and Research Libraries (ACRL)) and at one academic library (at Drexel University). They urge academic librarians to step out of their comfort zones of organizing, preserving and servicing discovery of information resources and embrace emerging roles for which their values and expertise have prepared them. If librarians ignore these opportunities, they risk being bypassed in efforts to ensure that managing research data and scholarship are central to research protocols. [ABSTRACT FROM AUTHOR] Copyright of Libri: International Journal of Libraries {\&} Information Services is the property of De Gruyter and its content may not be copied or emailed to multiple sites or posted to a listserv without the copyright holder's express written permission. However, users may print, download, or email articles for individual use. This abstract may be abridged. No warranty is given about the accuracy of the copy. Users should refer to the original published version of the material for the full abstract. (Copyright applies to all Abstracts.)},
annote = {Nitecki, Danuta A. 1; Email Address: dan44@drexel.edu Davis, Mary Ellen K. 2; Email Address: mdavis@ala.org; Affiliation: 1: Libraries, Drexel University, Philadelphia, PA, USA 2: Association of College and Research Libraries, Chicago, IL, USA; Source Info: Jun2019, Vol. 69 Issue 2, p117; Subject Term: ACADEMIC libraries; Subject Term: RESEARCH; Subject Term: ACADEMIC librarians; Subject Term: EDUCATIONAL cooperation; Subject Term: LEADERSHIP; Subject Term: HIGHER education; Author-Supplied Keyword: emerging librarian roles; Author-Supplied Keyword: higher education; Author-Supplied Keyword: intellectual entrepreneurship; Author-Supplied Keyword: leadership; Author-Supplied Keyword: research data management; NAICS/Industry Codes: 519120 Libraries and Archives; Number of Pages: 9p; Illustrations: 2 Diagrams, 1 Chart; Document Type: Article; Full Text Word Count: 4543},
author = {Nitecki, Danuta A and Davis, Mary Ellen K},
doi = {10.1515/libri-2018-0066},
isbn = {00242667},
journal = {Libri: International Journal of Libraries {\&} Information Services},
keywords = {ACADEMIC librarians,ACADEMIC libraries,EDUCATIONAL cooperation,HIGHER education,LEADERSHIP,RESEARCH,emerging librarian roles,intellectual entrepreneurship,research data management},
number = {2},
pages = {117--125},
pmid = {136769716},
title = {{Expanding Academic Librarians' Roles in the Research Life Cycle}},
url = {http://proxycu.wrlc.org/login?url=http://search.ebscohost.com/login.aspx?direct=true{\&}db=a9h{\&}AN=136769716{\&}site=ehost-live},
volume = {69},
year = {2019}
}
@article{Tversky1981,
author = {Tversky, A and Kahneman, D},
doi = {10.1126/science.7455683},
isbn = {0036-8075},
journal = {Science},
number = {4481},
pages = {453--458},
publisher = {American Association for the Advancement of Science (AAAS)},
title = {{The framing of decisions and the psychology of choice}},
url = {https://dx.doi.org/10.1126/science.7455683},
volume = {211},
year = {1981}
}
@article{Brewer2006,
abstract = {Maps and other data graphics may play a role in generating ideas and hypotheses at the beginning of a project. They are useful as part of analyses for evaluating model results and then at the end of a project when researchers present their results and conclusions to varied audiences, such as their local research group, decision makers, or a concerned public. Cancer researchers are gaining skill with geographic information system (GIS) mapping as one of their many tools and are broadening the symbolization approaches they use for investigating and illustrating their data. A single map is one of many possible representations of the data, so making multiple maps is often part of a complete mapping effort. Symbol types, color choices, and data classing each affect the information revealed by a map and are best tailored to the specific characteristics of data. Related data can be examined in series with coordinated classing and can also be compared using multivariate symbols that build on the basic rules of symbol design. Informative legend wording and setting suitable map projections are also basic to skilled mapmaking.},
author = {Brewer, Cynthia A},
doi = {http://dx.doi.org/10.1016/j.amepre.2005.09.007},
isbn = {0749-3797},
journal = {American Journal of Preventive Medicine},
number = {2, Supplement},
pages = {S25--S36},
title = {{Basic Mapping Principles for Visualizing Cancer Data Using Geographic Information Systems (GIS)}},
url = {http://www.sciencedirect.com/science/article/pii/S0749379705003582 http://ac.els-cdn.com/S0749379705003582/1-s2.0-S0749379705003582-main.pdf?{\_}tid=92d7a810-4260-11e3-9935-00000aab0f01{\&}acdnat=1383247010{\_}3e47e7c195950c39dd569a1a9bffc018},
volume = {30},
year = {2006}
}
@article{Byron2008a,
abstract = {In February 2008, the New York Times published an unusual chart of box office revenues for 7500 movies over 21 years. The chart was based on a similar visualization, developed by the first author, that displayed trends in music listening. This paper describes the design decisions and algorithms behind these graphics, and discusses the reaction on the Web. We suggest that this type of complex layered graph is effective for displaying large data sets to a mass audience. We provide a mathematical analysis of how this layered graph relates to traditional stacked graphs and to techniques such as ThemeRiver, showing how each method is optimizing a different "energy function". Finally, we discuss techniques for coloring and ordering the layers of such graphs. Throughout the paper, we emphasize the interplay between considerations of aesthetics and legibility.},
annote = {Byron, Lee
Wattenberg, Martin
Journal Article
United States
IEEE Trans Vis Comput Graph. 2008 Nov-Dec;14(6):1245-52. doi: 10.1109/TVCG.2008.166.},
author = {Byron, L and Wattenberg, M},
doi = {10.1109/tvcg.2008.166},
edition = {2008/11/08},
isbn = {1077-2626 (Print)1077-2626},
journal = {IEEE Trans Vis Comput Graph},
language = {eng},
number = {6},
pages = {1245--1252},
pmid = {18988970},
title = {{Stacked graphs--geometry {\&} aesthetics}},
volume = {14},
year = {2008}
}
@unpublished{Stone2006a,
address = {Baltimore, MD},
author = {Stone, Maureen},
publisher = {IEEE Visualization: VIS2006},
title = {{Color in Information Display: Part 2}},
url = {http://www.stonesc.com/Vis06/},
year = {2006}
}
@article{Thieme2018,
abstract = {The story of a statistical programming language that became a subcultural phenomenon. By Nick Thieme},
author = {Thieme, Nick},
doi = {10.1111/j.1740-9713.2018.01169.x},
isbn = {1740-9705},
journal = {Significance},
number = {4},
pages = {14--19},
publisher = {Wiley/Blackwell (10.1111)},
title = {{R generation}},
url = {https://doi.org/10.1111/j.1740-9713.2018.01169.x https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/j.1740-9713.2018.01169.x},
volume = {15},
year = {2018}
}
@book{Huston2009,
abstract = {Everyone in academia knows it and no one likes to admit it: faculty often have to teach courses in areas they don't know very well. The challenges are even greater when students don't share your cultural background, lifestyle, or assumptions about how to behave in a classroom. In this practical and funny book, an experienced teaching consultant offers many creative strategies for dealing with typical problems. --from publisher description},
address = {Cambridge, Mass.},
annote = {2009016140
GBA970420
Therese Huston.
22 cm.
Includes bibliographical references (p. [273]-302) and index.
The growing challenge -- Why it's better than it seems -- Getting ready -- Teaching and surviving -- Thinking in class -- Teaching students you don't understand -- Getting better -- Advice for administrators.},
author = {Huston, Therese},
isbn = {9780674035805 (alk. paper)},
keywords = {College teaching.,Effective teaching.,Learning.},
pages = {314 p.},
pmid = {15702624},
publisher = {Harvard University Press},
title = {{Teaching what you don't know}},
year = {2009}
}
@article{DeHouwer2019,
abstract = {It is generally assumed that relational knowledge is the foundation of higher cognition such as (analogical and conditional) reasoning, language, the use of relational categories, and planning. Dual-system models (e.g., Kahneman, 2011) that divide the realm of cognition into two systems with opposing properties (e.g., fast vs. slow, intentional vs. unintentional, conscious vs. unconscious, associative vs. propositional) foster the view that other psychological phenomena are not relational in nature. In this paper, I argue that the impact of relational knowledge is more widespread than dual-system models imply. More specifically, I review evidence suggesting that also Pavlovian conditioning, implicit evaluation, and habitual responding are mediated by relational knowledge. Considering the idea that relational knowledge underlies also fast, unintentional, unconscious, and seemingly associative psychological phenomena is not only theoretically important but also reveals new opportunities for influencing thinking and behavior.},
annote = {De Houwer, Jan
eng
Germany
Exp Psychol. 2019 Jul;66(4):257-265. doi: 10.1027/1618-3169/a000450.},
author = {{De Houwer}, J},
doi = {10.1027/1618-3169/a000450},
edition = {2019/09/19},
isbn = {2190-5142 (Electronic)1618-3169 (Linking)},
journal = {Exp Psychol},
keywords = {Pavlovian conditioning,cognition,dual-system models,habits,implicit evaluation,relational knowledge},
number = {4},
pages = {257--265},
pmid = {31530250},
title = {{Moving Beyond System 1 and System 2}},
url = {https://www.ncbi.nlm.nih.gov/pubmed/31530250},
volume = {66},
year = {2019}
}
@incollection{Williams2001,
author = {Williams, Mark S},
booktitle = {Neuroscience},
edition = {2nd},
editor = {Purves, D and Augustine, G J and Fitzpatrick, D and Katz, Lawrence C and LaMantia, Anthony-Samuel and McNamara, James O and Williams, Mark S},
publisher = {Sinauer Associates},
title = {{Cones and Color Vision}},
url = {https://www.ncbi.nlm.nih.gov/books/NBK11059/},
year = {2001}
}
@book{Robbins2013,
annote = {2004049163
GBA479978
Naomi B. Robbins.
illustrations ; 23 cm
Includes bibliographical references (pages 389-394) and index.
1. Introduction -- What we mean by an effective group -- General comments -- Captions -- The data we plot -- 2. Limitations of Some Common Charts and Graphs -- Pie charts -- Charts with a three-dimensional effect -- Bar charts: stacked and grouped -- Difference between curves -- Bubble plots -- 3. Human Perception and Our Abiblity to Decode Graphs -- Elementary graphical perception tasks -- Ordered elementary tasks -- Role of distance and detection -- 4. Some More Effective Graphs in One or Two Dimensions -- Distribution of one variable -- Strip plots -- Dot plots -- Histograms -- Jittering -- Comparing distributions: box plots -- Relationship of two variables: scatterplots -- Time series -- Line graphs -- Comments -- 5. Trellis Graphics and Other Ways to Display More Than Two Variables -- Alternative presentations of three variables -- Stacked bar chart -- Labeled scatterplot -- Trellis display -- More than three variables -- Superposed data sets -- Trellis multipanel displays -- Scatterplot matrices -- Mosaic plots -- Linked micromaps -- Parallel coordinate plots -- Nightingale rose -- Financial plot -- Comments -- 6. General Principles For Creating Effective Graphs -- Terminology -- Visual clarity -- Clarity of data -- Clarity of other elements -- Clear understanding -- General strategy -- 7. Scales -- Aspect ratio: Banking to 45° -- Scales: must zero be included? -- When to use logarithmic scales -- Scale breaks -- Using two Y scales -- Data hidden in the scales -- Other principles involving scales -- 8. Applying What We've Learned: Before and After Examples -- Grouped bar chart -- Ten small graphs -- Radar chart -- Multiple pie charts -- Tables -- 9. Some Comments On Software -- Statistical software: S Language -- Drawing programs: Illustrator -- Spreadsheets: Excel -- Moving an Axis in Excel -- Line charts with uneven time intervals -- Dot charts from Excel -- Data labels with Excel -- 10. Questions and Answers -- 1.) When should I use a table, and when should I use a graph? -- 2.) Should I use different graphs for presentations and for written reports? -- 3.) How do graphs for data analysis and graphs for communication differ? -- 4.) What should I use instead of pie charts? -- 5.) What if I just want an impression of the direction of the data? Then may I use three-dimensional charts? -- 6.) I use three-dimensional charts but I include data labels. That's OK, isn't it? -- 7.) I want my graphs to attract the reader's attention. How should I decorate them? -- 8.) Why do you think we see so many bad graphs? -- 9.) When should I use each type of graph? -- Appendix A: Checklist of possible graph defects -- Appendix B: List of figures with sources.
Purchased with funds from the Class of 1985 ; 20045.},
author = {Robbins, Naomi B},
edition = {2nd},
isbn = {978-0985911126},
keywords = {Statistics Graphic methods.},
pages = {xviii, 402 pages},
publisher = {Chart House},
title = {{Creating more effective graphs}},
year = {2013}
}
@article{SappNelson2017,
author = {{Sapp Nelson}, Megan},
doi = {10.7191/jeslib.2017.1096},
isbn = {21613974},
journal = {Journal of eScience Librarianship},
pages = {e1096},
title = {{A Pilot Competency Matrix for Data Management Skills: A Step toward the Development of Systematic Data Information Literacy Programs}},
year = {2017}
}
@article{Hunt2015,
abstract = {ABSTRACT Collection, processing, and long-term storage of data for broad-scale, collaborative natural resource monitoring and management projects poses technical and administrative challenges that, if not properly addressed, result in suboptimal management and learning. Data from many cooperators, often spanning multiple organizations, must be efficiently centralized and processed, and must be consistent in content and quality over the lifespan of such projects. We present a data management system for natural resource monitoring and management consisting of 2 components: a centralized, web-based platform for data entry and a connected relational database for data processing, modeling, and analysis. After the data management system has been customized to meet the needs of a specific project, operation and system maintenance require minimal external technical support, making it suitable for long-term projects that face potential staffing and budgeting constraints. We discuss the scope of projects for which this approach is applicable and document 2 U.S. Fish and Wildlife Service adaptive management case studies demonstrating this data management system: 1) Native Prairie Adaptive Management, and 2) Wetland Restoration and Sediment Removal. The standardized approach presented within is broadly applicable in collaborative natural resource monitoring and management settings and has the potential to improve management outcomes and facilitate deeper ecological understanding of systems being managed. ? 2015 The Wildlife Society.},
author = {Hunt, Victoria M and Jacobi, Sarah K and Knutson, Melinda G and Lonsdorf, Eric V and Papon, Shawn and Zorn, Jennifer},
doi = {10.1002/wsb.547},
isbn = {1938-5463},
journal = {Wildlife Society Bulletin},
keywords = {United States Fish and Wildlife Service,adaptive management,data collection,data quality,database,distributed decision-making,monitoring},
number = {3},
pages = {464--471},
publisher = {John Wiley {\&} Sons, Ltd},
title = {{A data management system for long-term natural resource monitoring and management projects with multiple cooperators}},
url = {https://doi.org/10.1002/wsb.547 https://wildlife.onlinelibrary.wiley.com/doi/pdf/10.1002/wsb.547},
volume = {39},
year = {2015}
}
@article{Lam2018,
abstract = {Visualization researchers and practitioners engaged in generating or evaluating designs are faced with the difficult problem of transforming the questions asked and actions taken by target users from domain-specific language and context into more abstract forms. Existing abstract task classifications aim to provide support for this endeavour by providing a carefully delineated suite of actions. Our experience is that this bottom-up approach is part of the challenge: low-level actions are difficult to interpret without a higher-level context of analysis goals and the analysis process. To bridge this gap, we propose a framework based on analysis reports derived from open-coding 20 design study papers published at IEEE InfoVis 2009-2015, to build on the previous work of abstractions that collectively encompass a broad variety of domains. The framework is organized in two axes illustrated by nine analysis goals. It helps situate the analysis goals by placing each goal under axes of specificity (Explore, Describe, Explain, Confirm) and number of data populations (Single, Multiple). The single-population types are Discover Observation, Describe Observation, Identify Main Cause, and Collect Evidence. The multiple-population types are Compare Entities, Explain Differences, and Evaluate Hypothesis. Each analysis goal is scoped by an input and an output and is characterized by analysis steps reported in the design study papers. We provide examples of how we and others have used the framework in a top-down approach to abstracting domain problems: visualization designers or researchers first identify the analysis goals of each unit of analysis in an analysis stream, and then encode the individual steps using existing task classifications with the context of the goal, the level of specificity, and the number of populations involved in the analysis. {\textcopyright} 1995-2012 IEEE.},
annote = {Cited By :2
Export Date: 2 January 2019},
author = {Lam, H and Tory, M and Munzner, T},
doi = {10.1109/TVCG.2017.2744319},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Analysis Goals,Data Analysis,Design Studies,Framework,Open Coding,Task Classifications},
number = {1},
pages = {435--445},
title = {{Bridging from Goals to Tasks with Design Study Analysis Reports}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85029155543{\&}doi=10.1109{\%}2FTVCG.2017.2744319{\&}partnerID=40{\&}md5=6f14298556481e63506d9a8c459f90e0 https://www.computer.org/csdl/trans/tg/2018/01/08023762.pdf},
volume = {24},
year = {2018}
}
@misc{SoftwareCarpentryFoundation2018,
author = {{Software Carpentry Foundation}},
shorttitle = {R for Reproducible Scientific Analysis},
title = {{R for Reproducible Scientific Analysis}},
url = {http://swcarpentry.github.io/r-novice-gapminder/},
year = {2018}
}
@article{Fecher2015,
abstract = {Despite widespread support from policy makers, funding agencies, and scientific journals, academic researchers rarely make their research data available to others. At the same time, data sharing in research is attributed a vast potential for scientific progress. It allows the reproducibility of study results and the reuse of old data for new research questions. Based on a systematic review of 98 scholarly papers and an empirical survey among 603 secondary data users, we develop a conceptual framework that explains the process of data sharing from the primary researcher's point of view. We show that this process can be divided into six descriptive categories: Data donor, research organization, research community, norms, data infrastructure, and data recipients. Drawing from our findings, we discuss theoretical implications regarding knowledge creation and dissemination as well as research policy measures to foster academic collaboration. We conclude that research data cannot be regarded as knowledge commons, but research policies that better incentivise data sharing are needed to improve the quality of research results and foster scientific progress.},
annote = {Fecher, Benedikt
Friesike, Sascha
Hebing, Marcel
eng
Research Support, Non-U.S. Gov't
PLoS One. 2015 Feb 25;10(2):e0118053. doi: 10.1371/journal.pone.0118053. eCollection 2015.},
author = {Fecher, B and Friesike, S and Hebing, M},
doi = {10.1371/journal.pone.0118053},
edition = {2015/02/26},
isbn = {1932-6203 (Electronic)1932-6203 (Linking)},
journal = {PLoS ONE},
keywords = {*Academies and Institutes,*Information Dissemination/ethics/legislation {\&} ju,*Research,Humans,Research Personnel,Surveys and Questionnaires},
number = {2},
pages = {e0118053},
pmid = {25714752},
title = {{What drives academic data sharing?}},
url = {https://www.ncbi.nlm.nih.gov/pubmed/25714752},
volume = {10},
year = {2015}
}
@incollection{Krauskopf1998,
author = {Krauskopf, John},
booktitle = {AZimuth},
doi = {https://doi.org/10.1016/S1387-6783(98)80006-8},
editor = {Nassau, Kurt},
isbn = {1387-6783},
pages = {97--121},
publisher = {North-Holland},
title = {{chapter 3 - Color Vision}},
url = {http://www.sciencedirect.com/science/article/pii/S1387678398800068},
volume = {1},
year = {1998}
}
@article{Liu2014,
author = {Liu, Shixia and Cui, Weiwei and Wu, Yingcai and Liu, Mengchen},
chapter = {1373},
doi = {10.1007/s00371-013-0892-3},
isbn = {0178-27891432-2315},
journal = {The Visual Computer},
number = {12},
pages = {1373--1393},
title = {{A survey on information visualization: recent advances and challenges}},
volume = {30},
year = {2014}
}
@article{Yi2007,
abstract = {Even though interaction is an important part of information visualization (Infovis), it has garnered a relatively low level of attention from the Infovis community. A few frameworks and taxonomies of Infovis interaction techniques exist, but they typically focus on low-level operations and do not address the variety of benefits interaction provides. After conducting an extensive review of Infovis systems and their interactive capabilities, we propose seven general categories of interaction techniques widely used in Infovis: 1) Select, 2) Explore, 3) Reconfigure, 4) Encode, 5) Abstract/Elaborate, 6) Filter, and 7) Connect. These categories are organized around a user's intent while interacting with a system rather than the low-level interaction techniques provided by a system. The categories can act as a framework to help discuss and evaluate interaction techniques and hopefully lay an initial foundation toward a deeper understanding and a science of interaction. {\textcopyright} 2007 IEEE.},
annote = {Cited By :386
Export Date: 3 February 2019},
author = {Yi, J S and Kang, Y A and Stasko, J T and Jacko, J A},
doi = {10.1109/TVCG.2007.70515},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Information visualization,Interaction,Interaction techniques,Taxonomy,Visual analytics},
number = {6},
pages = {1224--1231},
title = {{Toward a deeper understanding of the role of interaction in information visualization}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-35949002427{\&}doi=10.1109{\%}2FTVCG.2007.70515{\&}partnerID=40{\&}md5=809452e3ab5b6983b2587cb8775af891},
volume = {13},
year = {2007}
}
@inproceedings{Kery2018,
abstract = {Literate programming tools are used by millions of programmers today, and are intended to facilitate presenting data analyses in the form of a narrative. We interviewed 21 data scientists to study coding behaviors in a literate programming environment and how data scientists kept track of variants they explored. For participants who tried to keep a detailed history of their experimentation, both informal and formal versioning attempts led to problems, such as reduced notebook readability. During iteration, participants actively curated their notebooks into narratives, although primarily through cell structure rather than markdown explanations. Next, we surveyed 45 data scientists and asked them to envision how they might use their past history in a future version control system. Based on these results, we give design guidance for future literate programming tools, such as providing history search based on how programmers recall their explorations, through contextual details including images and parameters. {\textcopyright} 2018 Association for Computing Machinery.},
annote = {Export Date: 20 July 2018},
author = {Kery, M B and Radensky, M and Arya, M and John, B E and Myers, B A},
doi = {10.1145/3173574.3173748},
isbn = {9781450356206 (ISBN); 9781450356213 (ISBN)},
keywords = {Cell structure,Computer aided software engineering,Computer programming,Data science,Design guidance,End-user programmers (EUP), end-user software engi,End-user software engineering,Exploratory programming,Human computer interaction,Human engineering,Literate programming,Search-based,Version control system,Versioning},
language = {English},
publisher = {Association for Computing Machinery},
title = {{The story in the notebook: Exploratory data science using a literate programming tool}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046962150{\&}doi=10.1145{\%}2F3173574.3173748{\&}partnerID=40{\&}md5=2fa17150fab95f19acfe32efe5415264 https://dl.acm.org/citation.cfm?doid=3173574.3173748},
volume = {2018-April},
year = {2018}
}
@inproceedings{Lacher2018,
abstract = {In an effort to improve student performance in a flipped classroom environment, this paper explores the impact of including auto-graded coding questions in gate check quizzes associated with videos for a flipped CS1 course. Previous work showed that having students complete multiple choice questions that were intended to verify that they had done the preparation work did not have a statistically significant impact on outcomes as measured through written quizzes and exams. In an attempt to engage higher-level processing of learned information, this work builds on top of that by adding questions that require students to write short segments of code for most of the quizzes in addition to doing some multiple choice questions. We found that students who were given these coding video quizzes performed better on written assessments, especially for the final exam. {\textcopyright} 2018 Association for Computing Machinery.},
annote = {Export Date: 20 July 2018},
author = {Lacher, L L and Jiang, A and Zhang, Y and Lewis, M C},
doi = {10.1145/3159450.3159504},
isbn = {9781450351034 (ISBN)},
keywords = {Active learning,Assessments,Blended learning,CS1,Codes (symbols),Education computing,Flipped classroom,Flipped classrooms,Flipped learning,Inverted classroom,Mathematical programming,Novice programming,Programming,Students,Teaching,Video quizzes,Video signal processing},
language = {English},
pages = {574--579},
publisher = {Association for Computing Machinery, Inc},
title = {{Including coding qestions in video qizzes for a flipped CS1}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85046026284{\&}doi=10.1145{\%}2F3159450.3159504{\&}partnerID=40{\&}md5=6fb736a5cd4cab09f8698d8f6a817227 https://dl.acm.org/citation.cfm?doid=3159450.3159504},
volume = {2018-Janua},
year = {2018}
}
@inproceedings{Johnson1991,
abstract = {This paper describes a novel method for the visualization of hierarchically structured information. The Tree-Map visualization technique makes 100{\%} use of the available display space, mapping the full hierarchy onto a rectangular region in a space-filling manner. This efficient use of space allows very large hierarchies to be displayed in their entirety and facilitates the presentation of semantic information. {\textcopyright} 1991 IEEE.},
annote = {Cited By :690
Export Date: 17 August 2019},
author = {Johnson, B and Shneiderman, B},
editor = {Nielson, G M and Rosenblum, L},
isbn = {0818622458 (ISBN); 9780818622458 (ISBN)},
keywords = {Forestry,Hierarchical information,Large hierarchies,Rectangular regions,Semantic information,Semantics,Space filling,Structured information,Tree-maps,Visualization},
language = {English},
pages = {284--291},
publisher = {Association for Computing Machinery, Inc},
title = {{Tree-maps: A space-filling approach to the visualization of hierarchical information structures}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032279305{\&}partnerID=40{\&}md5=acf7edef25add366074801379757d410},
year = {1991}
}
@article{Feldon2017,
abstract = {Many PhD programs incorporate boot camps and summer bridge programs to accelerate the development of doctoral students' research skills and acculturation into their respective disciplines. These brief, high-intensity experiences span no more than several weeks and are typically designed to expose graduate students to data analysis techniques, to develop scientific writing skills, and to better embed incoming students into the scholarly community. However, there is no previous study that directly measures the outcomes of PhD students who participate in such programs and compares them to the outcomes of students who did not participate. Likewise, no previous study has used a longitudinal design to assess these outcomes over time. Here we show that participation in such programs is not associated with detectable benefits related to skill development, socialization into the academic community, or scholarly productivity for students in our sample. Analyzing data from 294 PhD students in the life sciences from 53 US institutions, we found no statistically significant differences in outcomes between participants and nonparticipants across 115 variables. These results stand in contrast to prior studies presenting boot camps as effective interventions based on participant satisfaction and perceived value. Many universities and government agencies (e.g., National Institutes of Health and National Science Foundation) invest substantial resources in boot camp and summer bridge activities in the hopes of better supporting scientific workforce development. Our findings do not reveal any measurable benefits to students, indicating that an allocation of limited resources to alternative strategies with stronger empirical foundations warrants consideration.},
annote = {Feldon, David F
Jeong, Soojeong
Peugh, James
Roksa, Josipa
Maahs-Fladung, Cathy
Shenoy, Alok
Oliva, Michael
eng
Research Support, U.S. Gov't, Non-P.H.S.
Proc Natl Acad Sci U S A. 2017 Sep 12;114(37):9854-9858. doi: 10.1073/pnas.1705783114. Epub 2017 Aug 28.},
author = {Feldon, D F and Jeong, S and Peugh, J and Roksa, J and Maahs-Fladung, C and Shenoy, A and Oliva, M},
doi = {10.1073/pnas.1705783114},
edition = {2017/08/30},
isbn = {1091-6490 (Electronic)0027-8424 (Linking)},
journal = {Proc Natl Acad Sci U S A},
keywords = {*boot camp,*doctoral education,*graduate training,*research skills,Biological Science Disciplines,Clinical Competence/*statistics {\&} numerical data,Education, Medical, Graduate/*methods,Education/*methods,Female,Humans,Longitudinal Studies,Male,National Institutes of Health (U.S.),United States,Universities},
number = {37},
pages = {9854--9858},
pmid = {28847929},
title = {{Null effects of boot camps and short-format training for PhD students in life sciences}},
url = {https://www.ncbi.nlm.nih.gov/pubmed/28847929},
volume = {114},
year = {2017}
}
@article{Schnapf1987,
author = {Schnapf, J L and Kraft, T W and Baylor, D A},
doi = {10.1038/325439a0},
journal = {Nature},
pages = {439},
publisher = {Nature Publishing Group},
title = {{Spectral sensitivity of human cone photoreceptors}},
url = {http://dx.doi.org/10.1038/325439a0 https://www.nature.com/articles/325439a0.pdf},
volume = {325},
year = {1987}
}
@article{Anscombe1973,
annote = {O7552
Times Cited:442
Cited References Count:12},
author = {Anscombe, F J},
doi = {Doi 10.2307/2682899},
isbn = {0003-1305},
journal = {American Statistician},
language = {English},
number = {1},
pages = {17--21},
title = {{Graphs in Statistical Analysis}},
volume = {27},
year = {1973}
}
@article{Goodale1992,
abstract = {Accumulating neuropsychological, electrophysiological and behavioural evidence suggests that the neural substrates of visual perception may be quite distinct from those underlying the visual control of actions. In other words, the set of object descriptions that permit identification and recognition may be computed independently of the set of descriptions that allow an observer to shape the hand appropriately to pick up an object. We propose that the ventral stream of projections from the striate cortex to the inferotemporal cortex plays the major role in the perceptual identification of objects, while the dorsal stream projecting from the striate cortex to the posterior parietal region mediates the required sensorimotor transformations for visually guided actions directed at such objects. {\textcopyright} 1992.},
annote = {Cited By :3441
Export Date: 17 August 2019
CODEN: TNSCD
Correspondence Address: Goodale, M.A.; Dept of Psychology, University of Western Ontario, London, Ont. N6A 5C2, Canada},
author = {Goodale, M A and Milner, A D},
doi = {10.1016/0166-2236(92)90344-8},
isbn = {01662236 (ISSN)},
journal = {Trends in Neurosciences},
keywords = {Animal,Psychomotor Performance,Visual Pathways,Visual Perception,human,monkey,nonhuman,performance,priority journal,short survey,vision,visual system},
language = {English},
number = {1},
pages = {20--25},
title = {{Separate visual pathways for perception and action}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0026565214{\&}doi=10.1016{\%}2F0166-2236{\%}2892{\%}2990344-8{\&}partnerID=40{\&}md5=6aa6448032e6d457fa1bf5c231809e60 https://www.sciencedirect.com/science/article/abs/pii/0166223692903448?via{\%}3Dihub},
volume = {15},
year = {1992}
}
@inproceedings{Rheingans2000,
author = {Rheingans, Penny L},
booktitle = {28th AIPR Workshop: 3D Visualization for Data Exploration and Decision Making},
pages = {9},
publisher = {SPIE},
title = {{Task-based color scale design}},
volume = {3905},
year = {2000}
}
@misc{Pierce2017,
author = {Pierce, Rod},
number = {December 18},
title = {{Percentage Difference, Percentage Error, Percentage Change}},
url = {http://www.mathsisfun.com/data/percentage-difference-vs-error.html},
volume = {2018},
year = {2017}
}
@article{Elmqvist2010,
abstract = {We present a model for building, visualizing, and interacting with multiscale representations of information visualization techniques using hierarchical aggregation. The motivation for this work is to make visual representations more visually scalable and less cluttered. The model allows for augmenting existing techniques with multiscale functionality, as well as for designing new visualization and interaction techniques that conform to this new class of visual representations. We give some examples of how to use the model for standard information visualization techniques such as scatterplots, parallel coordinates, and node-link diagrams, and discuss existing techniques that are based on hierarchical aggregation. This yields a set of design guidelines for aggregated visualizations. We also present a basic vocabulary of interaction techniques suitable for navigating these multiscale visualizations.},
annote = {Elmqvist, Niklas
Fekete, Jean-Daniel
eng
Research Support, Non-U.S. Gov't
IEEE Trans Vis Comput Graph. 2010 May-Jun;16(3):439-54. doi: 10.1109/TVCG.2009.84.},
author = {Elmqvist, N and Fekete, J D},
doi = {10.1109/TVCG.2009.84},
edition = {2010/03/13},
isbn = {1077-2626 (Print)1077-2626 (Linking)},
journal = {IEEE Trans Vis Comput Graph},
keywords = {*Algorithms,*Computer Graphics,*Models, Theoretical,*Software,*Software Design,*User-Computer Interface,Image Interpretation, Computer-Assisted/methods,Information Storage and Retrieval/*methods},
number = {3},
pages = {439--454},
pmid = {20224139},
title = {{Hierarchical aggregation for information visualization: overview, techniques, and design guidelines}},
url = {https://www.ncbi.nlm.nih.gov/pubmed/20224139},
volume = {16},
year = {2010}
}
@article{Pedersen2016,
abstract = {The aim of this article is to discuss how mutually enriching points from both affordance theory and cultural-historical activity theory can promote theoretical ideas which may prove useful as analytical tools for the study of human life and human development. There are two issues that need to be overcome in order to explore the potentials of James Gibson's affordance theory: it does not sufficiently theorize (a) development and (b) society. We claim that Gibson's affordance theory still needs to be brought beyond the axiom of immediacy. Ambivalences in Gibson's affordance theory will be discussed, and we will argue for certain revisions. The strong ideas of direct perceiving and of perception-action mutuality remain intact while synthesized with ideas of societal human life. We propose the concept of the affording of societal standards to be a meaningful term in order to grasp the specific societal character of affordance theory.},
annote = {Ef0gc
Times Cited:0
Cited References Count:38},
author = {Pedersen, S and Bang, J},
doi = {10.1177/0959354316669021},
isbn = {0959-3543},
journal = {Theory {\&} Psychology},
keywords = {activity theory,affordance,ecological psychology,gibson,james j,perception,perspective,social-psychology,standards},
language = {English},
number = {6},
pages = {731--750},
title = {{Historicizing affordance theory: A rendezvous between ecological psychology and cultural-historical activity theory}},
volume = {26},
year = {2016}
}
@incollection{Munzner2015d,
address = {Boca Raton},
annote = {2014020715
Tamara Munzner, Department of Computer Science, University of British Columbia.
25 cm
"An A K Peters Book."
Includes bibliographical references (pages 373-395) and indexes.},
author = {Munzner, Tamara},
booktitle = {Visualization analysis and design},
isbn = {9781466508910 (Pack - Book and Ebook acid-free paper)},
keywords = {Information visualization.},
pages = {43--58},
pmid = {18165423},
publisher = {CRC Press, Taylor {\&} Francis Group},
title = {{Why: Task Abstraction}},
year = {2015}
}
@incollection{Friendly2008,
author = {Friendly, Michael},
booktitle = {Handbook of Computational Statistics: Data Visualization},
chapter = {11.1},
editor = {Chen, Chun-houh and Härdle, Wolfgang and Unwin, Antony},
pages = {15--},
title = {{A Brief History of Data Visualization}},
year = {2008}
}
@article{Volk2014,
abstract = {Increasingly, research and management in natural resource science rely on very large datasets compiled from multiple sources. While it is generally good to have more data, utilizing large, complex datasets has introduced challenges in data sharing, especially for collaborating researchers in disparate locations (“distributed research teams”). We surveyed natural resource scientists about common data-sharing problems. The major issues identified by our survey respondents (n = 118) when providing data were lack of clarity in the data request (including format of data requested). When receiving data, survey respondents reported various insufficiencies in documentation describing the data (e.g., no data collection description/no protocol, data aggregated, or summarized without explanation). Since metadata, or “information about the data,” is a central obstacle in efficient data handling, we suggest documenting metadata through data dictionaries, protocols, read-me files, explicit null value documentation, and process metadata as essential to any large-scale research program. We advocate for all researchers, but especially those involved in distributed teams to alleviate these problems with the use of several readily available communication strategies including the use of organizational charts to define roles, data flow diagrams to outline procedures and timelines, and data update cycles to guide data-handling expectations. In particular, we argue that distributed research teams magnify data-sharing challenges making data management training even more crucial for natural resource scientists. If natural resource scientists fail to overcome communication and metadata documentation issues, then negative data-sharing experiences will likely continue to undermine the success of many large-scale collaborative projects.},
author = {Volk, Carol J and Lucero, Yasmin and Barnas, Katie},
doi = {10.1007/s00267-014-0258-2},
isbn = {1432-1009},
journal = {Environmental Management},
number = {5},
pages = {883--893},
title = {{Why is Data Sharing in Collaborative Natural Resource Efforts so Hard and What can We Do to Improve it?}},
url = {https://doi.org/10.1007/s00267-014-0258-2 https://link.springer.com/content/pdf/10.1007{\%}2Fs00267-014-0258-2.pdf},
volume = {53},
year = {2014}
}
@article{Evener2015,
abstract = {Innovation is a much-touted concept in the business world. Libraries, too, have felt the need for continuous innovation as we serve ever-changing needs. Leaders can use principles practiced in business to transform academic libraries into cultures of innovation. In a culture of innovation, employees are engaged in their work and excited about the possibilities of it. Leaders help cultivate creativity by promoting growth mind-sets, rewarding experimentation, and practicing discovery skills. Importantly, library leaders in cultures of innovation hone persuasive abilities to create buy-in for implementing innovations in order to serve users more effectively with dynamic solutions to persistent problems.},
annote = {Sp. Iss. SI
Vc3me
Times Cited:0
Cited References Count:40},
author = {Evener, Julie},
chapter = {296},
doi = {10.1080/10691316.2015.1060142},
isbn = {1069-13161545-2530},
journal = {College {\&} Undergraduate Libraries},
keywords = {creativity,engagement,implementation,innovation,leadership},
language = {English},
number = {3-4},
pages = {296--311},
title = {{Innovation in the Library: How to Engage Employees, Cultivate Creativity, and Create Buy-In for New Ideas}},
volume = {22},
year = {2015}
}
@book{Cairo2016,
address = {Place of publication not identified},
annote = {2016304900
Alberto Cairo.
illustrations ; 23 cm
Includes bibliographical references and index.
Foundations -- Truthful -- Functional -- Practice.},
author = {Cairo, Alberto},
isbn = {97803219340790321934075},
keywords = {Charts, diagrams, etc. Design.,Computer graphics.,Computergrafik.,Datenverarbeitung.,Information visualization.,Optical images.,Visualisierung.},
pages = {xvii, 382 pages},
pmid = {19137186},
publisher = {New Riders},
title = {{The truthful art : data, charts, and maps for communication}},
year = {2016}
}
@unpublished{Munzner2016,
author = {Munzner, T},
publisher = {University of British Columbia},
title = {{Visualization Analysis {\&} Design Full-Day Tutorial}},
year = {2016}
}
@article{Sedlmair2013,
abstract = {To verify cluster separation in high-dimensional data, analysts often reduce the data with a dimension reduction (DR) technique, and then visualize it with 2D Scatterplots, interactive 3D Scatterplots, or Scatterplot Matrices (SPLOMs). With the goal of providing guidance between these visual encoding choices, we conducted an empirical data study in which two human coders manually inspected a broad set of 816 scatterplots derived from 75 datasets, 4 DR techniques, and the 3 previously mentioned scatterplot techniques. Each coder scored all color-coded classes in each scatterplot in terms of their separability from other classes. We analyze the resulting quantitative data with a heatmap approach, and qualitatively discuss interesting scatterplot examples. Our findings reveal that 2D scatterplots are often 'good enough', that is, neither SPLOM nor interactive 3D adds notably more cluster separability with the chosen DR technique. If 2D is not good enough, the most promising approach is to use an alternative DR technique in 2D. Beyond that, SPLOM occasionally adds additional value, and interactive 3D rarely helps but often hurts in terms of poorer class separation and usability. We summarize these results as a workflow model and implications for design. Our results offer guidance to analysts during the DR exploration process.},
author = {Sedlmair, M and Munzner, T and Tory, M},
doi = {10.1109/TVCG.2013.153},
isbn = {1077-2626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {2D scatterplot technique,Algorithms,Computer Graphics,Computer Simulation,DR exploration process,Dimensionality reduction,Encoding,Image Enhancement,Image Interpretation, Computer-Assisted,Imaging, Three-Dimensional,Models, Statistical,Pattern Recognition, Automated,Principal component analysis,SPLOM,Three-dimensional displays,User-Computer Interface,cluster separation,color-coded classes,data analysis,data reduction,data visualisation,data visualization,dimension reduction technique,heatmap approach,high-dimensional data,interactive 3D Scatterplots,pattern clustering,quantitative study,scatterplot matrices,scatterplots,visual encoding choices},
number = {12},
pages = {2634--2643},
title = {{Empirical Guidance on Scatterplot and Dimension Reduction Technique Choices}},
url = {https://ieeexplore.ieee.org/ielx7/2945/6634084/06634128.pdf?tp={\&}arnumber=6634128{\&}isnumber=6634084},
volume = {19},
year = {2013}
}
@incollection{Lander2017f,
author = {Lander, Jared P},
booktitle = {R for Everyone},
edition = {2nd},
title = {{Advanced Data Structures}},
year = {2017}
}
@unpublished{NationalInstitutesofHealth2018,
author = {{National Institutes of Health}},
publisher = {National Institutes of Health},
title = {{NIH Strategic Plan for Data Science}},
url = {https://datascience.nih.gov/sites/default/files/NIH{\_}Strategic{\_}Plan{\_}for{\_}Data{\_}Science{\_}Final{\_}508.pdf},
year = {2018}
}
@misc{Herr2018,
author = {Herr, Josh and Tang, Ming and Psomopoulos, Fotis and Sharan, Malvika},
title = {{Data Carpentry: Genomics Workshop - Data wrangling and processing}},
url = {https://datacarpentry.org/wrangling-genomics/},
year = {2018}
}
@article{Meyer2015,
abstract = {We propose the nested blocks and guidelines model for the design and validation of visualization systems. The nested blocks and guidelines model extends the previously proposed four-level nested model by adding finer grained structure within each level, providing explicit mechanisms to capture and discuss design decision rationale. Blocks are the outcomes of the design process at a specific level, and guidelines discuss relationships between these blocks. Blocks at the algorithm and technique levels describe design choices, as do data blocks at the abstraction level, whereas task abstraction blocks and domain situation blocks are identified as the outcome of the designer's understanding of the requirements. In the nested blocks and guidelines model, there are two types of guidelines: within-level guidelines provide comparisons for blocks within the same level, while between-level guidelines provide mappings between adjacent levels of design. We analyze several recent articles using the nested blocks and guidelines model to provide concrete examples of how a researcher can use blocks and guidelines to describe and evaluate visualization research. We also discuss the nested blocks and guidelines model with respect to other design models to clarify its role in visualization design. Using the nested blocks and guidelines model, we pinpoint two implications for visualization evaluation. First, comparison of blocks at the domain level must occur implicitly downstream at the abstraction level; second, comparison between blocks must take into account both upstream assumptions and downstream requirements. Finally, we use the model to analyze two open problems: the need for mid-level task taxonomies to fill in the task blocks at the abstraction level and the need for more guidelines mapping between the algorithm and technique levels. {\textcopyright} The Author(s) 2013.},
annote = {Cited By :15
Export Date: 2 January 2019},
author = {Meyer, M and Sedlmair, M and Quinan, P S and Munzner, T},
doi = {10.1177/1473871613510429},
journal = {Information Visualization},
keywords = {Design studies,Nested model,Validation,Visualization},
number = {3},
pages = {234--249},
title = {{The nested blocks and guidelines model}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84943241635{\&}doi=10.1177{\%}2F1473871613510429{\&}partnerID=40{\&}md5=a09e7095129cd6a5bb9e5ff58c7ef350},
volume = {14},
year = {2015}
}
@inproceedings{Healey1996,
abstract = {We describe a technique for choosing multiple colours for use during data visualization. Our goal is a systematic method for maximizing the total number of colours available for use, while still allowing an observer to rapidly and accurately search a display for any one of the given colours. Previous research suggests that we need to consider three separate effects during colour selection: colour distance, linear separation, and colour category. We describe a simple method for measuring and controlling all of these effects. Our method was tested by performing a set of target identification studies; we analysed the ability of thirty eight observers to find a colour target in displays that contained differently coloured background elements. Results showed our method can be used to select a group of colours that will provide good differentiation between data elements during data visualization.},
author = {Healey, C G},
booktitle = {Proceedings of Seventh Annual IEEE Visualization '96},
doi = {10.1109/VISUAL.1996.568118},
keywords = {Computer displays,Computer graphics,Computer science,Guidelines,Military computing,Performance analysis,Performance evaluation,Testing,background elements,colour category,colour distance,colour selection,colour target,data visualisation,data visualization,ergonomics,identification studies,linear separation,screen design,systematic method},
pages = {263--270},
title = {{Choosing effective colours for data visualization}},
year = {1996}
}
@techreport{Wickham2011,
author = {Wickham, Hadley and Stryjewski, Lisa},
title = {40 years of boxplots},
url = {https://vita.had.co.nz/papers/boxplots.html},
year = {2011}
}
@article{Gregory1977,
abstract = {An optical technique is described for projecting two colour pictures with controlled brightness contrast, which may be set to zero - at isoluminance. Color registration is maintained without adjustment or special setting up. It is suggested that color and brightness contour registration in the visual channel is a problem which may be solved neurally by master brightness signals locking slave color signals. The projection apparatus allows the supposed master brightness signals to be removed - at isoluminance - when contour disturbances should occur. Observations of this kind are reported.},
annote = {Cited By :142
Export Date: 14 January 2019},
author = {Gregory, R L},
doi = {10.1068/p060113},
journal = {Perception},
number = {1},
pages = {113--119},
title = {{Vision with isoluminant colour contrast: 1. A projection technique and observations}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-0017350016{\&}doi=10.1068{\%}2Fp060113{\&}partnerID=40{\&}md5=2048644f1a254eed55529fa72c0ab04c},
volume = {6},
year = {1977}
}
@article{Aleven2016,
abstract = {In 2009, we reported on a new Intelligent Tutoring Systems (ITS) technology, example-tracing tutors, that can be built without programming using the Cognitive Tutor Authoring Tools (CTAT). Creating example-tracing tutors was shown to be 4-8 times as cost-effective as estimates for ITS development from the literature. Since 2009, CTAT and its associated learning management system, the Tutorshop, have been extended and have been used for both research and real-world instruction. As evidence that example-tracing tutors are an effective and mature ITS paradigm, CTAT-built tutors have been used by approximately 44,000 students and account for 40 {\%} of the data sets in DataShop, a large open repository for educational technology data sets. We review 18 example-tracing tutors built since 2009, which have been shown to be effective in helping students learn in real educational settings, often with large pre/post effect sizes. These tutors support a variety of pedagogical approaches, beyond step-based problem solving, including collaborative learning, educational games, and guided invention activities. CTAT and other ITS authoring tools illustrate that non-programmer approaches to building ITS are viable and useful and will likely play a key role in making ITS widespread. {\textcopyright} 2016 International Artificial Intelligence in Education Society.},
annote = {Cited By :18
Export Date: 20 July 2018
Correspondence Address: Aleven, V.; Human-Computer Interaction Institute, Carnegie Mellon University, 5000 Forbes Ave, United States; email: aleven@cs.cmu.edu},
author = {Aleven, V and McLaren, B M and Sewall, J and {Van Velsen}, M and Popescu, O and Demi, S and Ringenberg, M and Koedinger, K R},
doi = {10.1007/s40593-015-0088-2},
isbn = {15604292 (ISSN)},
journal = {International Journal of Artificial Intelligence in Education},
keywords = {Authoring tool,Authoring tools,Cognitive systems,Collaborative learning,Computer aided instruction,Cost effectiveness,Education,Educational settings,Example-tracing tutors,Intelligent tutoring system,Intelligent tutoring systems,Intelligent tutors,Intelligent vehicle highway systems,Learning management system,Pedagogical approach,Problem solving,Students,Teaching},
language = {English},
number = {1},
pages = {224--269},
publisher = {Springer New York LLC},
title = {{Example-Tracing Tutors: Intelligent Tutor Development for Non-programmers}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84958976144{\&}doi=10.1007{\%}2Fs40593-015-0088-2{\&}partnerID=40{\&}md5=657236cf81dba7276b9a83bf9c23309e https://link.springer.com/content/pdf/10.1007{\%}2Fs40593-015-0088-2.pdf},
volume = {26},
year = {2016}
}
@article{Chavan2011,
abstract = {Free and open access to primary biodiversity data is essential for informed decision-making to achieve conservation of biodiversity and sustainable development. However, primary biodiversity data are neither easily accessible nor discoverable. Among several impediments, one is a lack of incentives to data publishers for publishing of their data resources. One such mechanism currently lacking is recognition through conventional scholarly publication of enriched metadata, which should ensure rapid discovery of 'fit-for-use' biodiversity data resources.},
author = {Chavan, Vishwas and Penev, Lyubomir},
doi = {10.1186/1471-2105-12-S15-S2},
isbn = {1471-2105},
journal = {BMC bioinformatics},
number = {15},
pages = {S2},
title = {{The data paper: a mechanism to incentivize data publishing in biodiversity science}},
url = {https://doi.org/10.1186/1471-2105-12-S15-S2},
volume = {12},
year = {2011}
}
@article{Read2019,
abstract = {Background: Librarians and researchers alike have long identified research data management (RDM) training as a need in biomedical research. Despite the wealth of libraries offering RDM education to their communities, clinical research is an area that has not been targeted. Clinical RDM (CRDM) is seen by its community as an essential part of the research process where established guidelines exist, yet educational initiatives in this area are unknown. Case Presentation: Leveraging my academic library's experience supporting CRDM through informationist grants and REDCap training in our medical center, I developed a 1.5 hour CRDM workshop. This workshop was designed to use established CRDM guidelines in clinical research and address common questions asked by our community through the library's existing data support program. The workshop was offered to the entire medical center 4 times between November 2017 and July 2018. This case study describes the development, implementation, and evaluation of this workshop. Conclusions: The 4 workshops were well attended and well received by the medical center community, with 99{\%} stating that they would recommend the class to others and 98{\%} stating that they would use what they learned in their work. Attendees also articulated how they would implement the main competencies they learned from the workshop into their work. For the library, the effort to support CRDM has led to the coordination of a larger institutional collaborative training series to educate researchers on best practices with data, as well as the formation of institution-wide policy groups to address researcher challenges with CRDM, data transfer, and data sharing. {\textcopyright} 2019, Medical Library Association. All rights reserved.},
annote = {Export Date: 15 July 2019
CODEN: JMLAC
Correspondence Address: Read, K.B.; NYU Health Sciences Library, New York University School of Medicine, 577 First Avenue, United States; email: kevin.read@nyumc.org},
author = {Read, K B},
doi = {10.5195/jmla.2019.580},
isbn = {15365050 (ISSN)},
journal = {Journal of the Medical Library Association},
keywords = {Academic Medical Centers,Biomedical Research,Humans,Libraries, Medical,New York,Research Personnel,adult,article,case report,clinical article,clinical research,coordination,data analysis,education,female,human,human experiment,librarian,library,male,medical research,middle aged,organization and management,personnel,practice guideline,procedures,scientist,university hospital,young adult},
language = {English},
number = {1},
pages = {89--97},
publisher = {Medical Library Association},
title = {{Adapting data management education to support clinical research projects in an academic medical center}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85059286285{\&}doi=10.5195{\%}2Fjmla.2019.580{\&}partnerID=40{\&}md5=a0bd27490103cff2bdbdfd892a492bfd https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6300223/pdf/jmla-107-89.pdf},
volume = {107},
year = {2019}
}
@misc{Yau2019,
author = {Yau, Nathan},
number = {March 1},
title = {{Stolen Charts, Reusing Visualization Methods, and the Difference}},
url = {https://flowingdata.com/2019/02/07/process-27/},
volume = {2019},
year = {2019}
}
@book{Evergreen2017a,
address = {Thousand Oaks},
annote = {2017001369
Stephanie D. H. Evergreen.
Revised edition of the author's
Includes index.
About the author -- Acknowledgments -- Preface to the second edition -- The justification for presenting data effectively -- Graphics -- Text -- Color -- Arrangement -- A short last word on presenting data effectively -- Appendix A Research and evaluation report layout checklist -- Appendix B Data visualization checklist -- Index.},
author = {Evergreen, Stephanie D H},
edition = {Second Edi},
isbn = {9781506353128 (pbk. alk. paper)},
keywords = {Graphic design (Typography),Information visualization.,Presentation graphics software.,Visual communication.},
pages = {pages cm},
pmid = {19451038},
publisher = {SAGE Publications, Inc.},
title = {{Presenting data effectively : communicating your findings for maximum impact}},
year = {2017}
}
@article{Simons2005,
abstract = {People often fail to notice large changes to visual scenes, a phenomenon now known as change blindness. The extent of change blindness in visual perception suggests limits on our capacity to encode, retain, and compare visual information from one glance to the next; our awareness of our visual surroundings is far more sparse than most people intuitively believe. These failures of awareness and the erroneous intuitions that often accompany them have both theoretical and practical ramifications. This article briefly summarizes the current state of research on change blindness and suggests future directions that promise to improve our understanding of scene perception and visual memory.},
author = {Simons, Daniel J and Ambinder, Michael S},
doi = {10.1111/j.0963-7214.2005.00332.x},
isbn = {0963-7214},
journal = {Current Directions in Psychological Science},
number = {1},
pages = {44--48},
publisher = {SAGE Publications Inc},
title = {{Change Blindness: Theory and Consequences}},
url = {https://doi.org/10.1111/j.0963-7214.2005.00332.x},
volume = {14},
year = {2005}
}
@misc{AmericanStatisticalAssociation2019,
abstract = {Participants in the Guidelines for Assessment and Instruction in Statistics Education (GAISE) project have created two reports of recommendations for introductory statistics courses (college level) and statistics education in Pre-K-12 years.},
author = {{American Statistical Association}},
keywords = {gaise, guidelines for assessment and instruction i},
shorttitle = {Guidelines for Assessment and Instruction in Stati},
title = {{Guidelines for Assessment and Instruction in Statistics Education Reports}},
url = {https://www.amstat.org/asa/education/Guidelines-for-Assessment-and-Instruction-in-Statistics-Education-Reports.aspx},
volume = {2018},
year = {2019}
}
@incollection{Borner2015a,
address = {Cambridge, Massachusetts},
annote = {2014028219
Katy Börner.
illustrations (some color), maps (some color) ; 29 x 34 cm
One of a series of three publications influenced by the travelling exhibit Places {\&} Spaces: Mapping Science, curated by the Cyberinfrastructure for Network Science Center at Indiana University.
Includes bibliographical references and indexes.
Science and technology facts -- Envisioning science and technology -- Science maps in action -- Outlook.},
author = {Börner, Katy},
booktitle = {Atlas of knowledge : anyone can map},
isbn = {9780262028813 (hardcover alk. paper)0262028816 (hardcover alk. paper)},
keywords = {Communication in science Data processing.,Graph design.,Information visualization.,Science Atlases.,Science Study and teaching Graphic methods.,Statistics Graphic methods.,Technical illustration.},
pages = {26},
pmid = {18232070},
publisher = {The MIT Press},
title = {{Insight Need Types}},
year = {2015}
}
@incollection{Ware2013b,
abstract = {"This is a book about what the science of perception can tell us about visualization. There is a gold mine of information about how we see to be found in more than a century of work by vision researchers. The purpose of this book is to extract from that large body of research literature those design principles that apply to displaying information effectively"--},
address = {Waltham, MA},
annote = {2012009489
Colin Ware.
illustrations (some color) ; 25 cm.
Includes bibliographical references (pages [459]-496) and index.
Machine generated contents note: Chapter 1. Foundations for an Applied Science of Data Visualization Chapter 2. The Environment, Optics, Resolution, and the Display Chapter 3. Lightness, Brightness, Contrast and Constancy Chapter 4. Color Chapter 5. Visual Salience and Finding Information Chapter 6. Static and Moving Patterns Chapter 7. Space Perception Chapter 8. Visual Objects and Data Objects Chapter 9. Images, Narrative, and Gestures for Explanation Chapter 10. Interacting with Visualizations Chapter 11. Visual Thinking Processes.},
author = {Ware, Colin},
booktitle = {Information visualization: perception for design},
edition = {Third edit},
isbn = {9780123814647 (hardback)},
keywords = {Information visualization.,Visual perception.,Visualization.},
pages = {1--30},
pmid = {17195003},
publisher = {Morgan Kaufmann},
title = {{Foundations for an Applied Science of Data Visualization}},
year = {2013}
}
@incollection{Schroeder2005,
address = {Burlington},
author = {Schroeder, William J and Martin, Kenneth M},
booktitle = {Visualization Handbook},
doi = {https://doi.org/10.1016/B978-012387582-2/50003-4},
editor = {Hansen, Charles D and Johnson, Chris R},
isbn = {978-0-12-387582-2},
pages = {3--35},
publisher = {Butterworth-Heinemann},
title = {{1 - Overview of Visualization  Text and images taken with permission from the book The Visualization Toolkit: An Object-Oriented Approach to 3D Graphics, 3rd ed., published by Kitware, Inc. http://www.kitware.com/products/vtktextbook.html}},
url = {http://www.sciencedirect.com/science/article/pii/B9780123875822500034},
year = {2005}
}
@article{Treisman1985,
abstract = {Five experiments, with 42 university students, showed that the search rate for a target among distractors varied dramatically depending on which stimulus played the role of target and which that of distractors. For example, the time required to find a circle distinguished by an intersecting line was independent of the number of regular circles in the display, whereas the time to find a regular circle among circles with lines increased linearly with the number of distractors. The pattern of performance suggests parallel processing when the target had a unique distinguishing feature and serial self-terminating search when the target was distinguished only by the absence of a feature that was present in all the distractors. Results are consistent with A. Treisman and G. Gelade's (see record 1980-04685-001) feature-integration theory, which predicts that a single feature should be detected by the mere presence of activity in the relevant feature map, whereas tasks that require Ss to locate multiple instances of a feature demand focused attention. Search asymmetries may therefore offer a new diagnostic to identify the primitive features of early vision. Several candidate features are examined. Colors, line ends or terminators, and closure (in the sense of a partly or wholly enclosed area) appear to be functional features; connectedness, intactness (absence of an intersecting line), and acute angles do not. (40 ref) (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
address = {US},
annote = {Treisman, A
Souther, J
eng
Research Support, Non-U.S. Gov't
J Exp Psychol Gen. 1985 Sep;114(3):285-310.},
author = {Treisman, Anne and Souther, Janet},
doi = {10.1037/0096-3445.114.3.285},
edition = {1985/09/01},
isbn = {1939-2222(Electronic),0096-3445(Print)},
journal = {Journal of Experimental Psychology: General},
keywords = {*Visual Discrimination,*Visual Search,Cognitive Maps,Distraction,Pictorial Stimuli},
number = {3},
pages = {285--310},
pmid = {3161978},
publisher = {American Psychological Association},
title = {{Search asymmetry: A diagnostic for preattentive processing of separable features}},
url = {https://www.ncbi.nlm.nih.gov/pubmed/3161978},
volume = {114},
year = {1985}
}
@book{Ware2013c,
abstract = {"This is a book about what the science of perception can tell us about visualization. There is a gold mine of information about how we see to be found in more than a century of work by vision researchers. The purpose of this book is to extract from that large body of research literature those design principles that apply to displaying information effectively"--},
address = {Waltham, MA},
annote = {2012009489
Colin Ware.
illustrations (some color) ; 25 cm.
Includes bibliographical references (pages [459]-496) and index.
Machine generated contents note: Chapter 1. Foundations for an Applied Science of Data Visualization Chapter 2. The Environment, Optics, Resolution, and the Display Chapter 3. Lightness, Brightness, Contrast and Constancy Chapter 4. Color Chapter 5. Visual Salience and Finding Information Chapter 6. Static and Moving Patterns Chapter 7. Space Perception Chapter 8. Visual Objects and Data Objects Chapter 9. Images, Narrative, and Gestures for Explanation Chapter 10. Interacting with Visualizations Chapter 11. Visual Thinking Processes.},
author = {Ware, Colin},
booktitle = {Interactive technologies},
edition = {Third edit},
isbn = {9780123814647 (hardback)},
keywords = {Information visualization.,Visual perception.,Visualization.},
pages = {xx, 512 pages},
pmid = {17195003},
publisher = {Morgan Kaufmann},
title = {{Information visualization: perception for design}},
year = {2013}
}
@article{Yoon2017,
abstract = {Examining landscapes of research data management services in academic libraries is timely and significant for both those libraries on the front line and the libraries that are already ahead. While it provides overall understanding of where the research data management program is at and where it is going, it also provides understanding of current practices and data management recommendations and/or tool adoptions as well as revealing areas of improvement and support. This study examined the research data (management) services in academic libraries in the United States through a content analysis of 185 library websites, with four main areas of focus: service, information, education, and network. The results from the content analysis of these webpages reveals that libraries need to advance and engage more actively to provide services, supply information online, and develop educational services. There is also a wide variation among library data management services and programs according to their web presence. {\textcopyright} 2017 Ayoung Yoon and Teresa Schultz.},
annote = {Cited By :1
Export Date: 20 July 2018},
author = {Yoon, A and Schultz, T},
doi = {10.5860/crl.78.7.920},
isbn = {00100870 (ISSN)},
journal = {College and Research Libraries},
language = {English},
number = {7},
pages = {920--933},
publisher = {Association of College and Research Libraries},
title = {{Research data management services in academic libraries in the US: A content analysis of libraries' websites}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85032810413{\&}doi=10.5860{\%}2Fcrl.78.7.920{\&}partnerID=40{\&}md5=de66784abc4813b90cc874fd35557611 https://crl.acrl.org/index.php/crl/article/download/16788/18345},
volume = {78},
year = {2017}
}
@incollection{Matthes2016,
abstract = {Python Crash Courseis a quick, no-nonsense guide to programming in Python.},
address = {San Francisco, CA},
annote = {Accession Number: 1141153; OCLC: 932304495; Language: English},
author = {Matthes, Eric},
booktitle = {Python Crash Course : A Hands-on, Project-based Introduction to Programming},
isbn = {97815932760349781593277390},
keywords = {COMPUTERS / Software Development {\&} Engineering / S,Computer programming,Python (Computer program language)},
language = {English},
publisher = {No Starch Press},
title = {{Chapter 1: Introduction}},
url = {http://search.ebscohost.com/login.aspx?direct=true{\&}db=nlebk{\&}AN=1141153{\&}site=ehost-live},
year = {2016}
}
@inproceedings{Staubitz2015,
abstract = {In recent years, Massive Open Online Courses (MOOCs) have become a phenomenon presenting the prospect of free high class education to everybody. They bear a tremendous potential for teaching programming to a large and diverse audience. The typical MOOC components, such as video lectures, reading material, and easily assessable quizzes, however, are not sufficient for proper programming education. To learn programming, participants need an option to work on practical programming exercises and to solve actual programming tasks. It is crucial that the participants receive proper feedback on their work in a timely manner. Without a tool for automated assessment of programming assignments, the teaching teams would be restricted to offer optional ungraded exercises only. The paper at hand sketches scenarios how practical programming exercises could be provided and examines the landscape of potentially helpful tools in this context. Automated assessment has a long record in the history of computer science education. We give an overview of existing tools in this field and also explore the question what can and/or should be assessed.},
author = {Staubitz, T and Klement, H and Renz, J and Teusner, R and Meinel, C},
booktitle = {2015 IEEE International Conference on Teaching, Assessment, and Learning for Engineering (TALE)},
doi = {10.1109/TALE.2015.7386010},
keywords = {Assessment,Browsers,Context,Education,Games,MOOC,Programming,Programming profession,Servers,automated assessment,computer aided instruction,computer science education,educational courses,hand sketches,high class education,learn programming,massive open online courses,practical programming exercises,programming assignments,proper programming education,teaching programming},
pages = {23--30},
title = {{Towards practical programming exercises and automated assessment in Massive Open Online Courses}},
url = {https://ieeexplore.ieee.org/ielx7/7377406/7385995/07386010.pdf?tp={\&}arnumber=7386010{\&}isnumber=7385995},
year = {2015}
}
@article{Hampton2017,
abstract = {The scale and magnitude of complex and pressing environmental issues lend urgency to the need for integrative and reproducible analysis and synthesis, facilitated by data-intensive research approaches. However, the recent pace of technological change has been such that appropriate skills to accomplish data-intensive research are lacking among environmental scientists, who more than ever need greater access to training and mentorship in computational skills. Here, we provide a roadmap for raising data competencies of current and next-generation environmental researchers by describing the concepts and skills needed for effectively engaging with the heterogeneous, distributed, and rapidly growing volumes of available data. We articulate five key skills: (1) data management and processing, (2) analysis, (3) software skills for science, (4) visualization, and (5) communication methods for collaboration and dissemination. We provide an overview of the current suite of training initiatives available to environmental scientists and models for closing the skill-Transfer gap.},
annote = {Cited By :2
Export Date: 20 July 2018
CODEN: BISNA},
author = {Hampton, S E and Jones, M B and Wasser, L A and Schildhauer, M P and Supp, S R and Brun, J and Hernandez, R R and Boettiger, C and Collins, S L and Gross, L J and Fern{\'{a}}ndez, D S and Budden, A and White, E P and Teal, T K and Labou, S G and Aukema, J E},
doi = {10.1093/biosci/bix025},
isbn = {00063568 (ISSN)},
journal = {BioScience},
keywords = {computing,data management,ecology,informatics,workforce development},
language = {English},
number = {6},
pages = {546--557},
publisher = {Oxford University Press},
title = {{Skills and Knowledge for Data-Intensive Environmental Research}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85021122346{\&}doi=10.1093{\%}2Fbiosci{\%}2Fbix025{\&}partnerID=40{\&}md5=b8011adb51034a1aaee452b28bb39d93 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5451289/pdf/bix025.pdf},
volume = {67},
year = {2017}
}
@article{Treisman1988,
abstract = {A series of search experiments tested detection of targets distinguished from the distractors by differences on a single dimension. Our aim was to use the pattern of search latencies to infer which features are coded automatically in early vision. For each of 12 different dimensions, one or more pairs of contrasting stimuli were tested. Each member of a pair played the role of target in one condition and the role of distractor in the other condition. Targets defined by larger values on the quantitative dimensions of length, number, and contrast, by line curvature, by misaligned orientation, and by values that deviated from a standard or prototypical color or shape were detected easily, whereas targets defined by smaller values on the quantitative dimensions, by straightness, by frame-aligned orientation, and by prototypical colors or shapes required slow and apparently serial search. We interpret the results as evidence that focused attention to single items or to groups is required to reduce background activity when the Weber fraction distinguishing the pooled feature activity with displays containing a target and with displays containing only distractors is too small to allow reliable discrimination. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
address = {US},
annote = {Treisman, A
Gormican, S
eng
Research Support, Non-U.S. Gov't
Psychol Rev. 1988 Jan;95(1):15-48.},
author = {Treisman, Anne and Gormican, Stephen},
doi = {10.1037/0033-295X.95.1.15},
edition = {1988/01/01},
isbn = {1939-1471(Electronic),0033-295X(Print)},
journal = {Psychological Review},
keywords = {*Color Perception,*Spatial Organization,*Visual Contrast,*Visual Discrimination,*Visual Search,Form and Shape Perception},
number = {1},
pages = {15--48},
pmid = {3353475},
publisher = {American Psychological Association},
title = {{Feature analysis in early vision: Evidence from search asymmetries}},
url = {https://www.ncbi.nlm.nih.gov/pubmed/3353475},
volume = {95},
year = {1988}
}
@misc{Guo2017,
address = {Denver, Colorado, USA},
author = {Guo, Philip J},
booktitle = {Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems},
doi = {10.1145/3025453.3025945},
pages = {7070--7083},
publisher = {ACM},
title = {{Older Adults Learning Computer Programming: Motivations, Frustrations, and Design Opportunities}},
url = {https://dl.acm.org/citation.cfm?doid=3025453.3025945},
year = {2017}
}
@article{Hew2014,
abstract = {Abstract Although past research has sought to identify the factors of student engagement in traditional online courses, two questions remained largely unanswered with regard to Massive Open Online Courses (MOOCs): do the factors that could influence student engagement in traditional online courses also apply to online courses that are massive and open? What factors do students consider important in terms of their perceived ability to promote a satisfying or engaging online learning experience? This paper reports a case study of three top-rated MOOCs in the disciplines of programming languages, literature, and arts {\&} design in order to address these very questions. Using a mixed methods approach that combines participant observation with analysis of reflection data from 965 course participants, this paper seeks to understand the factors behind the popularity of these MOOCs. Five factors were found. These include the following, ranked in terms of importance: (1) problem-centric learning with clear expositions, (2) instructor accessibility and passion, (3) active learning, (4) peer interaction, and (5) using helpful course resources. The specific design strategies pertaining to each factor are further discussed in this paper. These strategies can provide useful guidance for instructors and are a worthwhile subject for further experimental validation.},
author = {Hew, Khe Foon},
doi = {10.1111/bjet.12235},
isbn = {0007-1013},
journal = {British Journal of Educational Technology},
number = {2},
pages = {320--341},
publisher = {Wiley/Blackwell (10.1111)},
title = {{Promoting engagement in online courses: What strategies can we learn from three highly rated MOOCS}},
url = {https://doi.org/10.1111/bjet.12235 https://onlinelibrary.wiley.com/doi/pdf/10.1111/bjet.12235},
volume = {47},
year = {2014}
}
@article{Brehmer2013,
abstract = {The considerable previous work characterizing visualization usage has focused on low-level tasks or interactions and high-level tasks, leaving a gap between them that is not addressed. This gap leads to a lack of distinction between the ends and means of a task, limiting the potential for rigorous analysis. We contribute a multi-level typology of visualization tasks to address this gap, distinguishing why and how a visualization task is performed, as well as what the task inputs and outputs are. Our typology allows complex tasks to be expressed as sequences of interdependent simpler tasks, resulting in concise and flexible descriptions for tasks of varying complexity and scope. It provides abstract rather than domain-specific descriptions of tasks, so that useful comparisons can be made between visualization systems targeted at different application domains. This descriptive power supports a level of analysis required for the generation of new designs, by guiding the translation of domain-specific problems into abstract tasks, and for the qualitative evaluation of visualization usage. We demonstrate the benefits of our approach in a detailed case study, comparing task descriptions from our typology to those derived from related work. We also discuss the similarities and differences between our typology and over two dozen extant classification systems and theoretical frameworks from the literatures of visualization, human-computer interaction, information retrieval, communications, and cartography.},
author = {Brehmer, Matthew and Munzner, Tamara},
doi = {10.1109/TVCG.2013.124},
isbn = {1077-2626},
journal = {IEEE Transactions on Visualization and Computer Graphics},
keywords = {Algorithms,Artificial Intelligence,Computer Simulation,Encoding,Humans,Modeling,Models, Theoretical,Qualitative evaluations,Reproducibility of Results,Sensitivity and Specificity,Task Performance and Analysis,Topology,Typology,User-Computer Interface,Visual Perception,abstract visualization tasks,cartography,communications,data visualisation,domain-specific problems,extant classification systems,human-computer interaction,information retrieval,multilevel typology,pattern classification,qualitative evaluation,task and requirements analysis,visualization models,visualization systems,visualization usage qualitative evaluation},
number = {12},
pages = {2376--2385},
title = {{A Multi-Level Typology of Abstract Visualization Tasks}},
url = {https://ieeexplore.ieee.org/ielx7/2945/6634084/06634168.pdf?tp={\&}arnumber=6634168{\&}isnumber=6634084},
volume = {19},
year = {2013}
}
@article{Donoho2017,
abstract = {ABSTRACTMore than 50 years ago, John Tukey called for a reformation of academic statistics. In ?The Future of Data Analysis,? he pointed to the existence of an as-yet unrecognized science, whose subject of interest was learning from data, or ?data analysis.? Ten to 20 years ago, John Chambers, Jeff Wu, Bill Cleveland, and Leo Breiman independently once again urged academic statistics to expand its boundaries beyond the classical domain of theoretical statistics; Chambers called for more emphasis on data preparation and presentation rather than statistical modeling; and Breiman called for emphasis on prediction rather than inference. Cleveland and Wu even suggested the catchy name ?data science? for this envisioned field. A recent and growing phenomenon has been the emergence of ?data science? programs at major universities, including UC Berkeley, NYU, MIT, and most prominently, the University of Michigan, which in September 2015 announced a {\$}100M ?Data Science Initiative? that aims to hire 35 new faculty. Teaching in these new programs has significant overlap in curricular subject matter with traditional statistics courses; yet many academic statisticians perceive the new programs as ?cultural appropriation.? This article reviews some ingredients of the current ?data science moment,? including recent commentary about data science in the popular media, and about how/whether data science is really different from statistics. The now-contemplated field of data science amounts to a superset of the fields of statistics and machine learning, which adds some technology for ?scaling up? to ?big data.? This chosen superset is motivated by commercial rather than intellectual developments. Choosing in this way is likely to miss out on the really important intellectual event of the next 50 years. Because all of science itself will soon become data that can be mined, the imminent revolution in data science is not about mere ?scaling up,? but instead the emergence of scientific studies of data analysis science-wide. In the future, we will be able to predict how a proposal to change data analysis workflows would impact the validity of data analysis across all of science, even predicting the impacts field-by-field. Drawing on work by Tukey, Cleveland, Chambers, and Breiman, I present a vision of data science based on the activities of people who are ?learning from data,? and I describe an academic field dedicated to improving that activity in an evidence-based manner. This new field is a better academic enlargement of statistics and machine learning than today?s data science initiatives, while being able to accommodate the same short-term goals. Based on a presentation at the Tukey Centennial Workshop, Princeton, NJ, September 18, 2015.},
author = {Donoho, David},
doi = {10.1080/10618600.2017.1384734},
isbn = {1061-8600},
journal = {Journal of Computational and Graphical Statistics},
number = {4},
pages = {745--766},
publisher = {Taylor {\&} Francis},
title = {{50 Years of Data Science}},
url = {https://doi.org/10.1080/10618600.2017.1384734 https://www.tandfonline.com/doi/pdf/10.1080/10618600.2017.1384734?needAccess=true},
volume = {26},
year = {2017}
}
@article{Staff2017,
abstract = {[This corrects the article DOI: 10.1371/journal.pcbi.1005755.].},
annote = {Export Date: 15 July 2019},
author = {Staff, Plos Computational Biology},
doi = {10.1371/journal.pcbi.1005858},
isbn = {15537358 (ISSN)},
journal = {PLOS Computational Biology},
keywords = {erratum,error},
language = {English},
number = {11},
pages = {e1005858},
publisher = {NLM (Medline)},
title = {{Erratum: Correction: Unmet needs for analyzing biological big data: A survey of 704 NSF principal investigators (PLoS computational biology (2017) 13 10 (e1005755))}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85057377811{\&}doi=10.1371{\%}2Fjournal.pcbi.1005858{\&}partnerID=40{\&}md5=0d0bd566518a3f85a8213ec5451e562f https://journals.plos.org/ploscompbiol/article/file?id=10.1371/journal.pcbi.1005858{\&}type=printable},
volume = {13},
year = {2017}
}
@article{Jacobs2016,
abstract = {Computer programming was once thought of as a skill required only by professional software developers. But today, given the ubiquitous nature of computation and data science it is quickly becoming necessary for all scientists and engineers to have at least a basic knowledge of how to program. Teaching how to program, particularly to those students with little or no computing background, is well-known to be a difficult task. However, there is also a wealth of evidence-based teaching practices for teaching programming skills that can be applied to greatly improve learning outcomes and the student experience. Adopting these practices naturally gives rise to greater learning efficiency-this is critical if programming is to be integrated into an already busy geoscience curriculum. This article considers an undergraduate computer programming course, run during the last five years in the Department of Earth Science and Engineering at Imperial College London. The teaching methodologies that were used each year are discussed, along with the challenges that were encountered and how the methodologies affected student performance. Anonymized student marks and feedback are used to highlight the discussion, and also how the adjustments made to the course eventually resulted in a highly effective learning environment. {\textcopyright} 2016 National Association of Geoscience Teachers.},
annote = {Cited By :3
Export Date: 20 July 2018
Correspondence Address: Jacobs, C.T.; Department of Earth Science and Engineering, South Kensington Campus, Imperial College LondonUnited Kingdom; email: c.jacobs10@imperial.ac.uk},
author = {Jacobs, C T and Gorman, G J and Rees, H E and Craig, L E},
doi = {10.5408/15-101.1},
isbn = {10899995 (ISSN)},
journal = {Journal of Geoscience Education},
keywords = {Computer programming,Earth science,England,Feedback,London [England],Teaching methodology,Undergraduate,United Kingdom,computer simulation,curriculum,higher education,learning,methodology,teaching,technology diffusion,university sector},
language = {English},
number = {3},
pages = {183--198},
publisher = {National Association of Geoscience Teachers Inc.},
title = {{Experiences with efficient methodologies for teaching computer programming to geoscientists}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84983371462{\&}doi=10.5408{\%}2F15-101.1{\&}partnerID=40{\&}md5=5098692ff8cff31eec3f450c00297d13 https://www.tandfonline.com/doi/full/10.5408/15-101.1},
volume = {64},
year = {2016}
}
@article{Varley-Winter2016,
author = {Varley-Winter, Olivia and Shah, Hetan},
doi = {10.1098/rsta.2016.0116},
journal = {Philosophical Transactions of the Royal Society A: Mathematical, Physical and Engineering Sciences},
number = {2083},
pages = {20160116},
publisher = {Royal Society},
title = {{The opportunities and ethics of big data: practical priorities for a national Council of Data Ethics}},
url = {https://doi.org/10.1098/rsta.2016.0116},
volume = {374},
year = {2016}
}
@incollection{Forrester2016a,
author = {Forrester, John V and Dick, Andrew D and McMenamin, Paul G and Roberts, Fiona and Pearlman, Eric},
booktitle = {The Eye (Fourth Edition)},
doi = {https://doi.org/10.1016/B978-0-7020-5554-6.00005-8},
editor = {Forrester, John V and Dick, Andrew D and McMenamin, Paul G and Roberts, Fiona and Pearlman, Eric},
isbn = {978-0-7020-5554-6},
pages = {269--337.e2},
publisher = {W.B. Saunders},
title = {{Chapter 5 - Physiology of vision and the visual system}},
url = {http://www.sciencedirect.com/science/article/pii/B9780702055546000058},
year = {2016}
}
@book{Knaflic2015a,
address = {Hoboken, New Jersey},
annote = {2015452957
Cole Nussbaumer Knaflic.
Data visualization guide for business professionals
illustrations (some color) ; 24 cm
Includes bibliographical references and index.},
author = {Knaflic, Cole Nussbaumer},
isbn = {9781119002253 (pbk.)1119002257},
keywords = {Business communication.,Business presentations.,Computer graphics.,Information visualization.},
pages = {xiii, 267 pages},
pmid = {19109477},
publisher = {Wiley},
title = {{Storytelling with data : a data visualization guide for business professionals}},
year = {2015}
}
@incollection{Brainard2001,
abstract = {Color vision is the ability to distinguish and identify lights and objects on the basis of their spectral properties. This entry presents several topics that underlie current theories of human color vision. These are trichromacy, opponency, adaptation, and color constancy. To understand the key ideas, it is useful to consider how information about color is transformed as it flows from the stimulus through the initial stages of the human visual system. At each image location, the color stimulus is specified by its spectral power distribution: the amount of power it contains at each wavelength. The classic color matching experiment shows that the normal human visual system is trichromatic: only three dimensions of spectral variation are coded by the visual system. The biological basis of normal trichromacy is that the retina contains three classes of cone photopigment. After the initial encoding of light by the cones, further processing occurs. Two aspects of this processing are particularly important. First, signals from three classes of cones are recombined to form a luminance and two color opponent channels. Second, there is adaptive signal regulation that keeps neural signals within their operating range and stabilizes the appearance of objects across changes of illumination (color constancy).},
address = {Oxford},
author = {Brainard, D H},
booktitle = {International Encyclopedia of the Social {\&} Behavioral Sciences},
doi = {https://doi.org/10.1016/B0-08-043076-7/00666-5},
editor = {Smelser, Neil J and Baltes, Paul B},
isbn = {978-0-08-043076-8},
pages = {2256--2263},
publisher = {Pergamon},
title = {{Color Vision Theory}},
url = {http://www.sciencedirect.com/science/article/pii/B0080430767006665},
year = {2001}
}
@article{Debra2015,
abstract = {Purpose ? The purpose of this paper is to chart the development of research data management services within the University of Bristol, from the initial Jisc-funded project, through to pilot service and planned core funding of the service. Design/methodology/approach ? The paper provides a case study of the approach of the University of Bristol Library service to develop a sustainable Research Data Service. Findings ? It outlines the services developed during the project and pilot phases of the service. In particular it focuses on the sustainability planning to ensure that research data management is embedded as a core university service. Originality/value ? The case study provides practical advice and valuable insights into the issues and experiences of ensuring that research data management is properly valued and supported within universities.},
author = {Debra, Hiom and Dom, Fripp and Stephen, Gray and Kellie, Snow and Damian, Steer},
chapter = {475},
doi = {10.1108/PROG-02-2015-0019},
isbn = {0033-0337},
journal = {Program},
number = {4},
pages = {475--493},
publisher = {Emerald},
title = {{Research data management at the University of Bristol: Charting a course from project to service}},
url = {https://doi.org/10.1108/PROG-02-2015-0019},
volume = {49},
year = {2015}
}
@article{Rustici2017,
abstract = {ELIXIR-UK is the UK node of ELIXIR, the European infrastructure for life science data. Since its foundation in 2014, ELIXIR-UK has played a leading role in training both within the UK and in the ELIXIR Training Platform, which coordinates and delivers training across all ELIXIR members. ELIXIR-UK contributes to the Training Platform's coordination and supports the development of training to address key skill gaps amongst UK scientists. As part of this work it acts as a conduit for nationally-important bioinformatics training resources to promote their activities to the ELIXIR community. ELIXIR-UK also leads ELIXIR's flagship Training Portal, TeSS, which collects information about a diverse range of training and makes it easily accessible to the community. ELIXIR-UK also works with others to provide key digital skills training, partnering with the Software Sustainability Institute to provide Software Carpentry training to the ELIXIR community and to establish the Data Carpentry initiative, and taking a lead role amongst national stakeholders to deliver the StaTS project - a coordinated effort to drive engagement with training in statistics. {\textcopyright} 2017 Larcombe L et al.},
annote = {Cited By :1
Export Date: 20 July 2018
Correspondence Address: Rustici, G.; Department of Genetics, University of CambridgeUnited Kingdom; email: gr231@cam.ac.uk},
author = {Rustici, G and Larcombe, L and Hendricusdottir, R and Attwood, T K and Bacall, F and Beard, N and Bellis, L J and Dunn, W B and Hancock, J M and Nenadic, A and Orengo, C and Overduin, B and Sansone, S A and Thurston, M and Viant, M R and Winder, C L and Goble, C A and Ponting, C P},
doi = {10.12688/f1000research.11837.1},
isbn = {20461402 (ISSN)},
journal = {F1000Research},
keywords = {Bioinformatics,ELIXIR-UK,Genomics,Impact,Metabolomics,Structural Bioinformatics,TeSS,Training,elixir,human,skill,software,statistics},
language = {English},
publisher = {Faculty of 1000 Ltd},
title = {{ELIXIR-UK role in bioinformatics training at the national level and across ELIXIR}},
url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85027266321{\&}doi=10.12688{\%}2Ff1000research.11837.1{\&}partnerID=40{\&}md5=526efc72b93b53c7afb008e27dd78d3b https://f1000researchdata.s3.amazonaws.com/manuscripts/12791/3b982f08-c644-4daa-8abc-ff035846e77e{\_}11837{\_}},
volume = {6},
year = {2017}
}
@article{Porter2019,
author = {Porter, Sandra G and Smith, Todd M},
doi = {10.1089/omi.2019.0080},
journal = {OMICS: A Journal of Integrative Biology},
publisher = {Mary Ann Liebert, Inc., publishers},
title = {{Bioinformatics for the Masses: The Need for Practical Data Science in Undergraduate Biology}},
url = {https://doi.org/10.1089/omi.2019.0080},
year = {2019}
}
@misc{McKenna2017,
author = {McKenna, S},
booktitle = {Eurographics Conference on Visualization (EuroVis)},
title = {{Visual Narrative Flow: Exploring Factors Shaping Data Visualization Story Reading Experiences}},
volume = {36},
year = {2017}
}
@book{Kirk2016a,
address = {Thousand Oaks, CA},
annote = {2015957322
Andy Kirk.},
author = {Kirk, Andy},
isbn = {97814739605419781473912137},
pages = {pages cm},
pmid = {18855341},
publisher = {SAGE Publications},
title = {{Data visualisation : a handbook for data driven design}},
year = {2016}
}
@incollection{Lander2017g,
author = {Lander, Jared P},
booktitle = {R for Everyone},
edition = {2nd},
title = {{Basics of R}},
year = {2017}
}
@article{Munafo2017,
abstract = {Improving the reliability and efficiency of scientific research will increase the credibility of the published scientific literature and accelerate discovery. Here we argue for the adoption of measures to optimize key elements of the scientific process: methods, reporting and dissemination, reproducibility, evaluation and incentives. There is some evidence from both simulations and empirical studies supporting the likely effectiveness of these measures, but their broad adoption by researchers, institutions, funders and journals will require iterative evaluation and improvement. We discuss the goals of these measures, and how they can be implemented, in the hope that this will facilitate action toward improving the transparency, reproducibility and efficiency of scientific research.},
annote = {Fr0ti
Times Cited:122
Cited References Count:88},
author = {Munaf{\`{o}}, Marcus R and Nosek, Brian A and Bishop, Dorothy V M and Button, Katherine S and Chambers, Christopher D and {Percie du Sert}, Nathalie and Simonsohn, Uri and Wagenmakers, Eric-Jan and Ware, Jennifer J and Ioannidis, John P A},
chapter = {0021},
doi = {10.1038/s41562-016-0021},
isbn = {2397-3374},
journal = {Nature Human Behaviour},
keywords = {biomedical-research,file drawer,increasing value,metaanalysis,psychological-research,randomized controlled trials,reducing waste,registered-reports,sample-size,statistical power},
language = {English},
number = {1},
title = {{A manifesto for reproducible science}},
volume = {1},
year = {2017}
}
@article{Livitz2010,
abstract = {Abstract Chromatic assimilation and chromatic contrast are two different types of spatio-chromatic interactions, which are rarely observed simultaneously. These phenomena are normally considered mutually exclusive, as they shift the chromaticity of an “induced” region in opposite chromatic directions: away and toward the chromaticity of the surround, respectively. In our displays we observed a shift of chromaticity of a target achromatic field induced by a uniform purple surround in a direction in color space that can be interpreted as the combined effect of chromatic contrast and chromatic assimilation of the surround color. We measured this combined effect by varying stimulus size, stimulus eccentricity, and binocular disparity of our stimuli. Our results show that chromatic assimilation and chromatic induction do not always cancel each other and may lead to perceptual shifts in chromaticity in a direction in color space that does not coincide with the line formed by the color of the surround and its chromatic complement. For example, due to the impact of a purple surround, a region that would look gray without chromatic surround does not look green or purplish, but is perceived as blue if viewed from a certain distance. We explain the observed effects by the structure of receptive fields of the neurons that encode spatio-chromatic interactions and by combination of individual induction effects produced by inputs representing primary chromatic signals on the output of double-opponent neurons.},
annote = {10.1167/10.7.398},
author = {Livitz, Gennady and Mingolla, Ennio},
doi = {10.1167/10.7.398},
isbn = {1534-7362},
journal = {Journal of Vision},
number = {7},
pages = {398},
title = {{The Combined Effect of Chromatic Contrast and Chromatic Assimilation Produced by a Purple Surround on an Achromatic Target}},
url = {http://dx.doi.org/10.1167/10.7.398},
volume = {10},
year = {2010}
}
